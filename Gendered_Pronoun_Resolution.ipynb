{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Gendered Pronoun Resolution*\n",
    "\n",
    "En el análisis de texto natural, existen oraciones complejas de entender incluso para las personas. Uno de los casos más conflictivos son los pronombres ambiguos. En 2018, se publicó un dataset junto con el paper [A Balanced Corpus of Gendered Ambiguous Pronouns](https://arxiv.org/pdf/1810.05201.pdf), donde se proponen un conjunto de textos con pronombres ambiguos con género.\n",
    "\n",
    "El objetivo de este dataset es encontrar el nombre en el texto al que el pronombre ambiguo hace referencia.\n",
    "\n",
    "Para ello se nos da un dataset con los siguientes campos:\n",
    "\n",
    "* `ID`: Identificador de la frase.\n",
    "* `Text`: Texto en fromato string.\n",
    "* `Pronoun`: string con el pronombre ambiguo.\n",
    "* `Pronoun-offset`: índice del carácter donde empieza el pronombre dentro del texto.\n",
    "* `A`: string con el primer nombre candidato a hacer referencia por el pronombre.\n",
    "* `A-offset`: índice del carácter donde empieza el nombre A dentro del texto.\n",
    "* `A-coref`: boleano indicando si el pronombre hace referencia al nombre A.\n",
    "* `B`: string con el segundo nombre candidato a hacer referencia por el pronombre.\n",
    "* `B-offset`: índice del carácter donde empieza el nombre B dentro del texto.\n",
    "* `B-coref`: boleano indicando si el pronombre hace referencia al nombre B.\n",
    "* `URL`: web de donde se ha sacado el fragmento de texto.\n",
    "\n",
    "## Objetivo:\n",
    "\n",
    "Hacer una predicción de a cuál de los dos nombres marcados en cada frase hace referencia el pronombre seleccionado usando **dos modelos distintos** de PNL siguiendo el formato descrito a continuación:\n",
    "\n",
    "* **MODELO 1**: Puede ser **cualquier modelo visto en los seminarios de PLN o en otras asignaturas**, como: Count vectorizer, HMM, Structured Perceptron, RNN, Logistic Regressor, XGBoost, etc...\n",
    "\n",
    "    * Justificar el porqué del modelo elegido.\n",
    "    * Entrenar el modelo.\n",
    "    * Dar una accuracy del modelo.\n",
    "    * Interpretar y explicar los resultados del modelo.\n",
    " \n",
    "\n",
    "* **MODELO 2**: Debe ser un modelo **basado en Transformers** que incorpore el concepto de ***attention***.\n",
    "\n",
    "    * Justificar el porqué del modelo elegido.\n",
    "    * Entrenar el modelo.\n",
    "    * Dar una accuracy del modelo.\n",
    "    * Interpretar y explicar los resultados del modelo.    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "import string \n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gap-development.tsv', 'gap-test.tsv', 'gap-validation.tsv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./input/gap-coreference-master\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./input/gap-coreference-master'"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = './input/'\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap-coreference-master')\n",
    "GAP_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-development.tsv')\n",
    "test_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-test.tsv')\n",
    "val_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-validation.tsv')\n",
    "\n",
    "train_df = pd.read_csv(train_df_path, sep='\\t') # train_df\n",
    "test_df = pd.read_csv(test_df_path, sep='\\t')\n",
    "val_df = pd.read_csv(val_df_path, sep='\\t')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text Pronoun   \n",
       "0  development-1  Zoe Telford -- played the police officer girlf...     her  \\\n",
       "1  development-2  He grew up in Evanston, Illinois the second ol...     His   \n",
       "2  development-3  He had been reelected to Congress, but resigne...     his   \n",
       "3  development-4  The current members of Crime have also perform...     his   \n",
       "4  development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...     She   \n",
       "\n",
       "   Pronoun-offset                  A  A-offset  A-coref                B   \n",
       "0             274     Cheryl Cassidy       191     True          Pauline  \\\n",
       "1             284          MacKenzie       228     True    Bernard Leach   \n",
       "2             265            Angeloz       173    False       De la Sota   \n",
       "3             321               Hell       174    False  Henry Rosenthal   \n",
       "4             437  Kitty Oppenheimer       219    False           Rivera   \n",
       "\n",
       "   B-offset  B-coref                                                URL  \n",
       "0       207    False  http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1       251    False      http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2       246     True  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3       336     True          http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4       294     True        http://en.wikipedia.org/wiki/Jessica_Rivera  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text              0\n",
       "Pronoun           0\n",
       "Pronoun-offset    0\n",
       "A                 0\n",
       "A-offset          0\n",
       "B                 0\n",
       "B-offset          0\n",
       "A-coref           0\n",
       "B-coref           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observamos que no hay valores nulos en el dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B-offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>324.963500</td>\n",
       "      <td>239.77800</td>\n",
       "      <td>300.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>98.788591</td>\n",
       "      <td>111.15768</td>\n",
       "      <td>113.226357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>274.000000</td>\n",
       "      <td>179.75000</td>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>239.00000</td>\n",
       "      <td>294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>370.000000</td>\n",
       "      <td>301.25000</td>\n",
       "      <td>358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1135.000000</td>\n",
       "      <td>971.00000</td>\n",
       "      <td>1098.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pronoun-offset    A-offset     B-offset\n",
       "count     2000.000000  2000.00000  2000.000000\n",
       "mean       324.963500   239.77800   300.535500\n",
       "std         98.788591   111.15768   113.226357\n",
       "min          3.000000     0.00000    16.000000\n",
       "25%        274.000000   179.75000   237.000000\n",
       "50%        316.000000   239.00000   294.000000\n",
       "75%        370.000000   301.25000   358.000000\n",
       "max       1135.000000   971.00000  1098.000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data \n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-coref\n",
      "False    1126\n",
      "True      874\n",
      "Name: count, dtype: int64\n",
      "\n",
      "B-coref\n",
      "False    1075\n",
      "True      925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data imbalance\n",
    "print(train_df[\"A-coref\"].value_counts())\n",
    "\n",
    "print(f\"\\n{train_df['B-coref'].value_counts()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El desbalanceo de clases no es extremadamente pronunciado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Zoe Telford -- played the police officer girlf...\n",
       "1       He grew up in Evanston, Illinois the second ol...\n",
       "2       He had been reelected to Congress, but resigne...\n",
       "3       The current members of Crime have also perform...\n",
       "4       Her Santa Fe Opera debut in 2005 was as Nuria ...\n",
       "                              ...                        \n",
       "1995    Faye's third husband, Paul Resnick, reported t...\n",
       "1996    The plot of the film focuses on the life of a ...\n",
       "1997    Grant played the part in Trevor Nunn's movie a...\n",
       "1998    The fashion house specialised in hand-printed ...\n",
       "1999    Watkins was a close friend of Hess' first wife...\n",
       "Name: Text, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full naw text\n",
    "raw_text = train_df[\"Text\"]\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para visualizar las frases\n",
    "def gap_printer2(data_df_row):\n",
    "        \n",
    "    text   = data_df_row[\"Text\"]\n",
    "    word_A = data_df_row[\"A\"]\n",
    "    word_B = data_df_row[\"B\"]\n",
    "    \n",
    "    pronoun       = data_df_row[\"Pronoun\"]\n",
    "    pronoun_begin = data_df_row[\"Pronoun-offset\"]\n",
    "    pronoun_end   = pronoun_begin + len(pronoun)\n",
    "    \n",
    "    word_A_begin = data_df_row[\"A-offset\"]\n",
    "    word_A_end   = data_df_row[\"A-offset\"] + len(word_A)\n",
    "    word_B_begin = data_df_row[\"B-offset\"]\n",
    "    word_B_end   = data_df_row[\"B-offset\"] + len(word_B)\n",
    "    \n",
    "    text_c = text.replace(word_A, \" {} \")\n",
    "    text_c = text.replace(word_B, \" {} \")\n",
    "    text_c = text.replace(pronoun, \" {} \")\n",
    "    \n",
    "    word_boundaries = np.sort([word_A_begin, word_A_end, pronoun_begin, pronoun_end, word_B_begin, word_B_end])\n",
    "    word_boundaries = list(zip(word_boundaries[::2], word_boundaries[1::2]))\n",
    "    \n",
    "    P1 = [0,word_boundaries[0][0]]\n",
    "    P2 = [word_boundaries[0][1],word_boundaries[1][0]]\n",
    "    P3 = [word_boundaries[1][1],word_boundaries[2][0]]\n",
    "    P4 = [word_boundaries[2][1],len(text)]\n",
    "\n",
    "    text_f = text[P1[0]:P1[1]] + \"{}\" + text[P2[0]:P2[1]] +  \"{}\" + text[P3[0]:P3[1]] + \"{}\" + text[P4[0]:P4[1]]\n",
    " \n",
    "    print(text_f.format( Fore.BLUE  + text[word_boundaries[0][0]:word_boundaries[0][1]]  + Fore.BLACK,\n",
    "                         Fore.BLUE  + text[word_boundaries[1][0]:word_boundaries[1][1]] + Fore.BLACK,\n",
    "                         Fore.BLUE  + text[word_boundaries[2][0]:word_boundaries[2][1]]  + Fore.BLACK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current members of Crime have also performed in San Francisco under the band name ''Remote Viewers``. Strike has published two works of fiction in recent years: Ports of \u001b[34mHell\u001b[30m, which is listed in the Rock and Roll Hall of Fame Library, and A Loud Humming Sound Came from Above. Rank has produced numerous films (under \u001b[34mhis\u001b[30m real name, \u001b[34mHenry Rosenthal\u001b[30m) including the hit The Devil and Daniel Johnston.\n"
     ]
    }
   ],
   "source": [
    "gap_printer2(train_df.loc[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El pronombre que tenemos que identificar es `his`. \n",
    "- Tenemos 2 posibles nombres a los que hace referencia: `Hell` y `Henry Rosenthal`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://en.wikipedia.org/wiki/Warren_MacKenzie'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraemos la URL del segundo elemento del dataset\n",
    "url = train_df[\"URL\"][1]\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge (Peppy) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois. MacKenzie studied with Bernard Leach from 1949 to 1952. His simple, wheel-thrown functional pottery is heavily influenced by the oriental aesthetic of Shoji Hamada and Kanjiro Kawai.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraemos el segundo texto del dataset\n",
    "text = train_df[\"Text\"][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'His'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraemos el primer pronombre del segundo elemento del dataset\n",
    "pronoun = train_df[\"Pronoun\"][1]\n",
    "pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraemos el offset del primer pronombre del segundo elemento del dataset\n",
    "pronoun_offset = train_df[\"Pronoun-offset\"][1]\n",
    "pronoun_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'His'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizamos de otra forma el pronombre. \n",
    "# A partir de la variable Text, si seleccionamos únicamente la parte que empieza\n",
    "# en el pronoun offset y acaba en el pronoun offset + el tamaño de ese pronombre, \n",
    "# lo que extraemos del texto es el pronombre. \n",
    "text[pronoun_offset:pronoun_offset+len(pronoun)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MacKenzie', 228)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos el nombre A y el A-offset\n",
    "A = train_df[\"A\"][1]\n",
    "A_offset = train_df[\"A-offset\"][1]\n",
    "A, A_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MacKenzie'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre A\n",
    "text[A_offset:A_offset+len(A)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Bernard Leach', 251)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre B y B-offset\n",
    "B = train_df[\"B\"][1]\n",
    "B_offset = train_df[\"B-offset\"][1]\n",
    "B, B_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bernard Leach'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre B \n",
    "text[B_offset:B_offset+len(B)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Variable Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos únicamente con las variables más interesantes: la URL no nos hace falta para un problema de procesado de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_imp_features(df):\n",
    "    imp_features =[\"Text\", \"Pronoun\", \"Pronoun-offset\", \"A\", \"A-offset\", \"B\", \"B-offset\"]\n",
    "    target_col = [\"A-coref\", \"B-coref\"]\n",
    "    df = df[imp_features+target_col]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = select_imp_features(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To lower case\n",
    "def lower_case(df):\n",
    "    df[\"text_clean\"] = df[\"Text\"].apply(lambda x: x.lower())\n",
    "    df[\"Pronoun\"] = df[\"Pronoun\"].apply(lambda x: x.lower())\n",
    "    df[\"A\"] = df[\"A\"].apply(lambda x: x.lower())\n",
    "    df[\"B\"] = df[\"B\"].apply(lambda x: x.lower())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>cheryl cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zoe telford -- played the police officer girlf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>mackenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>bernard leach</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>he grew up in evanston, illinois the second ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>de la sota</td>\n",
       "      <td>246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>he had been reelected to congress, but resigne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>hell</td>\n",
       "      <td>174</td>\n",
       "      <td>henry rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>the current members of crime have also perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>kitty oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>her santa fe opera debut in 2005 was as nuria ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Pronoun  Pronoun-offset   \n",
       "0  Zoe Telford -- played the police officer girlf...     her             274  \\\n",
       "1  He grew up in Evanston, Illinois the second ol...     His             284   \n",
       "2  He had been reelected to Congress, but resigne...     his             265   \n",
       "3  The current members of Crime have also perform...     his             321   \n",
       "4  Her Santa Fe Opera debut in 2005 was as Nuria ...     She             437   \n",
       "\n",
       "                   A  A-offset                B  B-offset  A-coref  B-coref   \n",
       "0     cheryl cassidy       191          pauline       207     True    False  \\\n",
       "1          mackenzie       228    bernard leach       251     True    False   \n",
       "2            angeloz       173       de la sota       246    False     True   \n",
       "3               hell       174  henry rosenthal       336    False     True   \n",
       "4  kitty oppenheimer       219           rivera       294    False     True   \n",
       "\n",
       "                                          text_clean  \n",
       "0  zoe telford -- played the police officer girlf...  \n",
       "1  he grew up in evanston, illinois the second ol...  \n",
       "2  he had been reelected to congress, but resigne...  \n",
       "3  the current members of crime have also perform...  \n",
       "4  her santa fe opera debut in 2005 was as nuria ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean = lower_case(train_df)\n",
    "train_df_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the contractions: Contraction Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(df):\n",
    "    df[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: contractions.fix(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "zoe telford -- played the police officer girlfriend of simon, maggie. dumped by simon in the final episode of series 1, after he slept with jenny, and is not seen again. phoebe thomas played cheryl cassidy, pauline's friend and also a year 11 pupil in simon's class. dumped her boyfriend following simon's advice after he would not have sex with her but later realised this was due to him catching crabs off her friend pauline.\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "re-elected in the 2007 election, she was re-named the minister of international relations, la francophonie and for the estrie region as well as the vice-chair of the treasury board. following her 2008 re-election, gagnon-tremblay gave up for portfolio of international relations to pierre arcand but was given the position of president of the treasury board previously occupied by monique jerome-forget who was also responsible for the portfolio of finances. she was given jerome-forget's government administration portfolio duties until 2010.\n"
     ]
    }
   ],
   "source": [
    "train_df_clean = expand_contractions(train_df_clean)\n",
    "# double check\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(train_df_clean[\"text_clean\"][0])\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(train_df_clean[\"text_clean\"][100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-characters and URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii_characters(df, col='text_clean'):\n",
    "    df[col] = df[col].apply(lambda text: re.sub(r'[^\\x00-\\x7f]', r'', text)) # get rid of non-characters and whitespace\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "zoe telford -- played the police officer girlfriend of simon, maggie. dumped by simon in the final episode of series 1, after he slept with jenny, and is not seen again. phoebe thomas played cheryl cassidy, pauline's friend and also a year 11 pupil in simon's class. dumped her boyfriend following simon's advice after he would not have sex with her but later realised this was due to him catching crabs off her friend pauline.\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "re-elected in the 2007 election, she was re-named the minister of international relations, la francophonie and for the estrie region as well as the vice-chair of the treasury board. following her 2008 re-election, gagnon-tremblay gave up for portfolio of international relations to pierre arcand but was given the position of president of the treasury board previously occupied by monique jerome-forget who was also responsible for the portfolio of finances. she was given jerome-forget's government administration portfolio duties until 2010.\n"
     ]
    }
   ],
   "source": [
    "train_df_clean = remove_non_ascii_characters(train_df_clean)\n",
    "\n",
    "# double check\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(train_df_clean[\"text_clean\"][0])\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(train_df_clean[\"text_clean\"][100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(df, col='text_clean'):\n",
    "    \"\"\"\n",
    "     - str.maketrans('', '', string.punctuation) crea un traductor utilizando maketrans \n",
    "       que mapea los caracteres de puntuación a None, es decir, los elimina.\n",
    "     - string.punctuation es una cadena predefinida en el módulo string que contiene todos \n",
    "       los caracteres de puntuación.\n",
    "     - text.translate(translator) aplica el traductor al texto, reemplazando las puntuaciones \n",
    "       con caracteres vacíos, lo que efectivamente las elimina.\n",
    "    \"\"\"\n",
    "    df[col] = df[col].apply(lambda text: text.translate(str.maketrans('', '', string.punctuation)))\n",
    "    # return re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \"\", text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "zoe telford  played the police officer girlfriend of simon maggie dumped by simon in the final episode of series 1 after he slept with jenny and is not seen again phoebe thomas played cheryl cassidy paulines friend and also a year 11 pupil in simons class dumped her boyfriend following simons advice after he would not have sex with her but later realised this was due to him catching crabs off her friend pauline\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "reelected in the 2007 election she was renamed the minister of international relations la francophonie and for the estrie region as well as the vicechair of the treasury board following her 2008 reelection gagnontremblay gave up for portfolio of international relations to pierre arcand but was given the position of president of the treasury board previously occupied by monique jeromeforget who was also responsible for the portfolio of finances she was given jeromeforgets government administration portfolio duties until 2010\n"
     ]
    }
   ],
   "source": [
    "train_df_clean = remove_punctuations(train_df_clean)\n",
    "# double check\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(train_df_clean[\"text_clean\"][0])\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(train_df_clean[\"text_clean\"][100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bernatsort/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') # word_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "['zoe', 'telford', 'played', 'the', 'police', 'officer', 'girlfriend', 'of', 'simon', 'maggie', 'dumped', 'by', 'simon', 'in', 'the', 'final', 'episode', 'of', 'series', '1', 'after', 'he', 'slept', 'with', 'jenny', 'and', 'is', 'not', 'seen', 'again', 'phoebe', 'thomas', 'played', 'cheryl', 'cassidy', 'paulines', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simons', 'class', 'dumped', 'her', 'boyfriend', 'following', 'simons', 'advice', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realised', 'this', 'was', 'due', 'to', 'him', 'catching', 'crabs', 'off', 'her', 'friend', 'pauline']\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "['reelected', 'in', 'the', '2007', 'election', 'she', 'was', 'renamed', 'the', 'minister', 'of', 'international', 'relations', 'la', 'francophonie', 'and', 'for', 'the', 'estrie', 'region', 'as', 'well', 'as', 'the', 'vicechair', 'of', 'the', 'treasury', 'board', 'following', 'her', '2008', 'reelection', 'gagnontremblay', 'gave', 'up', 'for', 'portfolio', 'of', 'international', 'relations', 'to', 'pierre', 'arcand', 'but', 'was', 'given', 'the', 'position', 'of', 'president', 'of', 'the', 'treasury', 'board', 'previously', 'occupied', 'by', 'monique', 'jeromeforget', 'who', 'was', 'also', 'responsible', 'for', 'the', 'portfolio', 'of', 'finances', 'she', 'was', 'given', 'jeromeforgets', 'government', 'administration', 'portfolio', 'duties', 'until', '2010']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>cheryl cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zoe telford  played the police officer girlfri...</td>\n",
       "      <td>[zoe, telford, played, the, police, officer, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>mackenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>bernard leach</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>he grew up in evanston illinois the second old...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinois, the, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>de la sota</td>\n",
       "      <td>246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>he had been reelected to congress but resigned...</td>\n",
       "      <td>[he, had, been, reelected, to, congress, but, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>hell</td>\n",
       "      <td>174</td>\n",
       "      <td>henry rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>the current members of crime have also perform...</td>\n",
       "      <td>[the, current, members, of, crime, have, also,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>kitty oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>her santa fe opera debut in 2005 was as nuria ...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, was, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Pronoun  Pronoun-offset   \n",
       "0  Zoe Telford -- played the police officer girlf...     her             274  \\\n",
       "1  He grew up in Evanston, Illinois the second ol...     His             284   \n",
       "2  He had been reelected to Congress, but resigne...     his             265   \n",
       "3  The current members of Crime have also perform...     his             321   \n",
       "4  Her Santa Fe Opera debut in 2005 was as Nuria ...     She             437   \n",
       "\n",
       "                   A  A-offset                B  B-offset  A-coref  B-coref   \n",
       "0     cheryl cassidy       191          pauline       207     True    False  \\\n",
       "1          mackenzie       228    bernard leach       251     True    False   \n",
       "2            angeloz       173       de la sota       246    False     True   \n",
       "3               hell       174  henry rosenthal       336    False     True   \n",
       "4  kitty oppenheimer       219           rivera       294    False     True   \n",
       "\n",
       "                                          text_clean   \n",
       "0  zoe telford  played the police officer girlfri...  \\\n",
       "1  he grew up in evanston illinois the second old...   \n",
       "2  he had been reelected to congress but resigned...   \n",
       "3  the current members of crime have also perform...   \n",
       "4  her santa fe opera debut in 2005 was as nuria ...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [zoe, telford, played, the, police, officer, g...  \n",
       "1  [he, grew, up, in, evanston, illinois, the, se...  \n",
       "2  [he, had, been, reelected, to, congress, but, ...  \n",
       "3  [the, current, members, of, crime, have, also,...  \n",
       "4  [her, santa, fe, opera, debut, in, 2005, was, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_clean['tokenized'] = train_df_clean['text_clean'].apply(word_tokenize)\n",
    "# double check\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(train_df_clean[\"tokenized\"][0])\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(train_df_clean[\"tokenized\"][100])\n",
    "display(train_df_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos los 3 tipos de stemming y luego elegimos el que haya dado mejores resultados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter_stemmer(text):\n",
    "    \"\"\"\n",
    "        Stem words in list of tokenized words with PorterStemmer\n",
    "    \"\"\"\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    stems = [stemmer.stem(i) for i in text]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "['zoe', 'telford', 'play', 'the', 'polic', 'offic', 'girlfriend', 'of', 'simon', 'maggi', 'dump', 'by', 'simon', 'in', 'the', 'final', 'episod', 'of', 'seri', '1', 'after', 'he', 'slept', 'with', 'jenni', 'and', 'is', 'not', 'seen', 'again', 'phoeb', 'thoma', 'play', 'cheryl', 'cassidi', 'paulin', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'advic', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realis', 'thi', 'wa', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'paulin']\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "['reelect', 'in', 'the', '2007', 'elect', 'she', 'wa', 'renam', 'the', 'minist', 'of', 'intern', 'relat', 'la', 'francophoni', 'and', 'for', 'the', 'estri', 'region', 'as', 'well', 'as', 'the', 'vicechair', 'of', 'the', 'treasuri', 'board', 'follow', 'her', '2008', 'reelect', 'gagnontremblay', 'gave', 'up', 'for', 'portfolio', 'of', 'intern', 'relat', 'to', 'pierr', 'arcand', 'but', 'wa', 'given', 'the', 'posit', 'of', 'presid', 'of', 'the', 'treasuri', 'board', 'previous', 'occupi', 'by', 'moniqu', 'jeromeforget', 'who', 'wa', 'also', 'respons', 'for', 'the', 'portfolio', 'of', 'financ', 'she', 'wa', 'given', 'jeromeforget', 'govern', 'administr', 'portfolio', 'duti', 'until', '2010']\n"
     ]
    }
   ],
   "source": [
    "train_df_clean['porter_stemmer'] = train_df_clean['tokenized'].apply(lambda x: porter_stemmer(x))\n",
    "\n",
    "# double check\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(train_df_clean[\"porter_stemmer\"][0])\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(train_df_clean[\"porter_stemmer\"][100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowball_stemmer(text):\n",
    "    \"\"\"\n",
    "        Stem words in list of tokenized words with SnowballStemmer\n",
    "    \"\"\"\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    stems = [stemmer.stem(i) for i in text]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "['zoe', 'telford', 'play', 'the', 'polic', 'offic', 'girlfriend', 'of', 'simon', 'maggi', 'dump', 'by', 'simon', 'in', 'the', 'final', 'episod', 'of', 'seri', '1', 'after', 'he', 'slept', 'with', 'jenni', 'and', 'is', 'not', 'seen', 'again', 'phoeb', 'thoma', 'play', 'cheryl', 'cassidi', 'paulin', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'advic', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realis', 'this', 'was', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'paulin']\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "['reelect', 'in', 'the', '2007', 'elect', 'she', 'was', 'renam', 'the', 'minist', 'of', 'intern', 'relat', 'la', 'francophoni', 'and', 'for', 'the', 'estri', 'region', 'as', 'well', 'as', 'the', 'vicechair', 'of', 'the', 'treasuri', 'board', 'follow', 'her', '2008', 'reelect', 'gagnontremblay', 'gave', 'up', 'for', 'portfolio', 'of', 'intern', 'relat', 'to', 'pierr', 'arcand', 'but', 'was', 'given', 'the', 'posit', 'of', 'presid', 'of', 'the', 'treasuri', 'board', 'previous', 'occupi', 'by', 'moniqu', 'jeromeforget', 'who', 'was', 'also', 'respons', 'for', 'the', 'portfolio', 'of', 'financ', 'she', 'was', 'given', 'jeromeforget', 'govern', 'administr', 'portfolio', 'duti', 'until', '2010']\n"
     ]
    }
   ],
   "source": [
    "train_df_clean['snowball_stemmer'] = train_df_clean['tokenized'].apply(lambda x: snowball_stemmer(x))\n",
    "\n",
    "# double check\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(train_df_clean[\"snowball_stemmer\"][0])\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(train_df_clean[\"snowball_stemmer\"][100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LancasterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lancaster_stemmer(text):\n",
    "    \"\"\"\n",
    "        Stem words in list of tokenized words with LancasterStemmer\n",
    "    \"\"\"\n",
    "    stemmer = nltk.LancasterStemmer()\n",
    "    stems = [stemmer.stem(i) for i in text]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "['zoe', 'telford', 'play', 'the', 'pol', 'off', 'girlfriend', 'of', 'simon', 'maggy', 'dump', 'by', 'simon', 'in', 'the', 'fin', 'episod', 'of', 'sery', '1', 'aft', 'he', 'slept', 'with', 'jenny', 'and', 'is', 'not', 'seen', 'again', 'phoeb', 'thoma', 'play', 'cheryl', 'cassidy', 'paulin', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'adv', 'aft', 'he', 'would', 'not', 'hav', 'sex', 'with', 'her', 'but', 'lat', 'real', 'thi', 'was', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'paulin']\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "['reelect', 'in', 'the', '2007', 'elect', 'she', 'was', 'renam', 'the', 'min', 'of', 'intern', 'rel', 'la', 'francophony', 'and', 'for', 'the', 'estry', 'reg', 'as', 'wel', 'as', 'the', 'vicechair', 'of', 'the', 'treasury', 'board', 'follow', 'her', '2008', 'reelect', 'gagnontremblay', 'gav', 'up', 'for', 'portfolio', 'of', 'intern', 'rel', 'to', 'pier', 'arcand', 'but', 'was', 'giv', 'the', 'posit', 'of', 'presid', 'of', 'the', 'treasury', 'board', 'prevy', 'occupy', 'by', 'mon', 'jeromeforget', 'who', 'was', 'also', 'respons', 'for', 'the', 'portfolio', 'of', 'fin', 'she', 'was', 'giv', 'jeromeforget', 'govern', 'admin', 'portfolio', 'duty', 'until', '2010']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>porter_stemmer</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>cheryl cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zoe telford  played the police officer girlfri...</td>\n",
       "      <td>[zoe, telford, played, the, police, officer, g...</td>\n",
       "      <td>[zoe, telford, play, the, polic, offic, girlfr...</td>\n",
       "      <td>[zoe, telford, play, the, polic, offic, girlfr...</td>\n",
       "      <td>[zoe, telford, play, the, pol, off, girlfriend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>mackenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>bernard leach</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>he grew up in evanston illinois the second old...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinois, the, se...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinoi, the, sec...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinoi, the, sec...</td>\n",
       "      <td>[he, grew, up, in, evanston, illino, the, seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>de la sota</td>\n",
       "      <td>246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>he had been reelected to congress but resigned...</td>\n",
       "      <td>[he, had, been, reelected, to, congress, but, ...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>hell</td>\n",
       "      <td>174</td>\n",
       "      <td>henry rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>the current members of crime have also perform...</td>\n",
       "      <td>[the, current, members, of, crime, have, also,...</td>\n",
       "      <td>[the, current, member, of, crime, have, also, ...</td>\n",
       "      <td>[the, current, member, of, crime, have, also, ...</td>\n",
       "      <td>[the, cur, memb, of, crim, hav, also, perform,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>kitty oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>her santa fe opera debut in 2005 was as nuria ...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, was, ...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, wa, a...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, was, ...</td>\n",
       "      <td>[her, sant, fe, oper, debut, in, 2005, was, as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Pronoun  Pronoun-offset   \n",
       "0  Zoe Telford -- played the police officer girlf...     her             274  \\\n",
       "1  He grew up in Evanston, Illinois the second ol...     His             284   \n",
       "2  He had been reelected to Congress, but resigne...     his             265   \n",
       "3  The current members of Crime have also perform...     his             321   \n",
       "4  Her Santa Fe Opera debut in 2005 was as Nuria ...     She             437   \n",
       "\n",
       "                   A  A-offset                B  B-offset  A-coref  B-coref   \n",
       "0     cheryl cassidy       191          pauline       207     True    False  \\\n",
       "1          mackenzie       228    bernard leach       251     True    False   \n",
       "2            angeloz       173       de la sota       246    False     True   \n",
       "3               hell       174  henry rosenthal       336    False     True   \n",
       "4  kitty oppenheimer       219           rivera       294    False     True   \n",
       "\n",
       "                                          text_clean   \n",
       "0  zoe telford  played the police officer girlfri...  \\\n",
       "1  he grew up in evanston illinois the second old...   \n",
       "2  he had been reelected to congress but resigned...   \n",
       "3  the current members of crime have also perform...   \n",
       "4  her santa fe opera debut in 2005 was as nuria ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0  [zoe, telford, played, the, police, officer, g...  \\\n",
       "1  [he, grew, up, in, evanston, illinois, the, se...   \n",
       "2  [he, had, been, reelected, to, congress, but, ...   \n",
       "3  [the, current, members, of, crime, have, also,...   \n",
       "4  [her, santa, fe, opera, debut, in, 2005, was, ...   \n",
       "\n",
       "                                      porter_stemmer   \n",
       "0  [zoe, telford, play, the, polic, offic, girlfr...  \\\n",
       "1  [he, grew, up, in, evanston, illinoi, the, sec...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "3  [the, current, member, of, crime, have, also, ...   \n",
       "4  [her, santa, fe, opera, debut, in, 2005, wa, a...   \n",
       "\n",
       "                                    snowball_stemmer   \n",
       "0  [zoe, telford, play, the, polic, offic, girlfr...  \\\n",
       "1  [he, grew, up, in, evanston, illinoi, the, sec...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "3  [the, current, member, of, crime, have, also, ...   \n",
       "4  [her, santa, fe, opera, debut, in, 2005, was, ...   \n",
       "\n",
       "                                   lancaster_stemmer  \n",
       "0  [zoe, telford, play, the, pol, off, girlfriend...  \n",
       "1  [he, grew, up, in, evanston, illino, the, seco...  \n",
       "2  [he, had, been, reelect, to, congress, but, re...  \n",
       "3  [the, cur, memb, of, crim, hav, also, perform,...  \n",
       "4  [her, sant, fe, oper, debut, in, 2005, was, as...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_clean['lancaster_stemmer'] = train_df_clean['tokenized'].apply(lambda x: lancaster_stemmer(x))\n",
    "\n",
    "# double check\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(train_df_clean[\"lancaster_stemmer\"][0])\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(train_df_clean[\"lancaster_stemmer\"][100])\n",
    "display(train_df_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming techniques comparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "\n",
      "\n",
      "['zoe', 'telford', 'play', 'the', 'polic', 'offic', 'girlfriend', 'of', 'simon', 'maggi', 'dump', 'by', 'simon', 'in', 'the', 'final', 'episod', 'of', 'seri', '1', 'after', 'he', 'slept', 'with', 'jenni', 'and', 'is', 'not', 'seen', 'again', 'phoeb', 'thoma', 'play', 'cheryl', 'cassidi', 'paulin', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'advic', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realis', 'thi', 'wa', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'paulin']\n",
      "\n",
      "\n",
      "['zoe', 'telford', 'play', 'the', 'polic', 'offic', 'girlfriend', 'of', 'simon', 'maggi', 'dump', 'by', 'simon', 'in', 'the', 'final', 'episod', 'of', 'seri', '1', 'after', 'he', 'slept', 'with', 'jenni', 'and', 'is', 'not', 'seen', 'again', 'phoeb', 'thoma', 'play', 'cheryl', 'cassidi', 'paulin', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'advic', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realis', 'this', 'was', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'paulin']\n",
      "\n",
      "\n",
      "['zoe', 'telford', 'play', 'the', 'pol', 'off', 'girlfriend', 'of', 'simon', 'maggy', 'dump', 'by', 'simon', 'in', 'the', 'fin', 'episod', 'of', 'sery', '1', 'aft', 'he', 'slept', 'with', 'jenny', 'and', 'is', 'not', 'seen', 'again', 'phoeb', 'thoma', 'play', 'cheryl', 'cassidy', 'paulin', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'adv', 'aft', 'he', 'would', 'not', 'hav', 'sex', 'with', 'her', 'but', 'lat', 'real', 'thi', 'was', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'paulin']\n"
     ]
    }
   ],
   "source": [
    "print(train_df_clean[\"Text\"][0])\n",
    "print(\"\\n\")\n",
    "print(train_df_clean[\"porter_stemmer\"][0])\n",
    "print(\"\\n\")\n",
    "print(train_df_clean[\"snowball_stemmer\"][0])\n",
    "print(\"\\n\")\n",
    "print(train_df_clean[\"lancaster_stemmer\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Según los resultados obtenidos, parece que el Porter stemmer y el Snowball stemmer producen resultados muy similares. \n",
    "\n",
    "- Sin embargo, el Lancaster stemmer tiende a ser más agresivo en la separación de palabras, lo que da como resultado palabras más cortas y menos reconocibles. \n",
    "\n",
    "- Por tanto, finalmente elegimos el Snowball stemmer, que es un poco más agresivo que el Porter stemmer pero menos agresivo que el Lancaster stemmer, y en nustro caso es el que mejor resultado ha dado. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging (POS Tagging):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bernatsort/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoS tags\n",
    "train_df_clean['pos_tags'] = train_df_clean['tokenized'].apply(nltk.tag.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenized:\n",
      "['zoe', 'telford', 'played', 'the', 'police', 'officer', 'girlfriend', 'of', 'simon', 'maggie', 'dumped', 'by', 'simon', 'in', 'the', 'final', 'episode', 'of', 'series', '1', 'after', 'he', 'slept', 'with', 'jenny', 'and', 'is', 'not', 'seen', 'again', 'phoebe', 'thomas', 'played', 'cheryl', 'cassidy', 'paulines', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simons', 'class', 'dumped', 'her', 'boyfriend', 'following', 'simons', 'advice', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realised', 'this', 'was', 'due', 'to', 'him', 'catching', 'crabs', 'off', 'her', 'friend', 'pauline']\n",
      "\n",
      "pos_tags:\n",
      "[('zoe', 'NN'), ('telford', 'NN'), ('played', 'VBD'), ('the', 'DT'), ('police', 'NN'), ('officer', 'NN'), ('girlfriend', 'NN'), ('of', 'IN'), ('simon', 'JJ'), ('maggie', 'NN'), ('dumped', 'VBN'), ('by', 'IN'), ('simon', 'NN'), ('in', 'IN'), ('the', 'DT'), ('final', 'JJ'), ('episode', 'NN'), ('of', 'IN'), ('series', 'NN'), ('1', 'CD'), ('after', 'IN'), ('he', 'PRP'), ('slept', 'VBD'), ('with', 'IN'), ('jenny', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('not', 'RB'), ('seen', 'VBN'), ('again', 'RB'), ('phoebe', 'JJ'), ('thomas', 'NN'), ('played', 'VBD'), ('cheryl', 'NN'), ('cassidy', 'NN'), ('paulines', 'NNS'), ('friend', 'NN'), ('and', 'CC'), ('also', 'RB'), ('a', 'DT'), ('year', 'NN'), ('11', 'CD'), ('pupil', 'NN'), ('in', 'IN'), ('simons', 'NNS'), ('class', 'NN'), ('dumped', 'VBD'), ('her', 'PRP$'), ('boyfriend', 'NN'), ('following', 'VBG'), ('simons', 'NNS'), ('advice', 'RB'), ('after', 'IN'), ('he', 'PRP'), ('would', 'MD'), ('not', 'RB'), ('have', 'VB'), ('sex', 'NN'), ('with', 'IN'), ('her', 'PRP$'), ('but', 'CC'), ('later', 'RB'), ('realised', 'VBD'), ('this', 'DT'), ('was', 'VBD'), ('due', 'JJ'), ('to', 'TO'), ('him', 'PRP'), ('catching', 'VBG'), ('crabs', 'NNS'), ('off', 'IN'), ('her', 'PRP$'), ('friend', 'NN'), ('pauline', 'NN')]\n",
      "\n",
      "\n",
      "\n",
      "tokenized:\n",
      "['reelected', 'in', 'the', '2007', 'election', 'she', 'was', 'renamed', 'the', 'minister', 'of', 'international', 'relations', 'la', 'francophonie', 'and', 'for', 'the', 'estrie', 'region', 'as', 'well', 'as', 'the', 'vicechair', 'of', 'the', 'treasury', 'board', 'following', 'her', '2008', 'reelection', 'gagnontremblay', 'gave', 'up', 'for', 'portfolio', 'of', 'international', 'relations', 'to', 'pierre', 'arcand', 'but', 'was', 'given', 'the', 'position', 'of', 'president', 'of', 'the', 'treasury', 'board', 'previously', 'occupied', 'by', 'monique', 'jeromeforget', 'who', 'was', 'also', 'responsible', 'for', 'the', 'portfolio', 'of', 'finances', 'she', 'was', 'given', 'jeromeforgets', 'government', 'administration', 'portfolio', 'duties', 'until', '2010']\n",
      "\n",
      "pos_tags:\n",
      "[('reelected', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('2007', 'CD'), ('election', 'NN'), ('she', 'PRP'), ('was', 'VBD'), ('renamed', 'VBN'), ('the', 'DT'), ('minister', 'NN'), ('of', 'IN'), ('international', 'JJ'), ('relations', 'NNS'), ('la', 'VBP'), ('francophonie', 'NN'), ('and', 'CC'), ('for', 'IN'), ('the', 'DT'), ('estrie', 'JJ'), ('region', 'NN'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('the', 'DT'), ('vicechair', 'NN'), ('of', 'IN'), ('the', 'DT'), ('treasury', 'NN'), ('board', 'NN'), ('following', 'VBG'), ('her', 'PRP$'), ('2008', 'CD'), ('reelection', 'NN'), ('gagnontremblay', 'NN'), ('gave', 'VBD'), ('up', 'RP'), ('for', 'IN'), ('portfolio', 'NN'), ('of', 'IN'), ('international', 'JJ'), ('relations', 'NNS'), ('to', 'TO'), ('pierre', 'VB'), ('arcand', 'NN'), ('but', 'CC'), ('was', 'VBD'), ('given', 'VBN'), ('the', 'DT'), ('position', 'NN'), ('of', 'IN'), ('president', 'NN'), ('of', 'IN'), ('the', 'DT'), ('treasury', 'NN'), ('board', 'NN'), ('previously', 'RB'), ('occupied', 'VBN'), ('by', 'IN'), ('monique', 'NN'), ('jeromeforget', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('also', 'RB'), ('responsible', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('portfolio', 'NN'), ('of', 'IN'), ('finances', 'NNS'), ('she', 'PRP'), ('was', 'VBD'), ('given', 'VBN'), ('jeromeforgets', 'NNS'), ('government', 'NN'), ('administration', 'NN'), ('portfolio', 'NN'), ('duties', 'NNS'), ('until', 'IN'), ('2010', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "print(\"\\ntokenized:\")\n",
    "print(train_df_clean[\"tokenized\"][0])\n",
    "print(\"\\npos_tags:\")\n",
    "print(train_df_clean[\"pos_tags\"][0])\n",
    "print(\"\\n\")\n",
    "print(\"\\ntokenized:\")\n",
    "print(train_df_clean[\"tokenized\"][100])\n",
    "print(\"\\npos_tags:\")\n",
    "print(train_df_clean[\"pos_tags\"][100])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ahora podemos utilizar estas etiquetas para aplicar la lematización."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dado que la lematización es un proceso más sofisticado que tiene en cuenta el contexto gramatical y semántico, es recomendable aplicarla después de la tokenización. Esto asegurará que las palabras se reduzcan a su forma base correcta y se conserven las relaciones léxicas y semánticas adecuadas en el texto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bernatsort/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos todas las etiquetas del texto: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(zoe, NN), (telford, NN), (played, VBD), (the...\n",
       "1       [(he, PRP), (grew, VBD), (up, RP), (in, IN), (...\n",
       "2       [(he, PRP), (had, VBD), (been, VBN), (reelecte...\n",
       "3       [(the, DT), (current, JJ), (members, NNS), (of...\n",
       "4       [(her, PRP$), (santa, NN), (fe, NN), (opera, N...\n",
       "                              ...                        \n",
       "1995    [(fayes, NNS), (third, JJ), (husband, NN), (pa...\n",
       "1996    [(the, DT), (plot, NN), (of, IN), (the, DT), (...\n",
       "1997    [(grant, NN), (played, VBD), (the, DT), (part,...\n",
       "1998    [(the, DT), (fashion, NN), (house, NN), (speci...\n",
       "1999    [(watkins, NNS), (was, VBD), (a, DT), (close, ...\n",
       "Name: pos_tags, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean['pos_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_pos_tags(df, pos_tags_col = \"pos_tags\"):\n",
    "    # Crear una lista para almacenar todas las etiquetas\n",
    "    all_tags = []\n",
    "\n",
    "    # Iterar sobre los elementos de la columna 'pos_tags'\n",
    "    for tags in df[pos_tags_col]:\n",
    "        # Obtener las etiquetas de cada par (palabra, etiqueta)\n",
    "        tag_list = [tag[1] for tag in tags]\n",
    "        # Agregar las etiquetas a la lista general: \n",
    "            # extend() para agregar múltiples elementos a una lista\n",
    "        all_tags.extend(tag_list)\n",
    "\n",
    "    # Obtener las etiquetas únicas sin repetidos\n",
    "    unique_tags = set(all_tags)\n",
    "\n",
    "    # Imprimir las etiquetas únicas\n",
    "    return unique_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VBZ', 'RP', 'NNP', 'POS', 'CC', 'DT', 'NN', 'VBD', 'FW', 'RBS', '$', 'VB', 'WP$', 'JJS', 'TO', 'MD', 'VBN', 'WRB', 'PRP', 'PRP$', 'RBR', 'NNS', 'WP', 'VBP', 'RB', 'PDT', 'JJ', 'IN', 'VBG', 'NNPS', 'EX', 'JJR', 'CD', 'WDT'}\n"
     ]
    }
   ],
   "source": [
    "# all unique tags\n",
    "print(get_unique_pos_tags(train_df_clean))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que mapee las etiquetas POS de NLTK a las etiquetas POS de WordNet. Esto es necesario para que el lematizador pueda interpretar correctamente las etiquetas POS:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *WordNet only contains \"open-class words\": nouns, verbs, adjectives, and adverbs. Thus, excluded words include determiners, prepositions, pronouns, conjunctions, and particles.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('POS'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('RB'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('CD'):\n",
    "        return wordnet.NOUN   \n",
    "    else:\n",
    "        return wordnet.NOUN  # Por defecto, asumimos sustantivos si la etiqueta POS no coincide con las anteriores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_clean['wordnet_pos'] = train_df_clean['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(zoe, n), (telford, n), (played, v), (the, n)...\n",
       "1       [(he, n), (grew, v), (up, n), (in, n), (evanst...\n",
       "2       [(he, n), (had, v), (been, v), (reelected, v),...\n",
       "3       [(the, n), (current, a), (members, n), (of, n)...\n",
       "4       [(her, n), (santa, n), (fe, n), (opera, n), (d...\n",
       "                              ...                        \n",
       "1995    [(fayes, n), (third, a), (husband, n), (paul, ...\n",
       "1996    [(the, n), (plot, n), (of, n), (the, n), (film...\n",
       "1997    [(grant, n), (played, v), (the, n), (part, n),...\n",
       "1998    [(the, n), (fashion, n), (house, n), (speciali...\n",
       "1999    [(watkins, n), (was, v), (a, n), (close, a), (...\n",
       "Name: wordnet_pos, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean['wordnet_pos']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el word lemmatizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_word_pos(text):\n",
    "    \"\"\"\n",
    "    Lemmatize the tokenized words (with PoS)\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With PoS\n",
    "train_df_clean['lemmatize_word_pos'] = train_df_clean['wordnet_pos'].apply(lambda x: lemmatize_word_pos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>porter_stemmer</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "      <th>lemmatize_word</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "      <th>lemmatize_word_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>cheryl cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zoe telford  played the police officer girlfri...</td>\n",
       "      <td>[zoe, telford, played, the, police, officer, g...</td>\n",
       "      <td>[zoe, telford, play, the, polic, offic, girlfr...</td>\n",
       "      <td>[zoe, telford, play, the, polic, offic, girlfr...</td>\n",
       "      <td>[zoe, telford, play, the, pol, off, girlfriend...</td>\n",
       "      <td>[zoe, telford, played, the, police, officer, g...</td>\n",
       "      <td>[(zoe, NN), (telford, NN), (played, VBD), (the...</td>\n",
       "      <td>[(zoe, n), (telford, n), (played, v), (the, n)...</td>\n",
       "      <td>[zoe, telford, play, the, police, officer, gir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>mackenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>bernard leach</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>he grew up in evanston illinois the second old...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinois, the, se...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinoi, the, sec...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinoi, the, sec...</td>\n",
       "      <td>[he, grew, up, in, evanston, illino, the, seco...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinois, the, se...</td>\n",
       "      <td>[(he, PRP), (grew, VBD), (up, RP), (in, IN), (...</td>\n",
       "      <td>[(he, n), (grew, v), (up, n), (in, n), (evanst...</td>\n",
       "      <td>[he, grow, up, in, evanston, illinois, the, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>de la sota</td>\n",
       "      <td>246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>he had been reelected to congress but resigned...</td>\n",
       "      <td>[he, had, been, reelected, to, congress, but, ...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelected, to, congress, but, ...</td>\n",
       "      <td>[(he, PRP), (had, VBD), (been, VBN), (reelecte...</td>\n",
       "      <td>[(he, n), (had, v), (been, v), (reelected, v),...</td>\n",
       "      <td>[he, have, be, reelect, to, congress, but, res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Pronoun  Pronoun-offset   \n",
       "0  Zoe Telford -- played the police officer girlf...     her             274  \\\n",
       "1  He grew up in Evanston, Illinois the second ol...     His             284   \n",
       "2  He had been reelected to Congress, but resigne...     his             265   \n",
       "\n",
       "                A  A-offset              B  B-offset  A-coref  B-coref   \n",
       "0  cheryl cassidy       191        pauline       207     True    False  \\\n",
       "1       mackenzie       228  bernard leach       251     True    False   \n",
       "2         angeloz       173     de la sota       246    False     True   \n",
       "\n",
       "                                          text_clean   \n",
       "0  zoe telford  played the police officer girlfri...  \\\n",
       "1  he grew up in evanston illinois the second old...   \n",
       "2  he had been reelected to congress but resigned...   \n",
       "\n",
       "                                           tokenized   \n",
       "0  [zoe, telford, played, the, police, officer, g...  \\\n",
       "1  [he, grew, up, in, evanston, illinois, the, se...   \n",
       "2  [he, had, been, reelected, to, congress, but, ...   \n",
       "\n",
       "                                      porter_stemmer   \n",
       "0  [zoe, telford, play, the, polic, offic, girlfr...  \\\n",
       "1  [he, grew, up, in, evanston, illinoi, the, sec...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "\n",
       "                                    snowball_stemmer   \n",
       "0  [zoe, telford, play, the, polic, offic, girlfr...  \\\n",
       "1  [he, grew, up, in, evanston, illinoi, the, sec...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "\n",
       "                                   lancaster_stemmer   \n",
       "0  [zoe, telford, play, the, pol, off, girlfriend...  \\\n",
       "1  [he, grew, up, in, evanston, illino, the, seco...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "\n",
       "                                      lemmatize_word   \n",
       "0  [zoe, telford, played, the, police, officer, g...  \\\n",
       "1  [he, grew, up, in, evanston, illinois, the, se...   \n",
       "2  [he, had, been, reelected, to, congress, but, ...   \n",
       "\n",
       "                                            pos_tags   \n",
       "0  [(zoe, NN), (telford, NN), (played, VBD), (the...  \\\n",
       "1  [(he, PRP), (grew, VBD), (up, RP), (in, IN), (...   \n",
       "2  [(he, PRP), (had, VBD), (been, VBN), (reelecte...   \n",
       "\n",
       "                                         wordnet_pos   \n",
       "0  [(zoe, n), (telford, n), (played, v), (the, n)...  \\\n",
       "1  [(he, n), (grew, v), (up, n), (in, n), (evanst...   \n",
       "2  [(he, n), (had, v), (been, v), (reelected, v),...   \n",
       "\n",
       "                                  lemmatize_word_pos  \n",
       "0  [zoe, telford, play, the, police, officer, gir...  \n",
       "1  [he, grow, up, in, evanston, illinois, the, se...  \n",
       "2  [he, have, be, reelect, to, congress, but, res...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_word(text):\n",
    "    \"\"\"\n",
    "    Lemmatize the tokenized words (without PoS)\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without PoS\n",
    "train_df_clean['lemmatize_word'] = train_df_clean['tokenized'].apply(lambda x: lemmatize_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>porter_stemmer</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "      <th>lemmatize_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>cheryl cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zoe telford  played the police officer girlfri...</td>\n",
       "      <td>[zoe, telford, played, the, police, officer, g...</td>\n",
       "      <td>[zoe, telford, play, the, polic, offic, girlfr...</td>\n",
       "      <td>[zoe, telford, play, the, polic, offic, girlfr...</td>\n",
       "      <td>[zoe, telford, play, the, pol, off, girlfriend...</td>\n",
       "      <td>[zoe, telford, played, the, police, officer, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>mackenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>bernard leach</td>\n",
       "      <td>251</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>he grew up in evanston illinois the second old...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinois, the, se...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinoi, the, sec...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinoi, the, sec...</td>\n",
       "      <td>[he, grew, up, in, evanston, illino, the, seco...</td>\n",
       "      <td>[he, grew, up, in, evanston, illinois, the, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>de la sota</td>\n",
       "      <td>246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>he had been reelected to congress but resigned...</td>\n",
       "      <td>[he, had, been, reelected, to, congress, but, ...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelect, to, congress, but, re...</td>\n",
       "      <td>[he, had, been, reelected, to, congress, but, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>hell</td>\n",
       "      <td>174</td>\n",
       "      <td>henry rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>the current members of crime have also perform...</td>\n",
       "      <td>[the, current, members, of, crime, have, also,...</td>\n",
       "      <td>[the, current, member, of, crime, have, also, ...</td>\n",
       "      <td>[the, current, member, of, crime, have, also, ...</td>\n",
       "      <td>[the, cur, memb, of, crim, hav, also, perform,...</td>\n",
       "      <td>[the, current, member, of, crime, have, also, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>kitty oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>her santa fe opera debut in 2005 was as nuria ...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, was, ...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, wa, a...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, was, ...</td>\n",
       "      <td>[her, sant, fe, oper, debut, in, 2005, was, as...</td>\n",
       "      <td>[her, santa, fe, opera, debut, in, 2005, wa, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Pronoun  Pronoun-offset   \n",
       "0  Zoe Telford -- played the police officer girlf...     her             274  \\\n",
       "1  He grew up in Evanston, Illinois the second ol...     His             284   \n",
       "2  He had been reelected to Congress, but resigne...     his             265   \n",
       "3  The current members of Crime have also perform...     his             321   \n",
       "4  Her Santa Fe Opera debut in 2005 was as Nuria ...     She             437   \n",
       "\n",
       "                   A  A-offset                B  B-offset  A-coref  B-coref   \n",
       "0     cheryl cassidy       191          pauline       207     True    False  \\\n",
       "1          mackenzie       228    bernard leach       251     True    False   \n",
       "2            angeloz       173       de la sota       246    False     True   \n",
       "3               hell       174  henry rosenthal       336    False     True   \n",
       "4  kitty oppenheimer       219           rivera       294    False     True   \n",
       "\n",
       "                                          text_clean   \n",
       "0  zoe telford  played the police officer girlfri...  \\\n",
       "1  he grew up in evanston illinois the second old...   \n",
       "2  he had been reelected to congress but resigned...   \n",
       "3  the current members of crime have also perform...   \n",
       "4  her santa fe opera debut in 2005 was as nuria ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0  [zoe, telford, played, the, police, officer, g...  \\\n",
       "1  [he, grew, up, in, evanston, illinois, the, se...   \n",
       "2  [he, had, been, reelected, to, congress, but, ...   \n",
       "3  [the, current, members, of, crime, have, also,...   \n",
       "4  [her, santa, fe, opera, debut, in, 2005, was, ...   \n",
       "\n",
       "                                      porter_stemmer   \n",
       "0  [zoe, telford, play, the, polic, offic, girlfr...  \\\n",
       "1  [he, grew, up, in, evanston, illinoi, the, sec...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "3  [the, current, member, of, crime, have, also, ...   \n",
       "4  [her, santa, fe, opera, debut, in, 2005, wa, a...   \n",
       "\n",
       "                                    snowball_stemmer   \n",
       "0  [zoe, telford, play, the, polic, offic, girlfr...  \\\n",
       "1  [he, grew, up, in, evanston, illinoi, the, sec...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "3  [the, current, member, of, crime, have, also, ...   \n",
       "4  [her, santa, fe, opera, debut, in, 2005, was, ...   \n",
       "\n",
       "                                   lancaster_stemmer   \n",
       "0  [zoe, telford, play, the, pol, off, girlfriend...  \\\n",
       "1  [he, grew, up, in, evanston, illino, the, seco...   \n",
       "2  [he, had, been, reelect, to, congress, but, re...   \n",
       "3  [the, cur, memb, of, crim, hav, also, perform,...   \n",
       "4  [her, sant, fe, oper, debut, in, 2005, was, as...   \n",
       "\n",
       "                                      lemmatize_word  \n",
       "0  [zoe, telford, played, the, police, officer, g...  \n",
       "1  [he, grew, up, in, evanston, illinois, the, se...  \n",
       "2  [he, had, been, reelected, to, congress, but, ...  \n",
       "3  [the, current, member, of, crime, have, also, ...  \n",
       "4  [her, santa, fe, opera, debut, in, 2005, wa, a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# double check\n",
    "display(train_df_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization with PoS vs Lemmatization without PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original:\n",
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "\n",
      "lemmatization PoS:\n",
      "['zoe', 'telford', 'play', 'the', 'police', 'officer', 'girlfriend', 'of', 'simon', 'maggie', 'dump', 'by', 'simon', 'in', 'the', 'final', 'episode', 'of', 'series', '1', 'after', 'he', 'sleep', 'with', 'jenny', 'and', 'be', 'not', 'see', 'again', 'phoebe', 'thomas', 'play', 'cheryl', 'cassidy', 'paulines', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'advice', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realise', 'this', 'be', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'pauline']\n",
      "\n",
      "lemmatization no PoS:\n",
      "['zoe', 'telford', 'played', 'the', 'police', 'officer', 'girlfriend', 'of', 'simon', 'maggie', 'dumped', 'by', 'simon', 'in', 'the', 'final', 'episode', 'of', 'series', '1', 'after', 'he', 'slept', 'with', 'jenny', 'and', 'is', 'not', 'seen', 'again', 'phoebe', 'thomas', 'played', 'cheryl', 'cassidy', 'paulines', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dumped', 'her', 'boyfriend', 'following', 'simon', 'advice', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realised', 'this', 'wa', 'due', 'to', 'him', 'catching', 'crab', 'off', 'her', 'friend', 'pauline']\n",
      "\n",
      "\n",
      "\n",
      "Original:\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "\n",
      "lemmatization PoS:\n",
      "['reelect', 'in', 'the', '2007', 'election', 'she', 'be', 'rename', 'the', 'minister', 'of', 'international', 'relation', 'la', 'francophonie', 'and', 'for', 'the', 'estrie', 'region', 'as', 'well', 'a', 'the', 'vicechair', 'of', 'the', 'treasury', 'board', 'follow', 'her', '2008', 'reelection', 'gagnontremblay', 'give', 'up', 'for', 'portfolio', 'of', 'international', 'relation', 'to', 'pierre', 'arcand', 'but', 'be', 'give', 'the', 'position', 'of', 'president', 'of', 'the', 'treasury', 'board', 'previously', 'occupy', 'by', 'monique', 'jeromeforget', 'who', 'be', 'also', 'responsible', 'for', 'the', 'portfolio', 'of', 'finance', 'she', 'be', 'give', 'jeromeforgets', 'government', 'administration', 'portfolio', 'duty', 'until', '2010']\n",
      "\n",
      "lemmatization no PoS:\n",
      "['reelected', 'in', 'the', '2007', 'election', 'she', 'wa', 'renamed', 'the', 'minister', 'of', 'international', 'relation', 'la', 'francophonie', 'and', 'for', 'the', 'estrie', 'region', 'a', 'well', 'a', 'the', 'vicechair', 'of', 'the', 'treasury', 'board', 'following', 'her', '2008', 'reelection', 'gagnontremblay', 'gave', 'up', 'for', 'portfolio', 'of', 'international', 'relation', 'to', 'pierre', 'arcand', 'but', 'wa', 'given', 'the', 'position', 'of', 'president', 'of', 'the', 'treasury', 'board', 'previously', 'occupied', 'by', 'monique', 'jeromeforget', 'who', 'wa', 'also', 'responsible', 'for', 'the', 'portfolio', 'of', 'finance', 'she', 'wa', 'given', 'jeromeforgets', 'government', 'administration', 'portfolio', 'duty', 'until', '2010']\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "print(\"\\nOriginal:\")\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(\"\\nlemmatization PoS:\")\n",
    "print(train_df_clean[\"lemmatize_word_pos\"][0])\n",
    "print(\"\\nlemmatization no PoS:\")\n",
    "print(train_df_clean[\"lemmatize_word\"][0])\n",
    "print(\"\\n\")\n",
    "print(\"\\nOriginal:\")\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(\"\\nlemmatization PoS:\")\n",
    "print(train_df_clean[\"lemmatize_word_pos\"][100])\n",
    "print(\"\\nlemmatization no PoS:\")\n",
    "print(train_df_clean[\"lemmatize_word\"][100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La lematización consiste en encontrar la raíz o lema de una palabra, y el lema de una palabra puede depender de su categoría gramatical.\n",
    "- Al disponer de etiquetas de PoS confiables y precisas, podemos utilizarlas para mejorar la lematización y obtener resultados más precisos.\n",
    "- Observamos que la lematización con PoS da mejores resultados que sin el PoS. \n",
    "- Por tanto, nos quedamos con la lematización con PoS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming (snowball_stemmer) vs Lemmatization with PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original:\n",
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\n",
      "\n",
      "snowball_stemmer:\n",
      "['zoe', 'telford', 'play', 'the', 'polic', 'offic', 'girlfriend', 'of', 'simon', 'maggi', 'dump', 'by', 'simon', 'in', 'the', 'final', 'episod', 'of', 'seri', '1', 'after', 'he', 'slept', 'with', 'jenni', 'and', 'is', 'not', 'seen', 'again', 'phoeb', 'thoma', 'play', 'cheryl', 'cassidi', 'paulin', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'advic', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realis', 'this', 'was', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'paulin']\n",
      "\n",
      "lemmatization PoS:\n",
      "['zoe', 'telford', 'play', 'the', 'police', 'officer', 'girlfriend', 'of', 'simon', 'maggie', 'dump', 'by', 'simon', 'in', 'the', 'final', 'episode', 'of', 'series', '1', 'after', 'he', 'sleep', 'with', 'jenny', 'and', 'be', 'not', 'see', 'again', 'phoebe', 'thomas', 'play', 'cheryl', 'cassidy', 'paulines', 'friend', 'and', 'also', 'a', 'year', '11', 'pupil', 'in', 'simon', 'class', 'dump', 'her', 'boyfriend', 'follow', 'simon', 'advice', 'after', 'he', 'would', 'not', 'have', 'sex', 'with', 'her', 'but', 'later', 'realise', 'this', 'be', 'due', 'to', 'him', 'catch', 'crab', 'off', 'her', 'friend', 'pauline']\n",
      "\n",
      "\n",
      "\n",
      "Original:\n",
      "Re-elected in the 2007 election, she was re-named the Minister of International Relations, La Francophonie and for the Estrie Region as well as the Vice-Chair of the Treasury Board. Following her 2008 re-election, Gagnon-Tremblay gave up for portfolio of International Relations to Pierre Arcand but was given the position of President of the Treasury Board previously occupied by Monique Jerome-Forget who was also responsible for the portfolio of finances. She was given Jerome-Forget's government administration portfolio duties until 2010.\n",
      "\n",
      "snowball_stemmer:\n",
      "['reelect', 'in', 'the', '2007', 'elect', 'she', 'was', 'renam', 'the', 'minist', 'of', 'intern', 'relat', 'la', 'francophoni', 'and', 'for', 'the', 'estri', 'region', 'as', 'well', 'as', 'the', 'vicechair', 'of', 'the', 'treasuri', 'board', 'follow', 'her', '2008', 'reelect', 'gagnontremblay', 'gave', 'up', 'for', 'portfolio', 'of', 'intern', 'relat', 'to', 'pierr', 'arcand', 'but', 'was', 'given', 'the', 'posit', 'of', 'presid', 'of', 'the', 'treasuri', 'board', 'previous', 'occupi', 'by', 'moniqu', 'jeromeforget', 'who', 'was', 'also', 'respons', 'for', 'the', 'portfolio', 'of', 'financ', 'she', 'was', 'given', 'jeromeforget', 'govern', 'administr', 'portfolio', 'duti', 'until', '2010']\n",
      "\n",
      "lemmatization PoS:\n",
      "['reelect', 'in', 'the', '2007', 'election', 'she', 'be', 'rename', 'the', 'minister', 'of', 'international', 'relation', 'la', 'francophonie', 'and', 'for', 'the', 'estrie', 'region', 'as', 'well', 'a', 'the', 'vicechair', 'of', 'the', 'treasury', 'board', 'follow', 'her', '2008', 'reelection', 'gagnontremblay', 'give', 'up', 'for', 'portfolio', 'of', 'international', 'relation', 'to', 'pierre', 'arcand', 'but', 'be', 'give', 'the', 'position', 'of', 'president', 'of', 'the', 'treasury', 'board', 'previously', 'occupy', 'by', 'monique', 'jeromeforget', 'who', 'be', 'also', 'responsible', 'for', 'the', 'portfolio', 'of', 'finance', 'she', 'be', 'give', 'jeromeforgets', 'government', 'administration', 'portfolio', 'duty', 'until', '2010']\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "print(\"\\nOriginal:\")\n",
    "print(train_df_clean[\"Text\"][0])\n",
    "print(\"\\nsnowball_stemmer:\")\n",
    "print(train_df_clean[\"snowball_stemmer\"][0])\n",
    "print(\"\\nlemmatization PoS:\")\n",
    "print(train_df_clean[\"lemmatize_word_pos\"][0])\n",
    "print(\"\\n\")\n",
    "print(\"\\nOriginal:\")\n",
    "print(train_df_clean[\"Text\"][100])\n",
    "print(\"\\nsnowball_stemmer:\")\n",
    "print(train_df_clean[\"snowball_stemmer\"][100])\n",
    "print(\"\\nlemmatization PoS:\")\n",
    "print(train_df_clean[\"lemmatize_word_pos\"][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como la precisión y la coherencia lingüística son importantes en nuestro problema, la lematización puede ser más apropiada, ya que considera el contexto gramatical y semántico de las palabras. \n",
    "\n",
    "- Por otro lado, el stemming es un proceso más simple que busca eliminar sufijos y prefijos de las palabras para obtener una forma truncada. El stemming puede producir resultados que no corresponden a palabras reales y puede no ser tan efectivo para capturar la forma base de las palabras.\n",
    "\n",
    "- En nuestro caso observamos que, efectivamente, la lematización con PoS funciona mejor que el stemming. \n",
    "\n",
    "- Por tanto, elegimos la lematización con PoS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Features Extraction\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métodos como One-Hot Encoding o Weighted Words, como Bag of Words (BoW) - Bag of n-grams, Frequency Vectors - CountVectorizer y Term Frequency-Inverse Document Frequency (TF-IDF) no capturan ni la semántica (el significado de las palabras) ni la sintáctica (posición de las palabras en el texto). Para superar estas limitaciones utilizamos los embeddings. Los embeddings captan el contexto de una palabra teniendo en cuenta las palabras vecinas en la frase y el orden de las palabras en la frase. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings: vector based numerical representations of text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos un número considerable de filas (2000), usaremos embeddings, como Word2Vec. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Word2Vec es un encoder de tipo denso. \n",
    "- Utiliza una red neuronal\n",
    "para aprender asociaciones de palabras a partir de un\n",
    "texto.\n",
    "- Por cada palabra, construye un vector de n dimensiones.\n",
    "- En función del número de parámetros y de los datos de\n",
    "entrenamiento, es capaz de capturar el significado de las\n",
    "palabras y detectar sinónimos o palabras relacionadas.\n",
    "- Permite calcular similitudes → cos(θ)\n",
    "- Permite hacer operaciones con los vectores de\n",
    "palabras.\n",
    "\n",
    "\n",
    "**Ventajas:**\n",
    "- Captura la posición de las palabras en el texto (sintáctica).\n",
    "- Capta el significado de las palabras (semántica). \n",
    "\n",
    "**Limitaciones:** \n",
    "- No puede captar el significado de la palabra a partir del texto (no capta la polisemia).\n",
    "- No capta las palabras del corpus que no están en el vocabulario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim version: 4.3.1\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "print(\"gensim version:\", gensim.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo word2vec\n",
    "word2vec_model = Word2Vec(vector_size=300, \n",
    "                          window=2, \n",
    "                          min_count=20, \n",
    "                          sample=6e-5, \n",
    "                          workers=cores-1, \n",
    "                          sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Vocabulary Table\n",
    "sentences = train_df_clean['lemmatize_word_pos']\n",
    "word2vec_model.build_vocab(sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para implementar Word2Vec, necesitaremos los textos preprocesados y tokenizados: la columna \"lemmatize_word_pos\"  contiene los textos lematizados y tokenizados. \n",
    "- Utilizaremos esa columna para entrenar el modelo Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637587, 4264350)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training of the model\n",
    "word2vec_model.train(sentences, \n",
    "                     total_examples=word2vec_model.corpus_count, # 2000: len(sentences)\n",
    "                     epochs=30, \n",
    "                     report_delay=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Número de palabras procesadas y el número total de tokens en tu conjunto de datos durante el entrenamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorización del texto: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(words, word2vec_model):\n",
    "    \"\"\"\n",
    "    Esta función verifica si cada palabra está presente en el vocabulario \n",
    "    del modelo Word2Vec y obtiene su vector correspondiente. \n",
    "    Luego, calcula el promedio de los vectores de palabras para obtener \n",
    "    el vector representativo de la lista de palabras.\n",
    "    \"\"\"\n",
    "    word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "def get_average_sentence_vector(sentences, word2vec_model):\n",
    "    \"\"\"\n",
    "    Toma una lista de oraciones y aplica la función get_sentence_vector() \n",
    "    a cada oración para obtener los vectores de palabras promedio. \n",
    "    Luego, se realiza el promedio de estos vectores de oraciones para \n",
    "    obtener un vector de oración promedio.\n",
    "    \"\"\"\n",
    "    sentence_vectors = [get_sentence_vector(sentence) for sentence in sentences]\n",
    "    if sentence_vectors:\n",
    "        return np.mean(sentence_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "def embed_data_with_sentence_vector(sentences, word2vec):\n",
    "    \"\"\"\n",
    "    Recorre las oraciones de cada muestra y obtiene el vector de oración promedio \n",
    "    utilizando get_average_sentence_vector(). Solo se agrega el vector de \n",
    "    oración promedio si no es un vector de ceros.\n",
    "    \"\"\"\n",
    "    embedded_mean = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence_vector = get_average_sentence_vector(sentence)\n",
    "        if np.any(sentence_vector):\n",
    "            embedded_mean.append(sentence_vector)\n",
    "    \n",
    "    return embedded_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_mean = embed_data_with_sentence_vector(sentences, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las dimensiones de embedded_mean coinciden con el número de filas en X_train, ya que cada elemento de embedded_mean corresponderá a una muestra en el mismo orden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de las otras features y creación de X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinamos embedded_mean con las features adicionales, como las columnas de desplazamiento (Pronoun-offset, A-offset y B-offset), y las características codificadas de los nombres A y B (A y B) y Pronoun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las características adicionales\n",
    "pronoun_offset = np.array(train_df['Pronoun-offset'])\n",
    "a_offset = np.array(train_df['A-offset'])\n",
    "b_offset = np.array(train_df['B-offset'])\n",
    "\n",
    "# Convertir las características adicionales en vectores de desplazamiento normalizados\n",
    "normalized_pronoun_offset = pronoun_offset / len(embedded_mean)\n",
    "normalized_a_offset = a_offset / len(embedded_mean)\n",
    "normalized_b_offset = b_offset / len(embedded_mean)\n",
    "\n",
    "# Obtener las representaciones vectoriales para Pronoun, A y B (si están disponibles)\n",
    "pronoun_vector = [word2vec_model.wv[word] if word in word2vec_model.wv else np.zeros(word2vec_model.vector_size) for word in train_df['Pronoun']]\n",
    "a_vector = [word2vec_model.wv[word] if word in word2vec_model.wv else np.zeros(word2vec_model.vector_size) for word in train_df['A']]\n",
    "b_vector = [word2vec_model.wv[word] if word in word2vec_model.wv else np.zeros(word2vec_model.vector_size) for word in train_df['B']]\n",
    "\n",
    "# Combinar las características en una matriz de características\n",
    "X_train = np.column_stack((embedded_mean, normalized_pronoun_offset, normalized_a_offset, normalized_b_offset, a_vector, b_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting target to binary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Debemos codificar las etiquetas de clase de las variables objetivo (A-coref y B-coref) para asegurar la compatibilidad con los modelos.\n",
    "-  Dabido a que tenemos clases binarias, usaremos el LabelEncoder:\n",
    "    - False = 0\n",
    "    - True = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(df, target_1=\"A-coref\", target_2=\"B-coref\"):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[target_1] = le.fit_transform(df[target_1])\n",
    "    df[target_2] = le.fit_transform(df[target_2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = encode_target(train_df, target_1=\"A-coref\", target_2=\"B-coref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A-coref\n",
       "0    1126\n",
       "1     874\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['A-coref'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-coref\n",
       "0    1075\n",
       "1     925\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['B-coref'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadir 3a condición: A-coref = False y B-coref = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede haber casos en los que la respuesta sea A-coref == False y B-coref == False, lo que indica que el pronombre no hace referencia a ninguno de los nombres propuestos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existe al menos una fila donde A-coref y B-coref son ambos 0.\n"
     ]
    }
   ],
   "source": [
    "if (~(train_df['A-coref'] | train_df['B-coref'])).any():\n",
    "    print(\"Existe al menos una fila donde A-coref y B-coref son ambos 0.\")\n",
    "else:\n",
    "    print(\"No existe ninguna fila donde A-coref y B-coref sean ambos 0.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, no puede haber casos en los que la respuesta sea A-coref == True y B-coref == True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existe ninguna fila donde A-coref y B-coref sean ambos 1.\n"
     ]
    }
   ],
   "source": [
    "if (train_df['A-coref'] & train_df['B-coref']).any():\n",
    "    print(\"Existe al menos una fila donde A-coref y B-coref son ambos 1.\")\n",
    "else:\n",
    "    print(\"No existe ninguna fila donde A-coref y B-coref sean ambos 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las columnas A-coref y B-coref del dataset de entrenamiento\n",
    "a_coref = train_df['A-coref'].values\n",
    "b_coref = train_df['B-coref'].values\n",
    "\n",
    "# Crear la tercera columna para representar la clase \"None\"\n",
    "none_coref = np.where((a_coref == 0) & (b_coref == 0), 1, 0)\n",
    "\n",
    "# Agregar la columna \"None-coref\" al dataset de entrenamiento\n",
    "train_df['None-coref'] = none_coref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None-coref\n",
       "0    1799\n",
       "1     201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['None-coref'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hay 201 casos en los que el pronombre no hace referencia a ninguno de los nombres propuestos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>None-coref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A-coref  B-coref  None-coref\n",
       "6           0        0           1\n",
       "15          0        0           1\n",
       "17          0        0           1\n",
       "28          0        0           1\n",
       "31          0        0           1\n",
       "...       ...      ...         ...\n",
       "1961        0        0           1\n",
       "1983        0        0           1\n",
       "1985        0        0           1\n",
       "1986        0        0           1\n",
       "1990        0        0           1\n",
       "\n",
       "[201 rows x 3 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casos en los que el pronombre no hace referencia a ninguno de los nombres propuestos\n",
    "train_df[train_df['None-coref']==1][['A-coref','B-coref','None-coref']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>None-coref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A-coref  B-coref  None-coref\n",
       "0           1        0           0\n",
       "1           1        0           0\n",
       "2           0        1           0\n",
       "3           0        1           0\n",
       "4           0        1           0\n",
       "...       ...      ...         ...\n",
       "1995        0        1           0\n",
       "1996        0        1           0\n",
       "1997        1        0           0\n",
       "1998        1        0           0\n",
       "1999        0        1           0\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['A-coref','B-coref','None-coref']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ahora tenemos 3 variables objetivo: \"A-coref\", \"B-coref\" y \"None-coref\". Cada instancia tiene un valor de 1 en una de las columnas correspondientes a la variable objetivo y un valor de 0 en las otras dos columnas.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear columna target "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creamos la columna target definitiva donde asignamos:\n",
    "    - `0`: si el pronombre hace referencia al nombre A.\n",
    "    - `1`: si el pronombre hace referencia al nombre B.\n",
    "    - `2`: si el pronombre no hace referencia a ninguno de los dos nombres propuestos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna target\n",
    "def get_target(row):\n",
    "    if row['A-coref'] == 1:\n",
    "        return 0\n",
    "    elif row['B-coref'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la columna target\n",
    "train_df['target'] = train_df.apply(get_target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>None-coref</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A-coref  B-coref  None-coref  target\n",
       "0           1        0           0       0\n",
       "1           1        0           0       0\n",
       "2           0        1           0       1\n",
       "3           0        1           0       1\n",
       "4           0        1           0       1\n",
       "...       ...      ...         ...     ...\n",
       "1995        0        1           0       1\n",
       "1996        0        1           0       1\n",
       "1997        1        0           0       0\n",
       "1998        1        0           0       0\n",
       "1999        0        1           0       1\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['A-coref','B-coref','None-coref', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>None-coref</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A-coref  B-coref  None-coref  target\n",
       "6           0        0           1       2\n",
       "15          0        0           1       2\n",
       "17          0        0           1       2\n",
       "28          0        0           1       2\n",
       "31          0        0           1       2\n",
       "...       ...      ...         ...     ...\n",
       "1961        0        0           1       2\n",
       "1983        0        0           1       2\n",
       "1985        0        0           1       2\n",
       "1986        0        0           1       2\n",
       "1990        0        0           1       2\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['None-coref']==1][['A-coref','B-coref','None-coref', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    925\n",
       "0    874\n",
       "2    201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 clases\n",
    "train_df['target'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 874 instancias donde el pronombre hace referencia al nombre A.\n",
    "- 925 instancias donde el pronombre hace referencia al nombre B.\n",
    "- 201 instancias donde el pronombre no hace referencia a ninguno de los dos nombres propuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full preprocessing pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulamos todos los pasos de limpieza y preprocesamiento anteriores en funciones. \n",
    "De esta manera, podremos aplicar todo el preprocesamiento de los datos al train set, validation set y test set por separado y de una manera más eficaz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaning Functions\n",
    "\n",
    "def select_imp_features(df):\n",
    "    imp_features = [\"Text\", \"Pronoun\", \"Pronoun-offset\", \"A\", \"A-offset\", \"B\", \"B-offset\"]\n",
    "    target_col = [\"A-coref\", \"B-coref\"]\n",
    "    df = df[imp_features + target_col]\n",
    "    return df \n",
    "\n",
    "def lower_case(df):\n",
    "    df.loc[:, \"text_clean\"] = df[\"Text\"].apply(lambda x: x.lower())\n",
    "    df.loc[:, \"Pronoun\"] = df[\"Pronoun\"].apply(lambda x: x.lower())\n",
    "    df.loc[:, \"A\"] = df[\"A\"].apply(lambda x: x.lower())\n",
    "    df.loc[:, \"B\"] = df[\"B\"].apply(lambda x: x.lower())\n",
    "\n",
    "def expand_contractions(df):\n",
    "    df.loc[:, \"text_clean\"] = df[\"text_clean\"].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "def remove_non_ascii_characters(df, col='text_clean'):\n",
    "    df.loc[:, col] = df[col].apply(lambda text: re.sub(r'[^\\x00-\\x7f]', r'', text)) # get rid of non-characters and whitespace\n",
    "    return df\n",
    "\n",
    "def remove_punctuations(df, col='text_clean'):\n",
    "    \"\"\"\n",
    "     - str.maketrans('', '', string.punctuation) crea un traductor utilizando maketrans \n",
    "       que mapea los caracteres de puntuación a None, es decir, los elimina.\n",
    "     - string.punctuation es una cadena predefinida en el módulo string que contiene todos \n",
    "       los caracteres de puntuación.\n",
    "     - text.translate(translator) aplica el traductor al texto, reemplazando las puntuaciones \n",
    "       con caracteres vacíos, lo que efectivamente las elimina.\n",
    "    \"\"\"\n",
    "    df.loc[:, col] = df[col].apply(lambda text: text.translate(str.maketrans('', '', string.punctuation)))\n",
    "    # return re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \"\", text)\n",
    "    return df\n",
    "\n",
    "# Orquestación secuencial de la limpieza de texto\n",
    "def text_cleaning(df):\n",
    "    # Crear una copia del DataFrame:\n",
    "        # todas las modificaciones se realicen en una copia independiente \n",
    "        # y no afectan al DataFrame original.\n",
    "    df = df.copy()  \n",
    "    # text cleaning functions\n",
    "    df = select_imp_features(df)\n",
    "    lower_case(df)\n",
    "    expand_contractions(df)\n",
    "    df = remove_non_ascii_characters(df)\n",
    "    df = remove_punctuations(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing Functions \n",
    "\n",
    "# Tokenization\n",
    "def tokenize_text(df):\n",
    "    df.loc[:, 'tokenized'] = df['text_clean'].apply(word_tokenize)\n",
    "\n",
    "# Part of Speech Tagging\n",
    "def part_of_speech_tagging(df):\n",
    "    df.loc[:, 'pos_tags'] = df['tokenized'].apply(nltk.tag.pos_tag)\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('POS'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('RB'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('CD'):\n",
    "        return wordnet.NOUN   \n",
    "    else:\n",
    "        return wordnet.NOUN  # Por defecto, asumimos sustantivos si la etiqueta POS no coincide con las anteriores\n",
    "\n",
    "def apply_wordnet_pos(df):\n",
    "    df.loc[:, 'wordnet_pos'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "    \n",
    "# Lemmatization with PoS\n",
    "def lemmatize_word_pos(text):\n",
    "    \"\"\"\n",
    "    Lemmatize the tokenized words (with PoS)\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n",
    "    return lemmatized_text\n",
    "\n",
    "def apply_lemmatize_word_pos(df):\n",
    "    df.loc[:, 'lemmatize_word_pos'] = df['wordnet_pos'].apply(lambda x: lemmatize_word_pos(x))\n",
    "\n",
    "# Orquestación secuencial del preprocesamiento del texto\n",
    "def text_preprocessing(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    tokenize_text(df)\n",
    "    part_of_speech_tagging(df)\n",
    "    apply_wordnet_pos(df)\n",
    "    apply_lemmatize_word_pos(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Features Extraction\n",
    "\n",
    "# Word2Vec Embedding\n",
    "def train_word2vec_model(sentences):\n",
    "    # Set up the parameters of the model\n",
    "    word2vec_model = Word2Vec(vector_size=300, \n",
    "                              window=2, \n",
    "                              min_count=20, \n",
    "                              sample=6e-5, \n",
    "                              workers=cores-1, \n",
    "                              sg=1)\n",
    "                              \n",
    "    # Building the Vocabulary Table\n",
    "    word2vec_model.build_vocab(sentences)\n",
    "    \n",
    "    # Training the model\n",
    "    word2vec_model.train(sentences, \n",
    "                         total_examples=word2vec_model.corpus_count,  # 2000: len(sentences)\n",
    "                         epochs=30, \n",
    "                         report_delay=1)\n",
    "    \n",
    "    return word2vec_model\n",
    "\n",
    "# Text Vectorization\n",
    "def get_sentence_vector(words, word2vec_model):\n",
    "    \"\"\"\n",
    "    Esta función verifica si cada palabra está presente en el vocabulario \n",
    "    del modelo Word2Vec y obtiene su vector correspondiente. \n",
    "    Luego, calcula el promedio de los vectores de palabras para obtener \n",
    "    el vector representativo de la lista de palabras.\n",
    "    \"\"\"\n",
    "    word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "def get_average_sentence_vector(sentences, word2vec_model):\n",
    "    \"\"\"\n",
    "    Toma una lista de oraciones y aplica la función get_sentence_vector() \n",
    "    a cada oración para obtener los vectores de palabras promedio. \n",
    "    Luego, se realiza el promedio de estos vectores de oraciones para \n",
    "    obtener un vector de oración promedio\n",
    "    \"\"\"\n",
    "    sentence_vectors = [get_sentence_vector(sentence, word2vec_model) for sentence in sentences]\n",
    "    if sentence_vectors:\n",
    "        return np.mean(sentence_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "def embed_data_with_sentence_vector(sentences, word2vec_model):\n",
    "    \"\"\"\n",
    "    Recorre las oraciones de cada muestra y obtiene el vector de oración promedio \n",
    "    utilizando get_average_sentence_vector(). Solo se agrega el vector de \n",
    "    oración promedio si no es un vector de ceros.\n",
    "    \"\"\"\n",
    "    embedded_mean = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence_vector = get_average_sentence_vector(sentence, word2vec_model)\n",
    "        if np.any(sentence_vector):\n",
    "            embedded_mean.append(sentence_vector)\n",
    "    \n",
    "    return embedded_mean\n",
    "\n",
    "def word2vec_text_vectorization_embed(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Entrenar el modelo Word2Vec\n",
    "    sentences = df['lemmatize_word_pos']\n",
    "    word2vec_model = train_word2vec_model(sentences)\n",
    "    # Obtener los vectores promedio de las frases\n",
    "    embedded_mean = embed_data_with_sentence_vector(sentences, word2vec_model)\n",
    "    \n",
    "    return word2vec_model, embedded_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the other features\n",
    "def get_additional_features(df, word2vec_model, embedded_mean):\n",
    "    \"\"\"\n",
    "    Combinamos embedded_mean con las features adicionales, como las columnas \n",
    "    de desplazamiento (Pronoun-offset, A-offset y B-offset), \n",
    "    y las características codificadas de los nombres A y B (A y B) y Pronoun.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Obtener las características adicionales\n",
    "    pronoun_offset = np.array(df['Pronoun-offset'])\n",
    "    a_offset = np.array(df['A-offset'])\n",
    "    b_offset = np.array(df['B-offset'])\n",
    "\n",
    "    # Convertir las características adicionales en vectores de desplazamiento normalizados\n",
    "    normalized_pronoun_offset = pronoun_offset / len(embedded_mean)\n",
    "    normalized_a_offset = a_offset / len(embedded_mean)\n",
    "    normalized_b_offset = b_offset / len(embedded_mean)\n",
    "\n",
    "    # Obtener las representaciones vectoriales para Pronoun, A y B (si están disponibles)\n",
    "    pronoun_vector = [word2vec_model.wv[word] if word in word2vec_model.wv else np.zeros(word2vec_model.vector_size) for word in df['Pronoun']]\n",
    "    a_vector = [word2vec_model.wv[word] if word in word2vec_model.wv else np.zeros(word2vec_model.vector_size) for word in df['A']]\n",
    "    b_vector = [word2vec_model.wv[word] if word in word2vec_model.wv else np.zeros(word2vec_model.vector_size) for word in df['B']]\n",
    "\n",
    "    # Combinar las características en una matriz de características\n",
    "    X = np.column_stack((embedded_mean, normalized_pronoun_offset, normalized_a_offset, normalized_b_offset, a_vector, b_vector))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting target to binary\n",
    "def encode_target(df, target_1=\"A-coref\", target_2=\"B-coref\"):\n",
    "    \"\"\"\n",
    "    Debemos codificar las etiquetas de clase de las variables objetivo \n",
    "    (A-coref y B-coref) para asegurar la compatibilidad con los modelos.\n",
    "    Dabido a que tenemos clases binarias, usaremos el LabelEncoder:\n",
    "        - False = 0\n",
    "        - True = 1\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[target_1] = le.fit_transform(df[target_1])\n",
    "    df[target_2] = le.fit_transform(df[target_2])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR COLUMNA TARGET DEFINITIVA\n",
    "# Añadir 3a condición: pronombre no hace referencia a ninguno de los nombres propuestos\n",
    "def add_none_coref_column(df):\n",
    "    \"\"\"\n",
    "    Puede haber casos en los que la respuesta sea A-coref == False y B-coref == False, \n",
    "    lo que indica que el pronombre no hace referencia a ninguno de los nombres propuestos. \n",
    "    \"\"\"\n",
    "    # Obtener las columnas A-coref y B-coref del dataset de entrenamiento\n",
    "    a_coref = df['A-coref'].values\n",
    "    b_coref = df['B-coref'].values\n",
    "\n",
    "    # Crear la tercera columna para representar la clase \"None\"\n",
    "    none_coref = np.where((a_coref == 0) & (b_coref == 0), 1, 0)\n",
    "\n",
    "    # Agregar la columna \"None-coref\" al dataset de entrenamiento\n",
    "    df['None-coref'] = none_coref\n",
    "\n",
    "    return df\n",
    "\n",
    "# Crear la columna target\n",
    "def get_target(row):\n",
    "    \"\"\"\n",
    "    Creamos la columna target definitiva donde asignamos:\n",
    "    - `0`: si el pronombre hace referencia al nombre A.\n",
    "    - `1`: si el pronombre hace referencia al nombre B.\n",
    "    - `2`: si el pronombre no hace referencia a ninguno de los dos nombres propuestos. \n",
    "    \"\"\"\n",
    "    if row['A-coref'] == 1:\n",
    "        return 0\n",
    "    elif row['B-coref'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def multiclass_target(df):\n",
    "    \"\"\"\n",
    "    Crea la columna target definitiva.\n",
    "    Agrega la columna \"None-coref\" y \"target\" al df, \n",
    "    donde la columna \"target\" contendrá los valores 0, 1 o 2 \n",
    "    dependiendo de si el pronombre hace referencia al nombre A, B \n",
    "    o a ninguno de los dos nombres propuestos.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Añadir la columna None-coref al df\n",
    "    df = add_none_coref_column(df)\n",
    "    # Crear la columna target \n",
    "    df['target'] = df.apply(get_target, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(df):\n",
    "    \"\"\"\n",
    "    Realiza el preprocesamiento completo del dataset.\n",
    "    Devuelve las características X y los valores objetivo y.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Text Cleaning\n",
    "    df_cleaned = text_cleaning(df)\n",
    "\n",
    "    # Text Preprocessing\n",
    "    df_clean_prep = text_preprocessing(df_cleaned)\n",
    "\n",
    "    # Text Features Extraction\n",
    "    word2vec_model, embedded_mean = word2vec_text_vectorization_embed(df_clean_prep)\n",
    "\n",
    "    # Preprocessing the other features\n",
    "    # Build the X (features)\n",
    "    X = get_additional_features(df_clean_prep, \n",
    "                                word2vec_model,\n",
    "                                embedded_mean)\n",
    "\n",
    "    # Converting target to binary\n",
    "    df_clean_prep = encode_target(df_clean_prep, \n",
    "                                  target_1=\"A-coref\", \n",
    "                                  target_2=\"B-coref\")\n",
    "\n",
    "    # Creamos la columna target definitiva\n",
    "    df_final = multiclass_target(df_clean_prep)\n",
    "\n",
    "    # y (target)\n",
    "    y = df_final['target'].values.astype(int)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "DATA_ROOT = './input/'\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap-coreference-master')\n",
    "train_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-development.tsv')\n",
    "train_df = pd.read_csv(train_df_path, sep='\\t') \n",
    "\n",
    "# Preprocess the TRAIN set\n",
    "X_train, y_train = preprocess_dataset(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "DATA_ROOT = './input/'\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap-coreference-master')\n",
    "val_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-validation.tsv')\n",
    "val_df = pd.read_csv(val_df_path, sep='\\t')\n",
    "\n",
    "# Preprocess the VALIDATION set\n",
    "X_val, y_val = preprocess_dataset(val_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "DATA_ROOT = './input/'\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap-coreference-master')\n",
    "test_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-test.tsv')\n",
    "test_df = pd.read_csv(test_df_path, sep='\\t')\n",
    "\n",
    "# Preprocess the TEST set\n",
    "X_test, y_test = preprocess_dataset(test_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text classification with 3 different classes.\n",
    "- Evaluation metric: multi-class log-loss.\n",
    "    -  La métrica de accuracy es ampliamente utilizada y fácil de interpretar, ya que representa la proporción de predicciones correctas en relación con el total de predicciones. Sin embargo, la accuracy puede ser engañosa en casos donde las clases están desbalanceadas, es decir, cuando algunas clases tienen muchos más ejemplos que otras. En estos casos, el modelo puede tener una alta accuracy al predecir la clase mayoritaria, pero tener un rendimiento deficiente en la predicción de las clases minoritarias.\n",
    "\n",
    "    - El log loss (pérdida logarítmica) es una métrica más adecuada cuando se trata de problemas de clasificación multiclase con clases desbalanceadas, como es nuestro caso. El log loss penaliza las predicciones incorrectas de manera más fuerte, y su valor se minimiza cuando las probabilidades asignadas a las clases correctas son cercanas a 1.0. Es una métrica más sensible a los errores de clasificación y proporciona una medida más precisa de la calidad de las predicciones en un problema multiclase."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos: \n",
    "- Clase 0: 874 instancias donde el pronombre hace referencia al nombre A.\n",
    "- Clase 1: 925 instancias donde el pronombre hace referencia al nombre B.\n",
    "- Clase 2: 201 instancias donde el pronombre no hace referencia a ninguno de los dos nombres propuestos.\n",
    "\n",
    "Las clases no están perfectamente equilibradas, pero tampoco existe un desequilibrio extremo.\n",
    "\n",
    "Dado que la clase \"0\" y la clase \"1\" tienen una cantidad similar de instancias, mientras que la clase \"2\" tiene menos instancias, es probable que el rendimiento del modelo en la clasificación de las clases \"0\" y \"1\" sea más representativo de su capacidad general. Sin embargo, esto no significa que la clase \"2\" deba ser descartada o ignorada, ya que sigue siendo una clase importante de nuestro problema.\n",
    "\n",
    "Al utilizar el log loss como métrica de evaluación, el modelo será penalizado de manera más significativa si no puede asignar una alta probabilidad a la clase correcta, tanto en las clases \"0\" y \"1\" como en la clase \"2\". Esto asegurará que el modelo sea más consciente de la importancia de todas las clases y buscará mejorar su rendimiento en cada una de ellas.\n",
    "\n",
    "Por tanto, al utilizar el log loss como métrica de evaluación, estaremos evaluando el rendimiento del modelo de manera justa y equilibrada en todas las clases, incluida la clase \"2\" que tiene menos instancias. Esto nos permitirá obtener una evaluación global más precisa del modelo y tomar decisiones informadas sobre su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.387 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       187\n",
      "           1       0.45      1.00      0.62       205\n",
      "           2       1.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.45       454\n",
      "   macro avg       0.82      0.33      0.21       454\n",
      "weighted avg       0.75      0.45      0.28       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Logistic Regression\n",
    "# clf = LogisticRegression(C=1.0)\n",
    "# clf.fit(X_train, y_train)\n",
    "# predictions = clf.predict_proba(X_val)\n",
    "\n",
    "# print (\"logloss: %0.3f \" % multiclass_logloss(y_val, predictions))\n",
    "\n",
    "# # Convertir probabilidades a etiquetas\n",
    "# predicted_labels = np.argmax(predictions, axis=1)  \n",
    "\n",
    "# # Imprimir el informe de clasificación\n",
    "# print(classification_report(y_val, predicted_labels, zero_division=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting with grid search we need to create a scoring function. \n",
    "# This is accomplished using the make_scorer function of scikit-learn.\n",
    "\n",
    "mll_scorer = metrics.make_scorer(multiclass_logloss, \n",
    "                                 greater_is_better=False, # el log loss debe ser minimizado\n",
    "                                 needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# grid of parameters: evaluate three different values of C with l1 and l2 penalty.\n",
    "# param_grid = {'C': [0.01, 1.0, 10], \n",
    "#               'penalty': ['none', 'l2']}\n",
    "\n",
    "param_grid  = [\n",
    "                {'solver' : ['saga'],\n",
    "                'penalty' : ['elasticnet', 'l1', 'l2', 'none'],\n",
    "                'max_iter' : [50,100,200,500,1000,2500],\n",
    "\n",
    "                'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "                {'solver' : ['newton-cg', 'lbfgs'],\n",
    "                'penalty' : ['l2','none'],\n",
    "                'max_iter' : [50,100,200,500,1000,2500],\n",
    "                'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 336 candidates, totalling 672 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340601.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "340601.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "340601.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "340601.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "340601.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "340601.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "340601.14s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "340601.14s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 2/336] START C=0.001, max_iter=50, penalty=l1, solver=saga.............\n",
      "[CV 2/2; 4/336] START C=0.001, max_iter=50, penalty=none, solver=saga...........\n",
      "[CV 2/2; 3/336] START C=0.001, max_iter=50, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 3/336] START C=0.001, max_iter=50, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 2/336] START C=0.001, max_iter=50, penalty=l1, solver=saga.............\n",
      "[CV 1/2; 4/336] START C=0.001, max_iter=50, penalty=none, solver=saga...........\n",
      "[CV 2/2; 1/336] START C=0.001, max_iter=50, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 1/336] START C=0.001, max_iter=50, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 1/336] END C=0.001, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 1/336] END C=0.001, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 2/336] END C=0.001, max_iter=50, penalty=l1, solver=saga;, score=-0.953 total time=   0.1s\n",
      "[CV 2/2; 2/336] END C=0.001, max_iter=50, penalty=l1, solver=saga;, score=-1.059 total time=   0.1s\n",
      "[CV 1/2; 5/336] START C=0.001, max_iter=100, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 5/336] START C=0.001, max_iter=100, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 6/336] START C=0.001, max_iter=100, penalty=l1, solver=saga............\n",
      "[CV 2/2; 6/336] START C=0.001, max_iter=100, penalty=l1, solver=saga............\n",
      "[CV 1/2; 5/336] END C=0.001, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 7/336] START C=0.001, max_iter=100, penalty=l2, solver=saga............\n",
      "[CV 2/2; 5/336] END C=0.001, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 7/336] START C=0.001, max_iter=100, penalty=l2, solver=saga............\n",
      "[CV 2/2; 6/336] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=-0.986 total time=   0.0s\n",
      "[CV 1/2; 8/336] START C=0.001, max_iter=100, penalty=none, solver=saga..........\n",
      "[CV 1/2; 6/336] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=-0.950 total time=   0.0s\n",
      "[CV 2/2; 8/336] START C=0.001, max_iter=100, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 3/336] END C=0.001, max_iter=50, penalty=l2, solver=saga;, score=-0.949 total time=   0.4s\n",
      "[CV 1/2; 7/336] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=-0.949 total time=   0.3s\n",
      "[CV 1/2; 9/336] START C=0.001, max_iter=200, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 9/336] START C=0.001, max_iter=200, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 9/336] END C=0.001, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 10/336] START C=0.001, max_iter=200, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 9/336] END C=0.001, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 10/336] START C=0.001, max_iter=200, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 7/336] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=-0.950 total time=   0.3s\n",
      "[CV 1/2; 11/336] START C=0.001, max_iter=200, penalty=l2, solver=saga...........\n",
      "[CV 2/2; 10/336] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=-0.999 total time=   0.0s\n",
      "[CV 2/2; 11/336] START C=0.001, max_iter=200, penalty=l2, solver=saga...........\n",
      "[CV 1/2; 10/336] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=-0.976 total time=   0.0s\n",
      "[CV 1/2; 12/336] START C=0.001, max_iter=200, penalty=none, solver=saga.........\n",
      "[CV 2/2; 3/336] END C=0.001, max_iter=50, penalty=l2, solver=saga;, score=-0.950 total time=   0.5s\n",
      "[CV 2/2; 12/336] START C=0.001, max_iter=200, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 11/336] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=-0.949 total time=   0.3s\n",
      "[CV 1/2; 13/336] START C=0.001, max_iter=500, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 11/336] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=-0.950 total time=   0.2s\n",
      "[CV 2/2; 13/336] START C=0.001, max_iter=500, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 13/336] END C=0.001, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 14/336] START C=0.001, max_iter=500, penalty=l1, solver=saga...........\n",
      "[CV 1/2; 4/336] END C=0.001, max_iter=50, penalty=none, solver=saga;, score=-0.948 total time=   0.7s\n",
      "[CV 1/2; 13/336] END C=0.001, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 14/336] START C=0.001, max_iter=500, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 14/336] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=-1.003 total time=   0.0s\n",
      "[CV 1/2; 15/336] START C=0.001, max_iter=500, penalty=l2, solver=saga...........\n",
      "[CV 1/2; 14/336] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=-0.956 total time=   0.0s\n",
      "[CV 2/2; 15/336] START C=0.001, max_iter=500, penalty=l2, solver=saga...........\n",
      "[CV 1/2; 16/336] START C=0.001, max_iter=500, penalty=none, solver=saga.........\n",
      "[CV 2/2; 4/336] END C=0.001, max_iter=50, penalty=none, solver=saga;, score=-0.969 total time=   0.7s\n",
      "[CV 2/2; 16/336] START C=0.001, max_iter=500, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 15/336] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=-0.949 total time=   0.3s\n",
      "[CV 1/2; 17/336] START C=0.001, max_iter=1000, penalty=elasticnet, solver=saga..\n",
      "[CV 1/2; 17/336] END C=0.001, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 17/336] START C=0.001, max_iter=1000, penalty=elasticnet, solver=saga..\n",
      "[CV 2/2; 17/336] END C=0.001, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 18/336] START C=0.001, max_iter=1000, penalty=l1, solver=saga..........\n",
      "[CV 2/2; 15/336] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=-0.950 total time=   0.3s\n",
      "[CV 2/2; 18/336] START C=0.001, max_iter=1000, penalty=l1, solver=saga..........\n",
      "[CV 1/2; 18/336] END C=0.001, max_iter=1000, penalty=l1, solver=saga;, score=-0.950 total time=   0.0s\n",
      "[CV 1/2; 19/336] START C=0.001, max_iter=1000, penalty=l2, solver=saga..........\n",
      "[CV 2/2; 18/336] END C=0.001, max_iter=1000, penalty=l1, solver=saga;, score=-1.002 total time=   0.0s\n",
      "[CV 2/2; 19/336] START C=0.001, max_iter=1000, penalty=l2, solver=saga..........\n",
      "[CV 1/2; 19/336] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=-0.949 total time=   0.2s\n",
      "[CV 1/2; 20/336] START C=0.001, max_iter=1000, penalty=none, solver=saga........\n",
      "[CV 2/2; 19/336] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=-0.950 total time=   0.3s\n",
      "[CV 2/2; 20/336] START C=0.001, max_iter=1000, penalty=none, solver=saga........\n",
      "[CV 1/2; 8/336] END C=0.001, max_iter=100, penalty=none, solver=saga;, score=-0.953 total time=   1.2s\n",
      "[CV 1/2; 21/336] START C=0.001, max_iter=2500, penalty=elasticnet, solver=saga..\n",
      "[CV 1/2; 21/336] END C=0.001, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 21/336] START C=0.001, max_iter=2500, penalty=elasticnet, solver=saga..\n",
      "[CV 2/2; 21/336] END C=0.001, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 22/336] START C=0.001, max_iter=2500, penalty=l1, solver=saga..........\n",
      "[CV 2/2; 8/336] END C=0.001, max_iter=100, penalty=none, solver=saga;, score=-0.974 total time=   1.3s\n",
      "[CV 2/2; 22/336] START C=0.001, max_iter=2500, penalty=l1, solver=saga..........\n",
      "[CV 1/2; 22/336] END C=0.001, max_iter=2500, penalty=l1, solver=saga;, score=-0.969 total time=   0.0s\n",
      "[CV 1/2; 23/336] START C=0.001, max_iter=2500, penalty=l2, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 22/336] END C=0.001, max_iter=2500, penalty=l1, solver=saga;, score=-1.072 total time=   0.0s\n",
      "[CV 2/2; 23/336] START C=0.001, max_iter=2500, penalty=l2, solver=saga..........\n",
      "[CV 2/2; 23/336] END C=0.001, max_iter=2500, penalty=l2, solver=saga;, score=-0.950 total time=   0.2s\n",
      "[CV 1/2; 24/336] START C=0.001, max_iter=2500, penalty=none, solver=saga........\n",
      "[CV 1/2; 23/336] END C=0.001, max_iter=2500, penalty=l2, solver=saga;, score=-0.949 total time=   0.3s\n",
      "[CV 2/2; 24/336] START C=0.001, max_iter=2500, penalty=none, solver=saga........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 12/336] END C=0.001, max_iter=200, penalty=none, solver=saga;, score=-0.960 total time=   2.6s\n",
      "[CV 1/2; 25/336] START C=0.01, max_iter=50, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 25/336] END C=0.01, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 25/336] START C=0.01, max_iter=50, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 25/336] END C=0.01, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 26/336] START C=0.01, max_iter=50, penalty=l1, solver=saga.............\n",
      "[CV 2/2; 12/336] END C=0.001, max_iter=200, penalty=none, solver=saga;, score=-0.982 total time=   2.5s\n",
      "[CV 2/2; 26/336] START C=0.01, max_iter=50, penalty=l1, solver=saga.............\n",
      "[CV 1/2; 26/336] END C=0.01, max_iter=50, penalty=l1, solver=saga;, score=-0.954 total time=   0.1s\n",
      "[CV 1/2; 27/336] START C=0.01, max_iter=50, penalty=l2, solver=saga.............\n",
      "[CV 2/2; 26/336] END C=0.01, max_iter=50, penalty=l1, solver=saga;, score=-0.995 total time=   0.0s\n",
      "[CV 2/2; 27/336] START C=0.01, max_iter=50, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 27/336] END C=0.01, max_iter=50, penalty=l2, solver=saga;, score=-0.948 total time=   0.3s\n",
      "[CV 1/2; 28/336] START C=0.01, max_iter=50, penalty=none, solver=saga...........\n",
      "[CV 2/2; 27/336] END C=0.01, max_iter=50, penalty=l2, solver=saga;, score=-0.950 total time=   0.3s\n",
      "[CV 2/2; 28/336] START C=0.01, max_iter=50, penalty=none, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 28/336] END C=0.01, max_iter=50, penalty=none, solver=saga;, score=-0.948 total time=   0.6s\n",
      "[CV 1/2; 29/336] START C=0.01, max_iter=100, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 29/336] END C=0.01, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 29/336] START C=0.01, max_iter=100, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 29/336] END C=0.01, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 30/336] START C=0.01, max_iter=100, penalty=l1, solver=saga............\n",
      "[CV 1/2; 30/336] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=-0.955 total time=   0.0s\n",
      "[CV 2/2; 30/336] START C=0.01, max_iter=100, penalty=l1, solver=saga............\n",
      "[CV 2/2; 28/336] END C=0.01, max_iter=50, penalty=none, solver=saga;, score=-0.969 total time=   0.6s\n",
      "[CV 1/2; 31/336] START C=0.01, max_iter=100, penalty=l2, solver=saga............\n",
      "[CV 2/2; 30/336] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=-1.110 total time=   0.0s\n",
      "[CV 2/2; 31/336] START C=0.01, max_iter=100, penalty=l2, solver=saga............\n",
      "[CV 1/2; 31/336] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=-0.948 total time=   0.3s\n",
      "[CV 1/2; 32/336] START C=0.01, max_iter=100, penalty=none, solver=saga..........\n",
      "[CV 2/2; 31/336] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=-0.950 total time=   0.3s\n",
      "[CV 2/2; 32/336] START C=0.01, max_iter=100, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 32/336] END C=0.01, max_iter=100, penalty=none, solver=saga;, score=-0.953 total time=   1.2s\n",
      "[CV 1/2; 33/336] START C=0.01, max_iter=200, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 33/336] END C=0.01, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 33/336] START C=0.01, max_iter=200, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 33/336] END C=0.01, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 34/336] START C=0.01, max_iter=200, penalty=l1, solver=saga............\n",
      "[CV 2/2; 32/336] END C=0.01, max_iter=100, penalty=none, solver=saga;, score=-0.974 total time=   1.2s\n",
      "[CV 2/2; 34/336] START C=0.01, max_iter=200, penalty=l1, solver=saga............\n",
      "[CV 1/2; 34/336] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=-0.953 total time=   0.1s\n",
      "[CV 2/2; 34/336] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=-0.963 total time=   0.0s\n",
      "[CV 1/2; 35/336] START C=0.01, max_iter=200, penalty=l2, solver=saga............\n",
      "[CV 2/2; 35/336] START C=0.01, max_iter=200, penalty=l2, solver=saga............\n",
      "[CV 2/2; 35/336] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=-0.950 total time=   0.3s\n",
      "[CV 1/2; 36/336] START C=0.01, max_iter=200, penalty=none, solver=saga..........\n",
      "[CV 1/2; 35/336] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=-0.948 total time=   0.3s\n",
      "[CV 2/2; 36/336] START C=0.01, max_iter=200, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 16/336] END C=0.001, max_iter=500, penalty=none, solver=saga;, score=-0.975 total time=   6.2s\n",
      "[CV 1/2; 37/336] START C=0.01, max_iter=500, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 37/336] END C=0.01, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 37/336] START C=0.01, max_iter=500, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 37/336] END C=0.01, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 38/336] START C=0.01, max_iter=500, penalty=l1, solver=saga............\n",
      "[CV 1/2; 38/336] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=-0.980 total time=   0.0s\n",
      "[CV 2/2; 16/336] END C=0.001, max_iter=500, penalty=none, solver=saga;, score=-1.001 total time=   6.2s\n",
      "[CV 1/2; 39/336] START C=0.01, max_iter=500, penalty=l2, solver=saga............\n",
      "[CV 2/2; 38/336] START C=0.01, max_iter=500, penalty=l1, solver=saga............\n",
      "[CV 2/2; 38/336] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=-0.955 total time=   0.0s\n",
      "[CV 2/2; 39/336] START C=0.01, max_iter=500, penalty=l2, solver=saga............\n",
      "[CV 2/2; 39/336] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=-0.950 total time=   0.2s\n",
      "[CV 1/2; 40/336] START C=0.01, max_iter=500, penalty=none, solver=saga..........\n",
      "[CV 1/2; 39/336] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=-0.948 total time=   0.3s\n",
      "[CV 2/2; 40/336] START C=0.01, max_iter=500, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 36/336] END C=0.01, max_iter=200, penalty=none, solver=saga;, score=-0.982 total time=   2.4s\n",
      "[CV 1/2; 41/336] START C=0.01, max_iter=1000, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 41/336] END C=0.01, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 41/336] START C=0.01, max_iter=1000, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 41/336] END C=0.01, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 42/336] START C=0.01, max_iter=1000, penalty=l1, solver=saga...........\n",
      "[CV 1/2; 42/336] END C=0.01, max_iter=1000, penalty=l1, solver=saga;, score=-0.949 total time=   0.0s\n",
      "[CV 2/2; 42/336] START C=0.01, max_iter=1000, penalty=l1, solver=saga...........\n",
      "[CV 1/2; 36/336] END C=0.01, max_iter=200, penalty=none, solver=saga;, score=-0.960 total time=   2.5s\n",
      "[CV 1/2; 43/336] START C=0.01, max_iter=1000, penalty=l2, solver=saga...........\n",
      "[CV 2/2; 42/336] END C=0.01, max_iter=1000, penalty=l1, solver=saga;, score=-0.968 total time=   0.0s\n",
      "[CV 2/2; 43/336] START C=0.01, max_iter=1000, penalty=l2, solver=saga...........\n",
      "[CV 1/2; 43/336] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=-0.948 total time=   0.4s\n",
      "[CV 1/2; 44/336] START C=0.01, max_iter=1000, penalty=none, solver=saga.........\n",
      "[CV 2/2; 43/336] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=-0.950 total time=   0.4s\n",
      "[CV 2/2; 44/336] START C=0.01, max_iter=1000, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 40/336] END C=0.01, max_iter=500, penalty=none, solver=saga;, score=-0.975 total time=   6.1s\n",
      "[CV 1/2; 45/336] START C=0.01, max_iter=2500, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 45/336] END C=0.01, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 45/336] START C=0.01, max_iter=2500, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 45/336] END C=0.01, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 46/336] START C=0.01, max_iter=2500, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 40/336] END C=0.01, max_iter=500, penalty=none, solver=saga;, score=-1.001 total time=   6.1s\n",
      "[CV 2/2; 46/336] START C=0.01, max_iter=2500, penalty=l1, solver=saga...........\n",
      "[CV 1/2; 46/336] END C=0.01, max_iter=2500, penalty=l1, solver=saga;, score=-0.956 total time=   0.0s\n",
      "[CV 1/2; 47/336] START C=0.01, max_iter=2500, penalty=l2, solver=saga...........\n",
      "[CV 2/2; 46/336] END C=0.01, max_iter=2500, penalty=l1, solver=saga;, score=-1.049 total time=   0.0s\n",
      "[CV 2/2; 47/336] START C=0.01, max_iter=2500, penalty=l2, solver=saga...........\n",
      "[CV 2/2; 20/336] END C=0.001, max_iter=1000, penalty=none, solver=saga;, score=-1.027 total time=  12.1s\n",
      "[CV 1/2; 48/336] START C=0.01, max_iter=2500, penalty=none, solver=saga.........\n",
      "[CV 1/2; 20/336] END C=0.001, max_iter=1000, penalty=none, solver=saga;, score=-0.991 total time=  12.2s\n",
      "[CV 2/2; 48/336] START C=0.01, max_iter=2500, penalty=none, solver=saga.........\n",
      "[CV 1/2; 47/336] END C=0.01, max_iter=2500, penalty=l2, solver=saga;, score=-0.948 total time=   0.2s\n",
      "[CV 1/2; 49/336] START C=0.1, max_iter=50, penalty=elasticnet, solver=saga......\n",
      "[CV 1/2; 49/336] END C=0.1, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 49/336] START C=0.1, max_iter=50, penalty=elasticnet, solver=saga......\n",
      "[CV 2/2; 49/336] END C=0.1, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 50/336] START C=0.1, max_iter=50, penalty=l1, solver=saga..............\n",
      "[CV 2/2; 47/336] END C=0.01, max_iter=2500, penalty=l2, solver=saga;, score=-0.950 total time=   0.3s\n",
      "[CV 2/2; 50/336] START C=0.1, max_iter=50, penalty=l1, solver=saga..............\n",
      "[CV 2/2; 50/336] END C=0.1, max_iter=50, penalty=l1, solver=saga;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 51/336] START C=0.1, max_iter=50, penalty=l2, solver=saga..............\n",
      "[CV 1/2; 50/336] END C=0.1, max_iter=50, penalty=l1, solver=saga;, score=-0.949 total time=   0.1s\n",
      "[CV 2/2; 51/336] START C=0.1, max_iter=50, penalty=l2, solver=saga..............\n",
      "[CV 1/2; 51/336] END C=0.1, max_iter=50, penalty=l2, solver=saga;, score=-0.948 total time=   0.2s\n",
      "[CV 1/2; 52/336] START C=0.1, max_iter=50, penalty=none, solver=saga............\n",
      "[CV 2/2; 51/336] END C=0.1, max_iter=50, penalty=l2, solver=saga;, score=-0.952 total time=   0.3s\n",
      "[CV 2/2; 52/336] START C=0.1, max_iter=50, penalty=none, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 52/336] END C=0.1, max_iter=50, penalty=none, solver=saga;, score=-0.948 total time=   0.6s\n",
      "[CV 1/2; 53/336] START C=0.1, max_iter=100, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 53/336] END C=0.1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 53/336] START C=0.1, max_iter=100, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 53/336] END C=0.1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 54/336] START C=0.1, max_iter=100, penalty=l1, solver=saga.............\n",
      "[CV 2/2; 52/336] END C=0.1, max_iter=50, penalty=none, solver=saga;, score=-0.969 total time=   0.6s\n",
      "[CV 2/2; 54/336] START C=0.1, max_iter=100, penalty=l1, solver=saga.............\n",
      "[CV 1/2; 54/336] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=-0.949 total time=   0.1s\n",
      "[CV 1/2; 55/336] START C=0.1, max_iter=100, penalty=l2, solver=saga.............\n",
      "[CV 2/2; 54/336] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=-0.952 total time=   0.1s\n",
      "[CV 2/2; 55/336] START C=0.1, max_iter=100, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 55/336] END C=0.1, max_iter=100, penalty=l2, solver=saga;, score=-0.948 total time=   0.2s\n",
      "[CV 1/2; 56/336] START C=0.1, max_iter=100, penalty=none, solver=saga...........\n",
      "[CV 2/2; 55/336] END C=0.1, max_iter=100, penalty=l2, solver=saga;, score=-0.952 total time=   0.3s\n",
      "[CV 2/2; 56/336] START C=0.1, max_iter=100, penalty=none, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 56/336] END C=0.1, max_iter=100, penalty=none, solver=saga;, score=-0.953 total time=   1.2s\n",
      "[CV 1/2; 57/336] START C=0.1, max_iter=200, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 56/336] END C=0.1, max_iter=100, penalty=none, solver=saga;, score=-0.974 total time=   1.2s\n",
      "[CV 1/2; 57/336] END C=0.1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 58/336] START C=0.1, max_iter=200, penalty=l1, solver=saga.............\n",
      "[CV 2/2; 57/336] START C=0.1, max_iter=200, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 57/336] END C=0.1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 58/336] START C=0.1, max_iter=200, penalty=l1, solver=saga.............\n",
      "[CV 1/2; 58/336] END C=0.1, max_iter=200, penalty=l1, solver=saga;, score=-0.949 total time=   0.1s\n",
      "[CV 1/2; 59/336] START C=0.1, max_iter=200, penalty=l2, solver=saga.............\n",
      "[CV 2/2; 58/336] END C=0.1, max_iter=200, penalty=l1, solver=saga;, score=-0.950 total time=   0.1s\n",
      "[CV 2/2; 59/336] START C=0.1, max_iter=200, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 59/336] END C=0.1, max_iter=200, penalty=l2, solver=saga;, score=-0.948 total time=   0.3s\n",
      "[CV 1/2; 60/336] START C=0.1, max_iter=200, penalty=none, solver=saga...........\n",
      "[CV 2/2; 59/336] END C=0.1, max_iter=200, penalty=l2, solver=saga;, score=-0.952 total time=   0.3s\n",
      "[CV 2/2; 60/336] START C=0.1, max_iter=200, penalty=none, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 60/336] END C=0.1, max_iter=200, penalty=none, solver=saga;, score=-0.960 total time=   2.4s\n",
      "[CV 1/2; 61/336] START C=0.1, max_iter=500, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 61/336] END C=0.1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 61/336] START C=0.1, max_iter=500, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 61/336] END C=0.1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 62/336] START C=0.1, max_iter=500, penalty=l1, solver=saga.............\n",
      "[CV 2/2; 60/336] END C=0.1, max_iter=200, penalty=none, solver=saga;, score=-0.982 total time=   2.4s\n",
      "[CV 2/2; 62/336] START C=0.1, max_iter=500, penalty=l1, solver=saga.............\n",
      "[CV 1/2; 62/336] END C=0.1, max_iter=500, penalty=l1, solver=saga;, score=-0.949 total time=   0.1s\n",
      "[CV 1/2; 63/336] START C=0.1, max_iter=500, penalty=l2, solver=saga.............\n",
      "[CV 2/2; 62/336] END C=0.1, max_iter=500, penalty=l1, solver=saga;, score=-0.950 total time=   0.1s\n",
      "[CV 2/2; 63/336] START C=0.1, max_iter=500, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 63/336] END C=0.1, max_iter=500, penalty=l2, solver=saga;, score=-0.948 total time=   0.3s\n",
      "[CV 1/2; 64/336] START C=0.1, max_iter=500, penalty=none, solver=saga...........\n",
      "[CV 2/2; 63/336] END C=0.1, max_iter=500, penalty=l2, solver=saga;, score=-0.952 total time=   0.3s\n",
      "[CV 2/2; 64/336] START C=0.1, max_iter=500, penalty=none, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 44/336] END C=0.01, max_iter=1000, penalty=none, solver=saga;, score=-1.027 total time=  11.9s\n",
      "[CV 1/2; 65/336] START C=0.1, max_iter=1000, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 65/336] END C=0.1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 65/336] START C=0.1, max_iter=1000, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 65/336] END C=0.1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 44/336] END C=0.01, max_iter=1000, penalty=none, solver=saga;, score=-0.991 total time=  12.0s\n",
      "[CV 1/2; 66/336] START C=0.1, max_iter=1000, penalty=l1, solver=saga............\n",
      "[CV 2/2; 66/336] START C=0.1, max_iter=1000, penalty=l1, solver=saga............\n",
      "[CV 1/2; 66/336] END C=0.1, max_iter=1000, penalty=l1, solver=saga;, score=-0.949 total time=   0.1s\n",
      "[CV 1/2; 67/336] START C=0.1, max_iter=1000, penalty=l2, solver=saga............\n",
      "[CV 2/2; 66/336] END C=0.1, max_iter=1000, penalty=l1, solver=saga;, score=-0.950 total time=   0.1s\n",
      "[CV 2/2; 67/336] START C=0.1, max_iter=1000, penalty=l2, solver=saga............\n",
      "[CV 1/2; 67/336] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=-0.948 total time=   0.2s\n",
      "[CV 1/2; 68/336] START C=0.1, max_iter=1000, penalty=none, solver=saga..........\n",
      "[CV 2/2; 67/336] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=-0.952 total time=   0.2s\n",
      "[CV 2/2; 68/336] START C=0.1, max_iter=1000, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 64/336] END C=0.1, max_iter=500, penalty=none, solver=saga;, score=-1.001 total time=   5.8s\n",
      "[CV 1/2; 69/336] START C=0.1, max_iter=2500, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 64/336] END C=0.1, max_iter=500, penalty=none, solver=saga;, score=-0.975 total time=   5.9s\n",
      "[CV 1/2; 69/336] END C=0.1, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 69/336] START C=0.1, max_iter=2500, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 70/336] START C=0.1, max_iter=2500, penalty=l1, solver=saga............\n",
      "[CV 2/2; 69/336] END C=0.1, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 70/336] START C=0.1, max_iter=2500, penalty=l1, solver=saga............\n",
      "[CV 1/2; 70/336] END C=0.1, max_iter=2500, penalty=l1, solver=saga;, score=-0.949 total time=   0.1s\n",
      "[CV 1/2; 71/336] START C=0.1, max_iter=2500, penalty=l2, solver=saga............\n",
      "[CV 2/2; 70/336] END C=0.1, max_iter=2500, penalty=l1, solver=saga;, score=-0.950 total time=   0.1s\n",
      "[CV 2/2; 71/336] START C=0.1, max_iter=2500, penalty=l2, solver=saga............\n",
      "[CV 1/2; 71/336] END C=0.1, max_iter=2500, penalty=l2, solver=saga;, score=-0.948 total time=   0.3s\n",
      "[CV 1/2; 72/336] START C=0.1, max_iter=2500, penalty=none, solver=saga..........\n",
      "[CV 2/2; 71/336] END C=0.1, max_iter=2500, penalty=l2, solver=saga;, score=-0.952 total time=   0.3s\n",
      "[CV 2/2; 72/336] START C=0.1, max_iter=2500, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 24/336] END C=0.001, max_iter=2500, penalty=none, solver=saga;, score=-1.080 total time=  30.3s\n",
      "[CV 1/2; 73/336] START C=1, max_iter=50, penalty=elasticnet, solver=saga........\n",
      "[CV 1/2; 73/336] END C=1, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 73/336] START C=1, max_iter=50, penalty=elasticnet, solver=saga........\n",
      "[CV 2/2; 73/336] END C=1, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 74/336] START C=1, max_iter=50, penalty=l1, solver=saga................\n",
      "[CV 1/2; 24/336] END C=0.001, max_iter=2500, penalty=none, solver=saga;, score=-1.027 total time=  30.5s\n",
      "[CV 2/2; 74/336] START C=1, max_iter=50, penalty=l1, solver=saga................\n",
      "[CV 1/2; 74/336] END C=1, max_iter=50, penalty=l1, solver=saga;, score=-0.944 total time=   0.5s\n",
      "[CV 1/2; 75/336] START C=1, max_iter=50, penalty=l2, solver=saga................\n",
      "[CV 1/2; 75/336] END C=1, max_iter=50, penalty=l2, solver=saga;, score=-0.945 total time=   0.3s\n",
      "[CV 2/2; 75/336] START C=1, max_iter=50, penalty=l2, solver=saga................\n",
      "[CV 2/2; 68/336] END C=0.1, max_iter=1000, penalty=none, solver=saga;, score=-1.027 total time=  11.8s\n",
      "[CV 1/2; 76/336] START C=1, max_iter=50, penalty=none, solver=saga..............\n",
      "[CV 2/2; 74/336] END C=1, max_iter=50, penalty=l1, solver=saga;, score=-0.948 total time=   0.8s\n",
      "[CV 2/2; 76/336] START C=1, max_iter=50, penalty=none, solver=saga..............\n",
      "[CV 1/2; 68/336] END C=0.1, max_iter=1000, penalty=none, solver=saga;, score=-0.991 total time=  11.9s\n",
      "[CV 1/2; 77/336] START C=1, max_iter=100, penalty=elasticnet, solver=saga.......\n",
      "[CV 1/2; 77/336] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 77/336] START C=1, max_iter=100, penalty=elasticnet, solver=saga.......\n",
      "[CV 2/2; 77/336] END C=1, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 78/336] START C=1, max_iter=100, penalty=l1, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 75/336] END C=1, max_iter=50, penalty=l2, solver=saga;, score=-0.957 total time=   0.3s\n",
      "[CV 2/2; 78/336] START C=1, max_iter=100, penalty=l1, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 76/336] END C=1, max_iter=50, penalty=none, solver=saga;, score=-0.948 total time=   0.7s\n",
      "[CV 1/2; 79/336] START C=1, max_iter=100, penalty=l2, solver=saga...............\n",
      "[CV 1/2; 78/336] END C=1, max_iter=100, penalty=l1, solver=saga;, score=-0.944 total time=   0.6s\n",
      "[CV 2/2; 79/336] START C=1, max_iter=100, penalty=l2, solver=saga...............\n",
      "[CV 2/2; 76/336] END C=1, max_iter=50, penalty=none, solver=saga;, score=-0.969 total time=   0.7s\n",
      "[CV 1/2; 80/336] START C=1, max_iter=100, penalty=none, solver=saga.............\n",
      "[CV 2/2; 79/336] END C=1, max_iter=100, penalty=l2, solver=saga;, score=-0.957 total time=   0.3s\n",
      "[CV 2/2; 80/336] START C=1, max_iter=100, penalty=none, solver=saga.............\n",
      "[CV 1/2; 79/336] END C=1, max_iter=100, penalty=l2, solver=saga;, score=-0.945 total time=   0.3s\n",
      "[CV 1/2; 81/336] START C=1, max_iter=200, penalty=elasticnet, solver=saga.......\n",
      "[CV 1/2; 81/336] END C=1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 81/336] START C=1, max_iter=200, penalty=elasticnet, solver=saga.......\n",
      "[CV 2/2; 81/336] END C=1, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 82/336] START C=1, max_iter=200, penalty=l1, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 82/336] END C=1, max_iter=200, penalty=l1, solver=saga;, score=-0.944 total time=   0.4s\n",
      "[CV 2/2; 82/336] START C=1, max_iter=200, penalty=l1, solver=saga...............\n",
      "[CV 2/2; 78/336] END C=1, max_iter=100, penalty=l1, solver=saga;, score=-0.948 total time=   1.3s\n",
      "[CV 1/2; 83/336] START C=1, max_iter=200, penalty=l2, solver=saga...............\n",
      "[CV 1/2; 83/336] END C=1, max_iter=200, penalty=l2, solver=saga;, score=-0.945 total time=   0.3s\n",
      "[CV 2/2; 83/336] START C=1, max_iter=200, penalty=l2, solver=saga...............\n",
      "[CV 1/2; 80/336] END C=1, max_iter=100, penalty=none, solver=saga;, score=-0.953 total time=   1.2s\n",
      "[CV 1/2; 84/336] START C=1, max_iter=200, penalty=none, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 83/336] END C=1, max_iter=200, penalty=l2, solver=saga;, score=-0.957 total time=   0.3s\n",
      "[CV 2/2; 84/336] START C=1, max_iter=200, penalty=none, solver=saga.............\n",
      "[CV 2/2; 80/336] END C=1, max_iter=100, penalty=none, solver=saga;, score=-0.974 total time=   1.2s\n",
      "[CV 1/2; 85/336] START C=1, max_iter=500, penalty=elasticnet, solver=saga.......\n",
      "[CV 1/2; 85/336] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 85/336] START C=1, max_iter=500, penalty=elasticnet, solver=saga.......\n",
      "[CV 2/2; 85/336] END C=1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 86/336] START C=1, max_iter=500, penalty=l1, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 86/336] END C=1, max_iter=500, penalty=l1, solver=saga;, score=-0.944 total time=   0.4s\n",
      "[CV 2/2; 86/336] START C=1, max_iter=500, penalty=l1, solver=saga...............\n",
      "[CV 2/2; 82/336] END C=1, max_iter=200, penalty=l1, solver=saga;, score=-0.948 total time=   1.3s\n",
      "[CV 1/2; 87/336] START C=1, max_iter=500, penalty=l2, solver=saga...............\n",
      "[CV 1/2; 87/336] END C=1, max_iter=500, penalty=l2, solver=saga;, score=-0.945 total time=   0.3s\n",
      "[CV 2/2; 87/336] START C=1, max_iter=500, penalty=l2, solver=saga...............\n",
      "[CV 2/2; 87/336] END C=1, max_iter=500, penalty=l2, solver=saga;, score=-0.957 total time=   0.3s\n",
      "[CV 1/2; 88/336] START C=1, max_iter=500, penalty=none, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 86/336] END C=1, max_iter=500, penalty=l1, solver=saga;, score=-0.948 total time=   1.1s\n",
      "[CV 2/2; 88/336] START C=1, max_iter=500, penalty=none, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 84/336] END C=1, max_iter=200, penalty=none, solver=saga;, score=-0.960 total time=   2.5s\n",
      "[CV 1/2; 89/336] START C=1, max_iter=1000, penalty=elasticnet, solver=saga......\n",
      "[CV 1/2; 89/336] END C=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 89/336] START C=1, max_iter=1000, penalty=elasticnet, solver=saga......\n",
      "[CV 2/2; 89/336] END C=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 90/336] START C=1, max_iter=1000, penalty=l1, solver=saga..............\n",
      "[CV 2/2; 84/336] END C=1, max_iter=200, penalty=none, solver=saga;, score=-0.982 total time=   2.6s\n",
      "[CV 2/2; 90/336] START C=1, max_iter=1000, penalty=l1, solver=saga..............\n",
      "[CV 1/2; 90/336] END C=1, max_iter=1000, penalty=l1, solver=saga;, score=-0.944 total time=   0.5s\n",
      "[CV 1/2; 91/336] START C=1, max_iter=1000, penalty=l2, solver=saga..............\n",
      "[CV 1/2; 91/336] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=-0.945 total time=   0.3s\n",
      "[CV 2/2; 91/336] START C=1, max_iter=1000, penalty=l2, solver=saga..............\n",
      "[CV 2/2; 91/336] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=-0.957 total time=   0.3s\n",
      "[CV 1/2; 92/336] START C=1, max_iter=1000, penalty=none, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 90/336] END C=1, max_iter=1000, penalty=l1, solver=saga;, score=-0.948 total time=   1.2s\n",
      "[CV 2/2; 92/336] START C=1, max_iter=1000, penalty=none, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 88/336] END C=1, max_iter=500, penalty=none, solver=saga;, score=-0.975 total time=   6.3s\n",
      "[CV 1/2; 93/336] START C=1, max_iter=2500, penalty=elasticnet, solver=saga......\n",
      "[CV 1/2; 93/336] END C=1, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 93/336] START C=1, max_iter=2500, penalty=elasticnet, solver=saga......\n",
      "[CV 2/2; 93/336] END C=1, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 94/336] START C=1, max_iter=2500, penalty=l1, solver=saga..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 88/336] END C=1, max_iter=500, penalty=none, solver=saga;, score=-1.001 total time=   6.2s\n",
      "[CV 2/2; 94/336] START C=1, max_iter=2500, penalty=l1, solver=saga..............\n",
      "[CV 1/2; 94/336] END C=1, max_iter=2500, penalty=l1, solver=saga;, score=-0.944 total time=   0.5s\n",
      "[CV 1/2; 95/336] START C=1, max_iter=2500, penalty=l2, solver=saga..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 48/336] END C=0.01, max_iter=2500, penalty=none, solver=saga;, score=-1.027 total time=  30.1s\n",
      "[CV 2/2; 95/336] START C=1, max_iter=2500, penalty=l2, solver=saga..............\n",
      "[CV 1/2; 95/336] END C=1, max_iter=2500, penalty=l2, solver=saga;, score=-0.945 total time=   0.3s\n",
      "[CV 1/2; 96/336] START C=1, max_iter=2500, penalty=none, solver=saga............\n",
      "[CV 2/2; 95/336] END C=1, max_iter=2500, penalty=l2, solver=saga;, score=-0.957 total time=   0.3s\n",
      "[CV 2/2; 96/336] START C=1, max_iter=2500, penalty=none, solver=saga............\n",
      "[CV 2/2; 48/336] END C=0.01, max_iter=2500, penalty=none, solver=saga;, score=-1.080 total time=  30.5s\n",
      "[CV 1/2; 97/336] START C=10, max_iter=50, penalty=elasticnet, solver=saga.......\n",
      "[CV 1/2; 97/336] END C=10, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 97/336] START C=10, max_iter=50, penalty=elasticnet, solver=saga.......\n",
      "[CV 2/2; 97/336] END C=10, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 98/336] START C=10, max_iter=50, penalty=l1, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 94/336] END C=1, max_iter=2500, penalty=l1, solver=saga;, score=-0.948 total time=   1.2s\n",
      "[CV 2/2; 98/336] START C=10, max_iter=50, penalty=l1, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 98/336] END C=10, max_iter=50, penalty=l1, solver=saga;, score=-0.942 total time=   0.9s\n",
      "[CV 1/2; 99/336] START C=10, max_iter=50, penalty=l2, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 98/336] END C=10, max_iter=50, penalty=l1, solver=saga;, score=-0.956 total time=   0.9s\n",
      "[CV 2/2; 99/336] START C=10, max_iter=50, penalty=l2, solver=saga...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 99/336] END C=10, max_iter=50, penalty=l2, solver=saga;, score=-0.944 total time=   0.6s\n",
      "[CV 1/2; 100/336] START C=10, max_iter=50, penalty=none, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 99/336] END C=10, max_iter=50, penalty=l2, solver=saga;, score=-0.963 total time=   0.6s\n",
      "[CV 2/2; 100/336] START C=10, max_iter=50, penalty=none, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 100/336] END C=10, max_iter=50, penalty=none, solver=saga;, score=-0.948 total time=   0.6s\n",
      "[CV 1/2; 101/336] START C=10, max_iter=100, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 101/336] END C=10, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 101/336] START C=10, max_iter=100, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 101/336] END C=10, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 102/336] START C=10, max_iter=100, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 100/336] END C=10, max_iter=50, penalty=none, solver=saga;, score=-0.969 total time=   0.6s\n",
      "[CV 2/2; 102/336] START C=10, max_iter=100, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 102/336] END C=10, max_iter=100, penalty=l1, solver=saga;, score=-0.943 total time=   1.6s\n",
      "[CV 1/2; 103/336] START C=10, max_iter=100, penalty=l2, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 102/336] END C=10, max_iter=100, penalty=l1, solver=saga;, score=-0.957 total time=   1.6s\n",
      "[CV 2/2; 103/336] START C=10, max_iter=100, penalty=l2, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 103/336] END C=10, max_iter=100, penalty=l2, solver=saga;, score=-0.944 total time=   1.2s\n",
      "[CV 1/2; 104/336] START C=10, max_iter=100, penalty=none, solver=saga...........\n",
      "[CV 2/2; 103/336] END C=10, max_iter=100, penalty=l2, solver=saga;, score=-0.963 total time=   1.3s\n",
      "[CV 2/2; 104/336] START C=10, max_iter=100, penalty=none, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 104/336] END C=10, max_iter=100, penalty=none, solver=saga;, score=-0.953 total time=   1.2s\n",
      "[CV 1/2; 105/336] START C=10, max_iter=200, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 105/336] END C=10, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 105/336] START C=10, max_iter=200, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 105/336] END C=10, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 106/336] START C=10, max_iter=200, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 104/336] END C=10, max_iter=100, penalty=none, solver=saga;, score=-0.974 total time=   1.2s\n",
      "[CV 2/2; 106/336] START C=10, max_iter=200, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 92/336] END C=1, max_iter=1000, penalty=none, solver=saga;, score=-0.991 total time=  12.3s\n",
      "[CV 1/2; 107/336] START C=10, max_iter=200, penalty=l2, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 92/336] END C=1, max_iter=1000, penalty=none, solver=saga;, score=-1.027 total time=  12.3s\n",
      "[CV 2/2; 107/336] START C=10, max_iter=200, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 107/336] END C=10, max_iter=200, penalty=l2, solver=saga;, score=-0.944 total time=   1.3s\n",
      "[CV 1/2; 108/336] START C=10, max_iter=200, penalty=none, solver=saga...........\n",
      "[CV 2/2; 107/336] END C=10, max_iter=200, penalty=l2, solver=saga;, score=-0.963 total time=   1.2s\n",
      "[CV 2/2; 108/336] START C=10, max_iter=200, penalty=none, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 106/336] END C=10, max_iter=200, penalty=l1, solver=saga;, score=-0.943 total time=   3.3s\n",
      "[CV 1/2; 109/336] START C=10, max_iter=500, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 109/336] END C=10, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 109/336] START C=10, max_iter=500, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 109/336] END C=10, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 110/336] START C=10, max_iter=500, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 106/336] END C=10, max_iter=200, penalty=l1, solver=saga;, score=-0.958 total time=   3.4s\n",
      "[CV 2/2; 110/336] START C=10, max_iter=500, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 108/336] END C=10, max_iter=200, penalty=none, solver=saga;, score=-0.960 total time=   2.5s\n",
      "[CV 1/2; 111/336] START C=10, max_iter=500, penalty=l2, solver=saga.............\n",
      "[CV 2/2; 108/336] END C=10, max_iter=200, penalty=none, solver=saga;, score=-0.982 total time=   2.4s\n",
      "[CV 2/2; 111/336] START C=10, max_iter=500, penalty=l2, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 72/336] END C=0.1, max_iter=2500, penalty=none, solver=saga;, score=-1.080 total time=  30.3s\n",
      "[CV 1/2; 111/336] END C=10, max_iter=500, penalty=l2, solver=saga;, score=-0.944 total time=   1.3s\n",
      "[CV 1/2; 112/336] START C=10, max_iter=500, penalty=none, solver=saga...........\n",
      "[CV 2/2; 112/336] START C=10, max_iter=500, penalty=none, solver=saga...........\n",
      "[CV 2/2; 111/336] END C=10, max_iter=500, penalty=l2, solver=saga;, score=-0.963 total time=   1.2s\n",
      "[CV 1/2; 113/336] START C=10, max_iter=1000, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 113/336] END C=10, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 113/336] START C=10, max_iter=1000, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 113/336] END C=10, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 72/336] END C=0.1, max_iter=2500, penalty=none, solver=saga;, score=-1.027 total time=  30.4s\n",
      "[CV 1/2; 114/336] START C=10, max_iter=1000, penalty=l1, solver=saga............\n",
      "[CV 2/2; 114/336] START C=10, max_iter=1000, penalty=l1, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 110/336] END C=10, max_iter=500, penalty=l1, solver=saga;, score=-0.944 total time=   8.1s\n",
      "[CV 1/2; 115/336] START C=10, max_iter=1000, penalty=l2, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 112/336] END C=10, max_iter=500, penalty=none, solver=saga;, score=-0.975 total time=   5.9s\n",
      "[CV 2/2; 115/336] START C=10, max_iter=1000, penalty=l2, solver=saga............\n",
      "[CV 2/2; 112/336] END C=10, max_iter=500, penalty=none, solver=saga;, score=-1.001 total time=   6.1s\n",
      "[CV 1/2; 116/336] START C=10, max_iter=1000, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 110/336] END C=10, max_iter=500, penalty=l1, solver=saga;, score=-0.959 total time=   8.2s\n",
      "[CV 2/2; 116/336] START C=10, max_iter=1000, penalty=none, solver=saga..........\n",
      "[CV 1/2; 115/336] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=-0.944 total time=   1.5s\n",
      "[CV 1/2; 117/336] START C=10, max_iter=2500, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 117/336] END C=10, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 117/336] START C=10, max_iter=2500, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 117/336] END C=10, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 118/336] START C=10, max_iter=2500, penalty=l1, solver=saga............\n",
      "[CV 2/2; 115/336] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=-0.963 total time=   1.3s\n",
      "[CV 2/2; 118/336] START C=10, max_iter=2500, penalty=l1, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 114/336] END C=10, max_iter=1000, penalty=l1, solver=saga;, score=-0.944 total time=  16.6s\n",
      "[CV 1/2; 119/336] START C=10, max_iter=2500, penalty=l2, solver=saga............\n",
      "[CV 2/2; 114/336] END C=10, max_iter=1000, penalty=l1, solver=saga;, score=-0.959 total time=  16.8s\n",
      "[CV 2/2; 119/336] START C=10, max_iter=2500, penalty=l2, solver=saga............\n",
      "[CV 1/2; 119/336] END C=10, max_iter=2500, penalty=l2, solver=saga;, score=-0.944 total time=   1.3s\n",
      "[CV 1/2; 120/336] START C=10, max_iter=2500, penalty=none, solver=saga..........\n",
      "[CV 2/2; 119/336] END C=10, max_iter=2500, penalty=l2, solver=saga;, score=-0.963 total time=   1.2s\n",
      "[CV 2/2; 120/336] START C=10, max_iter=2500, penalty=none, solver=saga..........\n",
      "[CV 1/2; 96/336] END C=1, max_iter=2500, penalty=none, solver=saga;, score=-1.027 total time=  30.5s\n",
      "[CV 1/2; 121/336] START C=100, max_iter=50, penalty=elasticnet, solver=saga.....\n",
      "[CV 1/2; 121/336] END C=100, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 121/336] START C=100, max_iter=50, penalty=elasticnet, solver=saga.....\n",
      "[CV 2/2; 121/336] END C=100, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 122/336] START C=100, max_iter=50, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 96/336] END C=1, max_iter=2500, penalty=none, solver=saga;, score=-1.080 total time=  30.6s\n",
      "[CV 2/2; 122/336] START C=100, max_iter=50, penalty=l1, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 116/336] END C=10, max_iter=1000, penalty=none, solver=saga;, score=-1.027 total time=  12.7s\n",
      "[CV 1/2; 123/336] START C=100, max_iter=50, penalty=l2, solver=saga.............\n",
      "[CV 1/2; 116/336] END C=10, max_iter=1000, penalty=none, solver=saga;, score=-0.991 total time=  12.9s\n",
      "[CV 2/2; 123/336] START C=100, max_iter=50, penalty=l2, solver=saga.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 122/336] END C=100, max_iter=50, penalty=l1, solver=saga;, score=-0.946 total time=   1.1s\n",
      "[CV 1/2; 124/336] START C=100, max_iter=50, penalty=none, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 122/336] END C=100, max_iter=50, penalty=l1, solver=saga;, score=-0.967 total time=   1.0s\n",
      "[CV 2/2; 124/336] START C=100, max_iter=50, penalty=none, solver=saga...........\n",
      "[CV 2/2; 123/336] END C=100, max_iter=50, penalty=l2, solver=saga;, score=-0.968 total time=   0.6s\n",
      "[CV 1/2; 123/336] END C=100, max_iter=50, penalty=l2, solver=saga;, score=-0.947 total time=   0.7s\n",
      "[CV 2/2; 125/336] START C=100, max_iter=100, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 125/336] START C=100, max_iter=100, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 125/336] END C=100, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 126/336] START C=100, max_iter=100, penalty=l1, solver=saga............\n",
      "[CV 1/2; 125/336] END C=100, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 126/336] START C=100, max_iter=100, penalty=l1, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 124/336] END C=100, max_iter=50, penalty=none, solver=saga;, score=-0.948 total time=   0.6s\n",
      "[CV 1/2; 127/336] START C=100, max_iter=100, penalty=l2, solver=saga............\n",
      "[CV 2/2; 124/336] END C=100, max_iter=50, penalty=none, solver=saga;, score=-0.970 total time=   0.6s\n",
      "[CV 2/2; 127/336] START C=100, max_iter=100, penalty=l2, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 127/336] END C=100, max_iter=100, penalty=l2, solver=saga;, score=-0.950 total time=   1.2s\n",
      "[CV 1/2; 128/336] START C=100, max_iter=100, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 127/336] END C=100, max_iter=100, penalty=l2, solver=saga;, score=-0.971 total time=   1.3s\n",
      "[CV 2/2; 128/336] START C=100, max_iter=100, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 126/336] END C=100, max_iter=100, penalty=l1, solver=saga;, score=-0.950 total time=   2.0s\n",
      "[CV 1/2; 129/336] START C=100, max_iter=200, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 129/336] END C=100, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 129/336] START C=100, max_iter=200, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 129/336] END C=100, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 130/336] START C=100, max_iter=200, penalty=l1, solver=saga............\n",
      "[CV 2/2; 126/336] END C=100, max_iter=100, penalty=l1, solver=saga;, score=-0.969 total time=   2.0s\n",
      "[CV 2/2; 130/336] START C=100, max_iter=200, penalty=l1, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 128/336] END C=100, max_iter=100, penalty=none, solver=saga;, score=-0.953 total time=   1.3s\n",
      "[CV 1/2; 131/336] START C=100, max_iter=200, penalty=l2, solver=saga............\n",
      "[CV 2/2; 128/336] END C=100, max_iter=100, penalty=none, solver=saga;, score=-0.974 total time=   1.2s\n",
      "[CV 2/2; 131/336] START C=100, max_iter=200, penalty=l2, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 131/336] END C=100, max_iter=200, penalty=l2, solver=saga;, score=-0.953 total time=   2.4s\n",
      "[CV 1/2; 132/336] START C=100, max_iter=200, penalty=none, solver=saga..........\n",
      "[CV 2/2; 131/336] END C=100, max_iter=200, penalty=l2, solver=saga;, score=-0.973 total time=   2.4s\n",
      "[CV 2/2; 132/336] START C=100, max_iter=200, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 130/336] END C=100, max_iter=200, penalty=l1, solver=saga;, score=-0.956 total time=   3.9s\n",
      "[CV 1/2; 133/336] START C=100, max_iter=500, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 133/336] END C=100, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 133/336] START C=100, max_iter=500, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 133/336] END C=100, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 134/336] START C=100, max_iter=500, penalty=l1, solver=saga............\n",
      "[CV 2/2; 130/336] END C=100, max_iter=200, penalty=l1, solver=saga;, score=-0.972 total time=   4.0s\n",
      "[CV 2/2; 134/336] START C=100, max_iter=500, penalty=l1, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 132/336] END C=100, max_iter=200, penalty=none, solver=saga;, score=-0.960 total time=   2.4s\n",
      "[CV 1/2; 135/336] START C=100, max_iter=500, penalty=l2, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 132/336] END C=100, max_iter=200, penalty=none, solver=saga;, score=-0.982 total time=   2.5s\n",
      "[CV 2/2; 135/336] START C=100, max_iter=500, penalty=l2, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 135/336] END C=100, max_iter=500, penalty=l2, solver=saga;, score=-0.956 total time=   5.8s\n",
      "[CV 1/2; 136/336] START C=100, max_iter=500, penalty=none, solver=saga..........\n",
      "[CV 2/2; 135/336] END C=100, max_iter=500, penalty=l2, solver=saga;, score=-0.975 total time=   5.8s\n",
      "[CV 2/2; 136/336] START C=100, max_iter=500, penalty=none, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 134/336] END C=100, max_iter=500, penalty=l1, solver=saga;, score=-0.980 total time=   9.3s\n",
      "[CV 1/2; 137/336] START C=100, max_iter=1000, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 137/336] END C=100, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 137/336] START C=100, max_iter=1000, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 134/336] END C=100, max_iter=500, penalty=l1, solver=saga;, score=-0.963 total time=   9.4s\n",
      "[CV 2/2; 137/336] END C=100, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 138/336] START C=100, max_iter=1000, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 138/336] START C=100, max_iter=1000, penalty=l1, solver=saga...........\n",
      "[CV 1/2; 118/336] END C=10, max_iter=2500, penalty=l1, solver=saga;, score=-0.944 total time=  30.8s\n",
      "[CV 1/2; 139/336] START C=100, max_iter=1000, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 136/336] END C=100, max_iter=500, penalty=none, solver=saga;, score=-0.975 total time=   6.0s\n",
      "[CV 2/2; 139/336] START C=100, max_iter=1000, penalty=l2, solver=saga...........\n",
      "[CV 2/2; 136/336] END C=100, max_iter=500, penalty=none, solver=saga;, score=-1.001 total time=   5.9s\n",
      "[CV 1/2; 140/336] START C=100, max_iter=1000, penalty=none, solver=saga.........\n",
      "[CV 1/2; 139/336] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=-0.956 total time=   7.2s\n",
      "[CV 2/2; 140/336] START C=100, max_iter=1000, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 139/336] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=-0.975 total time=   7.9s\n",
      "[CV 1/2; 141/336] START C=100, max_iter=2500, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 141/336] END C=100, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 141/336] START C=100, max_iter=2500, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 141/336] END C=100, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 142/336] START C=100, max_iter=2500, penalty=l1, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 120/336] END C=10, max_iter=2500, penalty=none, solver=saga;, score=-1.027 total time=  29.6s\n",
      "[CV 2/2; 142/336] START C=100, max_iter=2500, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 118/336] END C=10, max_iter=2500, penalty=l1, solver=saga;, score=-0.960 total time=  40.5s\n",
      "[CV 1/2; 143/336] START C=100, max_iter=2500, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 120/336] END C=10, max_iter=2500, penalty=none, solver=saga;, score=-1.080 total time=  29.8s\n",
      "[CV 2/2; 143/336] START C=100, max_iter=2500, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 140/336] END C=100, max_iter=1000, penalty=none, solver=saga;, score=-0.991 total time=  11.9s\n",
      "[CV 1/2; 144/336] START C=100, max_iter=2500, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 138/336] END C=100, max_iter=1000, penalty=l1, solver=saga;, score=-0.987 total time=  18.4s\n",
      "[CV 2/2; 144/336] START C=100, max_iter=2500, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 138/336] END C=100, max_iter=1000, penalty=l1, solver=saga;, score=-0.969 total time=  18.6s\n",
      "[CV 1/2; 145/336] START C=1000, max_iter=50, penalty=elasticnet, solver=saga....\n",
      "[CV 1/2; 145/336] END C=1000, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 145/336] START C=1000, max_iter=50, penalty=elasticnet, solver=saga....\n",
      "[CV 2/2; 145/336] END C=1000, max_iter=50, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 146/336] START C=1000, max_iter=50, penalty=l1, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 146/336] END C=1000, max_iter=50, penalty=l1, solver=saga;, score=-0.948 total time=   1.0s\n",
      "[CV 2/2; 146/336] START C=1000, max_iter=50, penalty=l1, solver=saga............\n",
      "[CV 1/2; 143/336] END C=100, max_iter=2500, penalty=l2, solver=saga;, score=-0.956 total time=   7.4s\n",
      "[CV 1/2; 147/336] START C=1000, max_iter=50, penalty=l2, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 146/336] END C=1000, max_iter=50, penalty=l1, solver=saga;, score=-0.969 total time=   0.9s\n",
      "[CV 2/2; 147/336] START C=1000, max_iter=50, penalty=l2, solver=saga............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 147/336] END C=1000, max_iter=50, penalty=l2, solver=saga;, score=-0.948 total time=   0.6s\n",
      "[CV 1/2; 148/336] START C=1000, max_iter=50, penalty=none, solver=saga..........\n",
      "[CV 2/2; 143/336] END C=100, max_iter=2500, penalty=l2, solver=saga;, score=-0.975 total time=   8.2s\n",
      "[CV 2/2; 148/336] START C=1000, max_iter=50, penalty=none, solver=saga..........\n",
      "[CV 2/2; 147/336] END C=1000, max_iter=50, penalty=l2, solver=saga;, score=-0.969 total time=   0.7s\n",
      "[CV 1/2; 149/336] START C=1000, max_iter=100, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 149/336] END C=1000, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 149/336] START C=1000, max_iter=100, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 149/336] END C=1000, max_iter=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 150/336] START C=1000, max_iter=100, penalty=l1, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 148/336] END C=1000, max_iter=50, penalty=none, solver=saga;, score=-0.948 total time=   0.8s\n",
      "[CV 2/2; 150/336] START C=1000, max_iter=100, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 148/336] END C=1000, max_iter=50, penalty=none, solver=saga;, score=-0.970 total time=   0.6s\n",
      "[CV 1/2; 151/336] START C=1000, max_iter=100, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 140/336] END C=100, max_iter=1000, penalty=none, solver=saga;, score=-1.027 total time=  12.0s\n",
      "[CV 2/2; 151/336] START C=1000, max_iter=100, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 151/336] END C=1000, max_iter=100, penalty=l2, solver=saga;, score=-0.952 total time=   1.1s\n",
      "[CV 1/2; 152/336] START C=1000, max_iter=100, penalty=none, solver=saga.........\n",
      "[CV 1/2; 150/336] END C=1000, max_iter=100, penalty=l1, solver=saga;, score=-0.953 total time=   1.9s\n",
      "[CV 2/2; 152/336] START C=1000, max_iter=100, penalty=none, solver=saga.........\n",
      "[CV 2/2; 151/336] END C=1000, max_iter=100, penalty=l2, solver=saga;, score=-0.973 total time=   1.3s\n",
      "[CV 1/2; 153/336] START C=1000, max_iter=200, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 153/336] END C=1000, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 153/336] START C=1000, max_iter=200, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 153/336] END C=1000, max_iter=200, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 154/336] START C=1000, max_iter=200, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 150/336] END C=1000, max_iter=100, penalty=l1, solver=saga;, score=-0.973 total time=   2.0s\n",
      "[CV 2/2; 154/336] START C=1000, max_iter=200, penalty=l1, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 152/336] END C=1000, max_iter=100, penalty=none, solver=saga;, score=-0.953 total time=   1.3s\n",
      "[CV 1/2; 155/336] START C=1000, max_iter=200, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 152/336] END C=1000, max_iter=100, penalty=none, solver=saga;, score=-0.974 total time=   1.3s\n",
      "[CV 2/2; 155/336] START C=1000, max_iter=200, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 155/336] END C=1000, max_iter=200, penalty=l2, solver=saga;, score=-0.959 total time=   2.4s\n",
      "[CV 1/2; 156/336] START C=1000, max_iter=200, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 155/336] END C=1000, max_iter=200, penalty=l2, solver=saga;, score=-0.980 total time=   2.4s\n",
      "[CV 2/2; 156/336] START C=1000, max_iter=200, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 154/336] END C=1000, max_iter=200, penalty=l1, solver=saga;, score=-0.960 total time=   3.9s\n",
      "[CV 1/2; 157/336] START C=1000, max_iter=500, penalty=elasticnet, solver=saga...\n",
      "[CV 1/2; 157/336] END C=1000, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 157/336] START C=1000, max_iter=500, penalty=elasticnet, solver=saga...\n",
      "[CV 2/2; 157/336] END C=1000, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 158/336] START C=1000, max_iter=500, penalty=l1, solver=saga...........\n",
      "[CV 2/2; 154/336] END C=1000, max_iter=200, penalty=l1, solver=saga;, score=-0.980 total time=   3.9s\n",
      "[CV 2/2; 158/336] START C=1000, max_iter=500, penalty=l1, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 156/336] END C=1000, max_iter=200, penalty=none, solver=saga;, score=-0.960 total time=   2.3s\n",
      "[CV 1/2; 159/336] START C=1000, max_iter=500, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 156/336] END C=1000, max_iter=200, penalty=none, solver=saga;, score=-0.982 total time=   2.4s\n",
      "[CV 2/2; 159/336] START C=1000, max_iter=500, penalty=l2, solver=saga...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 159/336] END C=1000, max_iter=500, penalty=l2, solver=saga;, score=-0.971 total time=   6.3s\n",
      "[CV 1/2; 160/336] START C=1000, max_iter=500, penalty=none, solver=saga.........\n",
      "[CV 2/2; 159/336] END C=1000, max_iter=500, penalty=l2, solver=saga;, score=-0.995 total time=   5.9s\n",
      "[CV 2/2; 160/336] START C=1000, max_iter=500, penalty=none, solver=saga.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 158/336] END C=1000, max_iter=500, penalty=l1, solver=saga;, score=-0.973 total time=   9.7s\n",
      "[CV 1/2; 161/336] START C=1000, max_iter=1000, penalty=elasticnet, solver=saga..\n",
      "[CV 1/2; 161/336] END C=1000, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 161/336] START C=1000, max_iter=1000, penalty=elasticnet, solver=saga..\n",
      "[CV 2/2; 161/336] END C=1000, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 162/336] START C=1000, max_iter=1000, penalty=l1, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 158/336] END C=1000, max_iter=500, penalty=l1, solver=saga;, score=-0.997 total time=   9.9s\n",
      "[CV 2/2; 162/336] START C=1000, max_iter=1000, penalty=l1, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 160/336] END C=1000, max_iter=500, penalty=none, solver=saga;, score=-0.975 total time=   6.1s\n",
      "[CV 1/2; 163/336] START C=1000, max_iter=1000, penalty=l2, solver=saga..........\n",
      "[CV 2/2; 160/336] END C=1000, max_iter=500, penalty=none, solver=saga;, score=-1.001 total time=   6.0s\n",
      "[CV 2/2; 163/336] START C=1000, max_iter=1000, penalty=l2, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 144/336] END C=100, max_iter=2500, penalty=none, solver=saga;, score=-1.027 total time=  30.4s\n",
      "[CV 1/2; 164/336] START C=1000, max_iter=1000, penalty=none, solver=saga........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 144/336] END C=100, max_iter=2500, penalty=none, solver=saga;, score=-1.080 total time=  30.3s\n",
      "[CV 2/2; 164/336] START C=1000, max_iter=1000, penalty=none, solver=saga........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 163/336] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=-0.982 total time=  12.0s\n",
      "[CV 1/2; 165/336] START C=1000, max_iter=2500, penalty=elasticnet, solver=saga..\n",
      "[CV 1/2; 165/336] END C=1000, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/2; 165/336] START C=1000, max_iter=2500, penalty=elasticnet, solver=saga..\n",
      "[CV 2/2; 165/336] END C=1000, max_iter=2500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/2; 166/336] START C=1000, max_iter=2500, penalty=l1, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 163/336] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=-1.010 total time=  12.2s\n",
      "[CV 2/2; 166/336] START C=1000, max_iter=2500, penalty=l1, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 162/336] END C=1000, max_iter=1000, penalty=l1, solver=saga;, score=-0.988 total time=  19.6s\n",
      "[CV 1/2; 167/336] START C=1000, max_iter=2500, penalty=l2, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 162/336] END C=1000, max_iter=1000, penalty=l1, solver=saga;, score=-1.020 total time=  20.1s\n",
      "[CV 2/2; 167/336] START C=1000, max_iter=2500, penalty=l2, solver=saga..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 142/336] END C=100, max_iter=2500, penalty=l1, solver=saga;, score=-0.977 total time=  45.7s\n",
      "[CV 1/2; 168/336] START C=1000, max_iter=2500, penalty=none, solver=saga........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 164/336] END C=1000, max_iter=1000, penalty=none, solver=saga;, score=-0.991 total time=  12.2s\n",
      "[CV 2/2; 168/336] START C=1000, max_iter=2500, penalty=none, solver=saga........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 142/336] END C=100, max_iter=2500, penalty=l1, solver=saga;, score=-0.998 total time=  46.5s\n",
      "[CV 1/2; 169/336] START C=0.001, max_iter=50, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 169/336] END C=0.001, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.949 total time=   0.1s\n",
      "[CV 2/2; 169/336] START C=0.001, max_iter=50, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 169/336] END C=0.001, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 170/336] START C=0.001, max_iter=50, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 170/336] END C=0.001, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.949 total time=   0.0s\n",
      "[CV 2/2; 170/336] START C=0.001, max_iter=50, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 170/336] END C=0.001, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 1/2; 171/336] START C=0.001, max_iter=50, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 164/336] END C=1000, max_iter=1000, penalty=none, solver=saga;, score=-1.027 total time=  11.9s\n",
      "[CV 2/2; 171/336] START C=0.001, max_iter=50, penalty=none, solver=newton-cg....\n",
      "[CV 1/2; 171/336] END C=0.001, max_iter=50, penalty=none, solver=newton-cg;, score=-1.593 total time=   4.1s\n",
      "[CV 1/2; 172/336] START C=0.001, max_iter=50, penalty=none, solver=lbfgs........\n",
      "[CV 1/2; 172/336] END C=0.001, max_iter=50, penalty=none, solver=lbfgs;, score=-0.956 total time=   0.1s\n",
      "[CV 2/2; 172/336] START C=0.001, max_iter=50, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 172/336] END C=0.001, max_iter=50, penalty=none, solver=lbfgs;, score=-0.972 total time=   0.1s\n",
      "[CV 1/2; 173/336] START C=0.001, max_iter=100, penalty=l2, solver=newton-cg.....\n",
      "[CV 2/2; 171/336] END C=0.001, max_iter=50, penalty=none, solver=newton-cg;, score=-1.599 total time=   3.2s\n",
      "[CV 2/2; 173/336] START C=0.001, max_iter=100, penalty=l2, solver=newton-cg.....\n",
      "[CV 1/2; 173/336] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.949 total time=   0.1s\n",
      "[CV 1/2; 174/336] START C=0.001, max_iter=100, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 174/336] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.949 total time=   0.0s\n",
      "[CV 2/2; 174/336] START C=0.001, max_iter=100, penalty=l2, solver=lbfgs.........\n",
      "[CV 2/2; 173/336] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 175/336] START C=0.001, max_iter=100, penalty=none, solver=newton-cg...\n",
      "[CV 2/2; 174/336] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 2/2; 175/336] START C=0.001, max_iter=100, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 175/336] END C=0.001, max_iter=100, penalty=none, solver=newton-cg;, score=-1.599 total time=   3.2s\n",
      "[CV 1/2; 176/336] START C=0.001, max_iter=100, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 176/336] END C=0.001, max_iter=100, penalty=none, solver=lbfgs;, score=-1.007 total time=   0.2s\n",
      "[CV 2/2; 176/336] START C=0.001, max_iter=100, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 176/336] END C=0.001, max_iter=100, penalty=none, solver=lbfgs;, score=-1.034 total time=   0.3s\n",
      "[CV 1/2; 177/336] START C=0.001, max_iter=200, penalty=l2, solver=newton-cg.....\n",
      "[CV 1/2; 177/336] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.949 total time=   0.1s\n",
      "[CV 2/2; 177/336] START C=0.001, max_iter=200, penalty=l2, solver=newton-cg.....\n",
      "[CV 2/2; 177/336] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 178/336] START C=0.001, max_iter=200, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 178/336] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.949 total time=   0.0s\n",
      "[CV 2/2; 178/336] START C=0.001, max_iter=200, penalty=l2, solver=lbfgs.........\n",
      "[CV 2/2; 178/336] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 1/2; 179/336] START C=0.001, max_iter=200, penalty=none, solver=newton-cg...\n",
      "[CV 1/2; 175/336] END C=0.001, max_iter=100, penalty=none, solver=newton-cg;, score=-1.593 total time=   4.1s\n",
      "[CV 2/2; 179/336] START C=0.001, max_iter=200, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 179/336] END C=0.001, max_iter=200, penalty=none, solver=newton-cg;, score=-1.599 total time=   3.3s\n",
      "[CV 1/2; 180/336] START C=0.001, max_iter=200, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 180/336] END C=0.001, max_iter=200, penalty=none, solver=lbfgs;, score=-1.054 total time=   0.4s\n",
      "[CV 2/2; 180/336] START C=0.001, max_iter=200, penalty=none, solver=lbfgs.......\n",
      "[CV 1/2; 179/336] END C=0.001, max_iter=200, penalty=none, solver=newton-cg;, score=-1.593 total time=   4.2s\n",
      "[CV 1/2; 181/336] START C=0.001, max_iter=500, penalty=l2, solver=newton-cg.....\n",
      "[CV 2/2; 180/336] END C=0.001, max_iter=200, penalty=none, solver=lbfgs;, score=-1.125 total time=   0.4s\n",
      "[CV 2/2; 181/336] START C=0.001, max_iter=500, penalty=l2, solver=newton-cg.....\n",
      "[CV 1/2; 181/336] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.949 total time=   0.1s\n",
      "[CV 1/2; 182/336] START C=0.001, max_iter=500, penalty=l2, solver=lbfgs.........\n",
      "[CV 2/2; 181/336] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 2/2; 182/336] START C=0.001, max_iter=500, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 182/336] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.949 total time=   0.0s\n",
      "[CV 1/2; 183/336] START C=0.001, max_iter=500, penalty=none, solver=newton-cg...\n",
      "[CV 2/2; 182/336] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 2/2; 183/336] START C=0.001, max_iter=500, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 183/336] END C=0.001, max_iter=500, penalty=none, solver=newton-cg;, score=-1.599 total time=   3.2s\n",
      "[CV 1/2; 184/336] START C=0.001, max_iter=500, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 183/336] END C=0.001, max_iter=500, penalty=none, solver=newton-cg;, score=-1.593 total time=   4.1s\n",
      "[CV 2/2; 184/336] START C=0.001, max_iter=500, penalty=none, solver=lbfgs.......\n",
      "[CV 1/2; 184/336] END C=0.001, max_iter=500, penalty=none, solver=lbfgs;, score=-1.171 total time=   1.0s\n",
      "[CV 1/2; 185/336] START C=0.001, max_iter=1000, penalty=l2, solver=newton-cg....\n",
      "[CV 1/2; 185/336] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.949 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 185/336] START C=0.001, max_iter=1000, penalty=l2, solver=newton-cg....\n",
      "[CV 2/2; 185/336] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 186/336] START C=0.001, max_iter=1000, penalty=l2, solver=lbfgs........\n",
      "[CV 1/2; 186/336] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.949 total time=   0.0s\n",
      "[CV 2/2; 186/336] START C=0.001, max_iter=1000, penalty=l2, solver=lbfgs........\n",
      "[CV 2/2; 186/336] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 1/2; 187/336] START C=0.001, max_iter=1000, penalty=none, solver=newton-cg..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 184/336] END C=0.001, max_iter=500, penalty=none, solver=lbfgs;, score=-1.489 total time=   1.0s\n",
      "[CV 2/2; 187/336] START C=0.001, max_iter=1000, penalty=none, solver=newton-cg..\n",
      "[CV 2/2; 187/336] END C=0.001, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.599 total time=   3.2s\n",
      "[CV 1/2; 188/336] START C=0.001, max_iter=1000, penalty=none, solver=lbfgs......\n",
      "[CV 1/2; 187/336] END C=0.001, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.593 total time=   4.0s\n",
      "[CV 2/2; 188/336] START C=0.001, max_iter=1000, penalty=none, solver=lbfgs......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 188/336] END C=0.001, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.317 total time=   2.0s\n",
      "[CV 1/2; 189/336] START C=0.001, max_iter=2500, penalty=l2, solver=newton-cg....\n",
      "[CV 1/2; 189/336] END C=0.001, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.949 total time=   0.1s\n",
      "[CV 2/2; 189/336] START C=0.001, max_iter=2500, penalty=l2, solver=newton-cg....\n",
      "[CV 2/2; 188/336] END C=0.001, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.601 total time=   2.0s\n",
      "[CV 1/2; 190/336] START C=0.001, max_iter=2500, penalty=l2, solver=lbfgs........\n",
      "[CV 2/2; 189/336] END C=0.001, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 2/2; 190/336] START C=0.001, max_iter=2500, penalty=l2, solver=lbfgs........\n",
      "[CV 1/2; 190/336] END C=0.001, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.949 total time=   0.0s\n",
      "[CV 1/2; 191/336] START C=0.001, max_iter=2500, penalty=none, solver=newton-cg..\n",
      "[CV 2/2; 190/336] END C=0.001, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 2/2; 191/336] START C=0.001, max_iter=2500, penalty=none, solver=newton-cg..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 167/336] END C=1000, max_iter=2500, penalty=l2, solver=saga;, score=-0.992 total time=  27.6s\n",
      "[CV 1/2; 192/336] START C=0.001, max_iter=2500, penalty=none, solver=lbfgs......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 167/336] END C=1000, max_iter=2500, penalty=l2, solver=saga;, score=-1.024 total time=  28.6s\n",
      "[CV 2/2; 192/336] START C=0.001, max_iter=2500, penalty=none, solver=lbfgs......\n",
      "[CV 2/2; 191/336] END C=0.001, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.599 total time=   3.4s\n",
      "[CV 1/2; 193/336] START C=0.01, max_iter=50, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 193/336] END C=0.01, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 193/336] START C=0.01, max_iter=50, penalty=l2, solver=newton-cg.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 193/336] END C=0.01, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 194/336] START C=0.01, max_iter=50, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 194/336] END C=0.01, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.0s\n",
      "[CV 2/2; 194/336] START C=0.01, max_iter=50, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 194/336] END C=0.01, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 1/2; 195/336] START C=0.01, max_iter=50, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 191/336] END C=0.001, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.593 total time=   4.3s\n",
      "[CV 2/2; 195/336] START C=0.01, max_iter=50, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 192/336] END C=0.001, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.355 total time=   6.0s\n",
      "[CV 1/2; 196/336] START C=0.01, max_iter=50, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 168/336] END C=1000, max_iter=2500, penalty=none, solver=saga;, score=-1.027 total time=  32.8s\n",
      "[CV 2/2; 196/336] START C=0.01, max_iter=50, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 196/336] END C=0.01, max_iter=50, penalty=none, solver=lbfgs;, score=-0.956 total time=   0.1s\n",
      "[CV 1/2; 197/336] START C=0.01, max_iter=100, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 197/336] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 197/336] START C=0.01, max_iter=100, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 196/336] END C=0.01, max_iter=50, penalty=none, solver=lbfgs;, score=-0.972 total time=   0.2s\n",
      "[CV 1/2; 198/336] START C=0.01, max_iter=100, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 198/336] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.0s\n",
      "[CV 2/2; 198/336] START C=0.01, max_iter=100, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 197/336] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 199/336] START C=0.01, max_iter=100, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 198/336] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 2/2; 199/336] START C=0.01, max_iter=100, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 195/336] END C=0.01, max_iter=50, penalty=none, solver=newton-cg;, score=-1.599 total time=   4.2s\n",
      "[CV 1/2; 200/336] START C=0.01, max_iter=100, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 168/336] END C=1000, max_iter=2500, penalty=none, solver=saga;, score=-1.080 total time=  32.8s\n",
      "[CV 2/2; 200/336] START C=0.01, max_iter=100, penalty=none, solver=lbfgs........\n",
      "[CV 1/2; 200/336] END C=0.01, max_iter=100, penalty=none, solver=lbfgs;, score=-1.007 total time=   0.3s\n",
      "[CV 1/2; 201/336] START C=0.01, max_iter=200, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 195/336] END C=0.01, max_iter=50, penalty=none, solver=newton-cg;, score=-1.593 total time=   5.2s\n",
      "[CV 2/2; 201/336] START C=0.01, max_iter=200, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 201/336] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.2s\n",
      "[CV 1/2; 202/336] START C=0.01, max_iter=200, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 202/336] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 201/336] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 2/2; 202/336] START C=0.01, max_iter=200, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 203/336] START C=0.01, max_iter=200, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 202/336] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 2/2; 203/336] START C=0.01, max_iter=200, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 200/336] END C=0.01, max_iter=100, penalty=none, solver=lbfgs;, score=-1.034 total time=   0.4s\n",
      "[CV 1/2; 204/336] START C=0.01, max_iter=200, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 204/336] END C=0.01, max_iter=200, penalty=none, solver=lbfgs;, score=-1.054 total time=   0.6s\n",
      "[CV 2/2; 204/336] START C=0.01, max_iter=200, penalty=none, solver=lbfgs........\n",
      "[CV 2/2; 192/336] END C=0.001, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.867 total time=   6.6s\n",
      "[CV 1/2; 205/336] START C=0.01, max_iter=500, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 205/336] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 205/336] START C=0.01, max_iter=500, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 205/336] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 206/336] START C=0.01, max_iter=500, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 206/336] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.0s\n",
      "[CV 2/2; 206/336] START C=0.01, max_iter=500, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 206/336] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 207/336] START C=0.01, max_iter=500, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 204/336] END C=0.01, max_iter=200, penalty=none, solver=lbfgs;, score=-1.125 total time=   0.7s\n",
      "[CV 2/2; 207/336] START C=0.01, max_iter=500, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 199/336] END C=0.01, max_iter=100, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.0s\n",
      "[CV 1/2; 208/336] START C=0.01, max_iter=500, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 203/336] END C=0.01, max_iter=200, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.0s\n",
      "[CV 2/2; 208/336] START C=0.01, max_iter=500, penalty=none, solver=lbfgs........\n",
      "[CV 1/2; 199/336] END C=0.01, max_iter=100, penalty=none, solver=newton-cg;, score=-1.593 total time=   6.2s\n",
      "[CV 1/2; 209/336] START C=0.01, max_iter=1000, penalty=l2, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 209/336] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 209/336] START C=0.01, max_iter=1000, penalty=l2, solver=newton-cg.....\n",
      "[CV 2/2; 209/336] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 210/336] START C=0.01, max_iter=1000, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 210/336] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.0s\n",
      "[CV 2/2; 210/336] START C=0.01, max_iter=1000, penalty=l2, solver=lbfgs.........\n",
      "[CV 2/2; 210/336] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 211/336] START C=0.01, max_iter=1000, penalty=none, solver=newton-cg...\n",
      "[CV 1/2; 208/336] END C=0.01, max_iter=500, penalty=none, solver=lbfgs;, score=-1.171 total time=   1.6s\n",
      "[CV 2/2; 211/336] START C=0.01, max_iter=1000, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 203/336] END C=0.01, max_iter=200, penalty=none, solver=newton-cg;, score=-1.593 total time=   6.4s\n",
      "[CV 1/2; 212/336] START C=0.01, max_iter=1000, penalty=none, solver=lbfgs.......\n",
      "[CV 2/2; 207/336] END C=0.01, max_iter=500, penalty=none, solver=newton-cg;, score=-1.599 total time=   4.9s\n",
      "[CV 2/2; 212/336] START C=0.01, max_iter=1000, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 208/336] END C=0.01, max_iter=500, penalty=none, solver=lbfgs;, score=-1.489 total time=   1.6s\n",
      "[CV 1/2; 213/336] START C=0.01, max_iter=2500, penalty=l2, solver=newton-cg.....\n",
      "[CV 1/2; 213/336] END C=0.01, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 213/336] START C=0.01, max_iter=2500, penalty=l2, solver=newton-cg.....\n",
      "[CV 2/2; 213/336] END C=0.01, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.950 total time=   0.1s\n",
      "[CV 1/2; 214/336] START C=0.01, max_iter=2500, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 214/336] END C=0.01, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 214/336] START C=0.01, max_iter=2500, penalty=l2, solver=lbfgs.........\n",
      "[CV 2/2; 214/336] END C=0.01, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.950 total time=   0.0s\n",
      "[CV 1/2; 215/336] START C=0.01, max_iter=2500, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 207/336] END C=0.01, max_iter=500, penalty=none, solver=newton-cg;, score=-1.593 total time=   6.1s\n",
      "[CV 2/2; 215/336] START C=0.01, max_iter=2500, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 212/336] END C=0.01, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.317 total time=   2.8s\n",
      "[CV 1/2; 216/336] START C=0.01, max_iter=2500, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 212/336] END C=0.01, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.601 total time=   3.2s\n",
      "[CV 2/2; 216/336] START C=0.01, max_iter=2500, penalty=none, solver=lbfgs.......\n",
      "[CV 2/2; 211/336] END C=0.01, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.0s\n",
      "[CV 1/2; 217/336] START C=0.1, max_iter=50, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 217/336] END C=0.1, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.2s\n",
      "[CV 2/2; 217/336] START C=0.1, max_iter=50, penalty=l2, solver=newton-cg........\n",
      "[CV 2/2; 217/336] END C=0.1, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.952 total time=   0.1s\n",
      "[CV 1/2; 218/336] START C=0.1, max_iter=50, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 218/336] END C=0.1, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 218/336] START C=0.1, max_iter=50, penalty=l2, solver=lbfgs............\n",
      "[CV 2/2; 218/336] END C=0.1, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.952 total time=   0.1s\n",
      "[CV 1/2; 219/336] START C=0.1, max_iter=50, penalty=none, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 211/336] END C=0.01, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.593 total time=   6.2s\n",
      "[CV 2/2; 219/336] START C=0.1, max_iter=50, penalty=none, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 215/336] END C=0.01, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.599 total time=   4.8s\n",
      "[CV 1/2; 220/336] START C=0.1, max_iter=50, penalty=none, solver=lbfgs..........\n",
      "[CV 1/2; 220/336] END C=0.1, max_iter=50, penalty=none, solver=lbfgs;, score=-0.956 total time=   0.2s\n",
      "[CV 2/2; 220/336] START C=0.1, max_iter=50, penalty=none, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 220/336] END C=0.1, max_iter=50, penalty=none, solver=lbfgs;, score=-0.972 total time=   0.2s\n",
      "[CV 1/2; 221/336] START C=0.1, max_iter=100, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 221/336] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.2s\n",
      "[CV 2/2; 221/336] START C=0.1, max_iter=100, penalty=l2, solver=newton-cg.......\n",
      "[CV 2/2; 221/336] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.952 total time=   0.2s\n",
      "[CV 1/2; 222/336] START C=0.1, max_iter=100, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 222/336] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 222/336] START C=0.1, max_iter=100, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 222/336] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.952 total time=   0.1s\n",
      "[CV 1/2; 223/336] START C=0.1, max_iter=100, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 215/336] END C=0.01, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.593 total time=   6.4s\n",
      "[CV 2/2; 223/336] START C=0.1, max_iter=100, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 219/336] END C=0.1, max_iter=50, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.0s\n",
      "[CV 1/2; 224/336] START C=0.1, max_iter=100, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 224/336] END C=0.1, max_iter=100, penalty=none, solver=lbfgs;, score=-1.007 total time=   0.3s\n",
      "[CV 2/2; 224/336] START C=0.1, max_iter=100, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 216/336] END C=0.01, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.355 total time=   7.9s\n",
      "[CV 1/2; 225/336] START C=0.1, max_iter=200, penalty=l2, solver=newton-cg.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 216/336] END C=0.01, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.867 total time=   7.7s\n",
      "[CV 1/2; 225/336] END C=0.1, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 225/336] START C=0.1, max_iter=200, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 226/336] START C=0.1, max_iter=200, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 226/336] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 226/336] START C=0.1, max_iter=200, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 224/336] END C=0.1, max_iter=100, penalty=none, solver=lbfgs;, score=-1.034 total time=   0.3s\n",
      "[CV 1/2; 227/336] START C=0.1, max_iter=200, penalty=none, solver=newton-cg.....\n",
      "[CV 1/2; 219/336] END C=0.1, max_iter=50, penalty=none, solver=newton-cg;, score=-1.593 total time=   6.3s\n",
      "[CV 2/2; 227/336] START C=0.1, max_iter=200, penalty=none, solver=newton-cg.....\n",
      "[CV 2/2; 225/336] END C=0.1, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.952 total time=   0.2s\n",
      "[CV 2/2; 226/336] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.952 total time=   0.1s\n",
      "[CV 2/2; 228/336] START C=0.1, max_iter=200, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 228/336] START C=0.1, max_iter=200, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 228/336] END C=0.1, max_iter=200, penalty=none, solver=lbfgs;, score=-1.054 total time=   0.6s\n",
      "[CV 2/2; 228/336] END C=0.1, max_iter=200, penalty=none, solver=lbfgs;, score=-1.125 total time=   0.6s\n",
      "[CV 1/2; 229/336] START C=0.1, max_iter=500, penalty=l2, solver=newton-cg.......\n",
      "[CV 2/2; 229/336] START C=0.1, max_iter=500, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 229/336] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.2s\n",
      "[CV 1/2; 230/336] START C=0.1, max_iter=500, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 229/336] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.952 total time=   0.2s\n",
      "[CV 2/2; 230/336] START C=0.1, max_iter=500, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 223/336] END C=0.1, max_iter=100, penalty=none, solver=newton-cg;, score=-1.599 total time=   4.8s\n",
      "[CV 1/2; 231/336] START C=0.1, max_iter=500, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 230/336] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.952 total time=   0.1s\n",
      "[CV 2/2; 231/336] START C=0.1, max_iter=500, penalty=none, solver=newton-cg.....\n",
      "[CV 1/2; 230/336] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 1/2; 232/336] START C=0.1, max_iter=500, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 166/336] END C=1000, max_iter=2500, penalty=l1, solver=saga;, score=-1.062 total time=  57.0s\n",
      "[CV 2/2; 232/336] START C=0.1, max_iter=500, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 166/336] END C=1000, max_iter=2500, penalty=l1, solver=saga;, score=-1.018 total time=  57.4s\n",
      "[CV 1/2; 233/336] START C=0.1, max_iter=1000, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 223/336] END C=0.1, max_iter=100, penalty=none, solver=newton-cg;, score=-1.593 total time=   6.0s\n",
      "[CV 2/2; 233/336] START C=0.1, max_iter=1000, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 233/336] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.2s\n",
      "[CV 1/2; 234/336] START C=0.1, max_iter=1000, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 233/336] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.952 total time=   0.2s\n",
      "[CV 2/2; 234/336] START C=0.1, max_iter=1000, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 234/336] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 1/2; 235/336] START C=0.1, max_iter=1000, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 234/336] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.952 total time=   0.1s\n",
      "[CV 2/2; 235/336] START C=0.1, max_iter=1000, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 232/336] END C=0.1, max_iter=500, penalty=none, solver=lbfgs;, score=-1.171 total time=   1.7s\n",
      "[CV 1/2; 236/336] START C=0.1, max_iter=1000, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 232/336] END C=0.1, max_iter=500, penalty=none, solver=lbfgs;, score=-1.489 total time=   1.8s\n",
      "[CV 2/2; 236/336] START C=0.1, max_iter=1000, penalty=none, solver=lbfgs........\n",
      "[CV 2/2; 227/336] END C=0.1, max_iter=200, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.6s\n",
      "[CV 1/2; 237/336] START C=0.1, max_iter=2500, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 237/336] END C=0.1, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.948 total time=   0.2s\n",
      "[CV 2/2; 237/336] START C=0.1, max_iter=2500, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 237/336] END C=0.1, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.952 total time=   0.2s\n",
      "[CV 1/2; 238/336] START C=0.1, max_iter=2500, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 238/336] END C=0.1, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.948 total time=   0.1s\n",
      "[CV 2/2; 238/336] START C=0.1, max_iter=2500, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 238/336] END C=0.1, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.952 total time=   0.1s\n",
      "[CV 1/2; 239/336] START C=0.1, max_iter=2500, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 236/336] END C=0.1, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.317 total time=   3.6s\n",
      "[CV 2/2; 239/336] START C=0.1, max_iter=2500, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 231/336] END C=0.1, max_iter=500, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.9s\n",
      "[CV 1/2; 240/336] START C=0.1, max_iter=2500, penalty=none, solver=lbfgs........\n",
      "[CV 2/2; 236/336] END C=0.1, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.601 total time=   3.6s\n",
      "[CV 2/2; 240/336] START C=0.1, max_iter=2500, penalty=none, solver=lbfgs........\n",
      "[CV 1/2; 227/336] END C=0.1, max_iter=200, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.0s\n",
      "[CV 1/2; 241/336] START C=1, max_iter=50, penalty=l2, solver=newton-cg..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 241/336] END C=1, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 241/336] START C=1, max_iter=50, penalty=l2, solver=newton-cg..........\n",
      "[CV 2/2; 241/336] END C=1, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 242/336] START C=1, max_iter=50, penalty=l2, solver=lbfgs..............\n",
      "[CV 1/2; 242/336] END C=1, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.945 total time=   0.1s\n",
      "[CV 2/2; 242/336] START C=1, max_iter=50, penalty=l2, solver=lbfgs..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 242/336] END C=1, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 243/336] START C=1, max_iter=50, penalty=none, solver=newton-cg........\n",
      "[CV 2/2; 235/336] END C=0.1, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.9s\n",
      "[CV 2/2; 243/336] START C=1, max_iter=50, penalty=none, solver=newton-cg........\n",
      "[CV 1/2; 231/336] END C=0.1, max_iter=500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.3s\n",
      "[CV 1/2; 244/336] START C=1, max_iter=50, penalty=none, solver=lbfgs............\n",
      "[CV 1/2; 244/336] END C=1, max_iter=50, penalty=none, solver=lbfgs;, score=-0.956 total time=   0.2s\n",
      "[CV 2/2; 244/336] START C=1, max_iter=50, penalty=none, solver=lbfgs............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 244/336] END C=1, max_iter=50, penalty=none, solver=lbfgs;, score=-0.972 total time=   0.2s\n",
      "[CV 1/2; 245/336] START C=1, max_iter=100, penalty=l2, solver=newton-cg.........\n",
      "[CV 1/2; 245/336] END C=1, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 245/336] START C=1, max_iter=100, penalty=l2, solver=newton-cg.........\n",
      "[CV 2/2; 245/336] END C=1, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 246/336] START C=1, max_iter=100, penalty=l2, solver=lbfgs.............\n",
      "[CV 1/2; 246/336] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.945 total time=   0.1s\n",
      "[CV 2/2; 246/336] START C=1, max_iter=100, penalty=l2, solver=lbfgs.............\n",
      "[CV 1/2; 235/336] END C=0.1, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.4s\n",
      "[CV 1/2; 247/336] START C=1, max_iter=100, penalty=none, solver=newton-cg.......\n",
      "[CV 2/2; 246/336] END C=1, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.2s\n",
      "[CV 2/2; 247/336] START C=1, max_iter=100, penalty=none, solver=newton-cg.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 239/336] END C=0.1, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 1/2; 248/336] START C=1, max_iter=100, penalty=none, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 248/336] END C=1, max_iter=100, penalty=none, solver=lbfgs;, score=-1.007 total time=   0.4s\n",
      "[CV 2/2; 248/336] START C=1, max_iter=100, penalty=none, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 248/336] END C=1, max_iter=100, penalty=none, solver=lbfgs;, score=-1.034 total time=   0.4s\n",
      "[CV 1/2; 249/336] START C=1, max_iter=200, penalty=l2, solver=newton-cg.........\n",
      "[CV 1/2; 249/336] END C=1, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 249/336] START C=1, max_iter=200, penalty=l2, solver=newton-cg.........\n",
      "[CV 2/2; 249/336] END C=1, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 250/336] START C=1, max_iter=200, penalty=l2, solver=lbfgs.............\n",
      "[CV 1/2; 239/336] END C=0.1, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.2s\n",
      "[CV 2/2; 250/336] START C=1, max_iter=200, penalty=l2, solver=lbfgs.............\n",
      "[CV 1/2; 250/336] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.945 total time=   0.1s\n",
      "[CV 1/2; 251/336] START C=1, max_iter=200, penalty=none, solver=newton-cg.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 250/336] END C=1, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.2s\n",
      "[CV 2/2; 251/336] START C=1, max_iter=200, penalty=none, solver=newton-cg.......\n",
      "[CV 2/2; 243/336] END C=1, max_iter=50, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.9s\n",
      "[CV 1/2; 252/336] START C=1, max_iter=200, penalty=none, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 252/336] END C=1, max_iter=200, penalty=none, solver=lbfgs;, score=-1.054 total time=   0.7s\n",
      "[CV 2/2; 252/336] START C=1, max_iter=200, penalty=none, solver=lbfgs...........\n",
      "[CV 1/2; 243/336] END C=1, max_iter=50, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.3s\n",
      "[CV 1/2; 253/336] START C=1, max_iter=500, penalty=l2, solver=newton-cg.........\n",
      "[CV 1/2; 253/336] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 247/336] END C=1, max_iter=100, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.8s\n",
      "[CV 2/2; 253/336] START C=1, max_iter=500, penalty=l2, solver=newton-cg.........\n",
      "[CV 1/2; 254/336] START C=1, max_iter=500, penalty=l2, solver=lbfgs.............\n",
      "[CV 2/2; 252/336] END C=1, max_iter=200, penalty=none, solver=lbfgs;, score=-1.125 total time=   0.7s\n",
      "[CV 2/2; 254/336] START C=1, max_iter=500, penalty=l2, solver=lbfgs.............\n",
      "[CV 1/2; 254/336] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.945 total time=   0.2s\n",
      "[CV 1/2; 255/336] START C=1, max_iter=500, penalty=none, solver=newton-cg.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 253/336] END C=1, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.957 total time=   0.2s\n",
      "[CV 2/2; 255/336] START C=1, max_iter=500, penalty=none, solver=newton-cg.......\n",
      "[CV 2/2; 254/336] END C=1, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 256/336] START C=1, max_iter=500, penalty=none, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 240/336] END C=0.1, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.355 total time=   9.0s\n",
      "[CV 2/2; 256/336] START C=1, max_iter=500, penalty=none, solver=lbfgs...........\n",
      "[CV 2/2; 240/336] END C=0.1, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.867 total time=   9.0s\n",
      "[CV 1/2; 257/336] START C=1, max_iter=1000, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 257/336] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 257/336] START C=1, max_iter=1000, penalty=l2, solver=newton-cg........\n",
      "[CV 2/2; 257/336] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 258/336] START C=1, max_iter=1000, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 258/336] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 258/336] START C=1, max_iter=1000, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 247/336] END C=1, max_iter=100, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.3s\n",
      "[CV 1/2; 259/336] START C=1, max_iter=1000, penalty=none, solver=newton-cg......\n",
      "[CV 2/2; 258/336] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.2s\n",
      "[CV 2/2; 259/336] START C=1, max_iter=1000, penalty=none, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 256/336] END C=1, max_iter=500, penalty=none, solver=lbfgs;, score=-1.171 total time=   1.8s\n",
      "[CV 1/2; 260/336] START C=1, max_iter=1000, penalty=none, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 256/336] END C=1, max_iter=500, penalty=none, solver=lbfgs;, score=-1.489 total time=   1.9s\n",
      "[CV 2/2; 260/336] START C=1, max_iter=1000, penalty=none, solver=lbfgs..........\n",
      "[CV 2/2; 251/336] END C=1, max_iter=200, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.1s\n",
      "[CV 1/2; 261/336] START C=1, max_iter=2500, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 261/336] END C=1, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 261/336] START C=1, max_iter=2500, penalty=l2, solver=newton-cg........\n",
      "[CV 2/2; 261/336] END C=1, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 262/336] START C=1, max_iter=2500, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 262/336] END C=1, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.945 total time=   0.1s\n",
      "[CV 2/2; 262/336] START C=1, max_iter=2500, penalty=l2, solver=lbfgs............\n",
      "[CV 2/2; 262/336] END C=1, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 263/336] START C=1, max_iter=2500, penalty=none, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 260/336] END C=1, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.317 total time=   3.8s\n",
      "[CV 2/2; 263/336] START C=1, max_iter=2500, penalty=none, solver=newton-cg......\n",
      "[CV 1/2; 251/336] END C=1, max_iter=200, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.5s\n",
      "[CV 1/2; 264/336] START C=1, max_iter=2500, penalty=none, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 260/336] END C=1, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.601 total time=   3.7s\n",
      "[CV 2/2; 264/336] START C=1, max_iter=2500, penalty=none, solver=lbfgs..........\n",
      "[CV 2/2; 255/336] END C=1, max_iter=500, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.1s\n",
      "[CV 1/2; 265/336] START C=10, max_iter=50, penalty=l2, solver=newton-cg.........\n",
      "[CV 1/2; 265/336] END C=10, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.944 total time=   0.4s\n",
      "[CV 2/2; 265/336] START C=10, max_iter=50, penalty=l2, solver=newton-cg.........\n",
      "[CV 2/2; 265/336] END C=10, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.963 total time=   0.3s\n",
      "[CV 1/2; 266/336] START C=10, max_iter=50, penalty=l2, solver=lbfgs.............\n",
      "[CV 1/2; 266/336] END C=10, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.945 total time=   0.2s\n",
      "[CV 2/2; 266/336] START C=10, max_iter=50, penalty=l2, solver=lbfgs.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 266/336] END C=10, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.964 total time=   0.2s\n",
      "[CV 1/2; 267/336] START C=10, max_iter=50, penalty=none, solver=newton-cg.......\n",
      "[CV 2/2; 259/336] END C=1, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 2/2; 267/336] START C=10, max_iter=50, penalty=none, solver=newton-cg.......\n",
      "[CV 1/2; 255/336] END C=1, max_iter=500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.5s\n",
      "[CV 1/2; 268/336] START C=10, max_iter=50, penalty=none, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 268/336] END C=10, max_iter=50, penalty=none, solver=lbfgs;, score=-0.956 total time=   0.2s\n",
      "[CV 2/2; 268/336] START C=10, max_iter=50, penalty=none, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 268/336] END C=10, max_iter=50, penalty=none, solver=lbfgs;, score=-0.972 total time=   0.2s\n",
      "[CV 1/2; 269/336] START C=10, max_iter=100, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 269/336] END C=10, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.944 total time=   0.4s\n",
      "[CV 2/2; 269/336] START C=10, max_iter=100, penalty=l2, solver=newton-cg........\n",
      "[CV 2/2; 269/336] END C=10, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.963 total time=   0.3s\n",
      "[CV 1/2; 270/336] START C=10, max_iter=100, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 259/336] END C=1, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.4s\n",
      "[CV 2/2; 270/336] START C=10, max_iter=100, penalty=l2, solver=lbfgs............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 270/336] END C=10, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.944 total time=   0.4s\n",
      "[CV 1/2; 271/336] START C=10, max_iter=100, penalty=none, solver=newton-cg......\n",
      "[CV 2/2; 270/336] END C=10, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.963 total time=   0.4s\n",
      "[CV 2/2; 271/336] START C=10, max_iter=100, penalty=none, solver=newton-cg......\n",
      "[CV 2/2; 263/336] END C=1, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.9s\n",
      "[CV 1/2; 272/336] START C=10, max_iter=100, penalty=none, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 272/336] END C=10, max_iter=100, penalty=none, solver=lbfgs;, score=-1.007 total time=   0.3s\n",
      "[CV 2/2; 272/336] START C=10, max_iter=100, penalty=none, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 272/336] END C=10, max_iter=100, penalty=none, solver=lbfgs;, score=-1.034 total time=   0.4s\n",
      "[CV 1/2; 273/336] START C=10, max_iter=200, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 263/336] END C=1, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.4s\n",
      "[CV 2/2; 273/336] START C=10, max_iter=200, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 273/336] END C=10, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.944 total time=   0.6s\n",
      "[CV 1/2; 274/336] START C=10, max_iter=200, penalty=l2, solver=lbfgs............\n",
      "[CV 2/2; 273/336] END C=10, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.963 total time=   0.5s\n",
      "[CV 2/2; 274/336] START C=10, max_iter=200, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 274/336] END C=10, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.944 total time=   0.6s\n",
      "[CV 1/2; 275/336] START C=10, max_iter=200, penalty=none, solver=newton-cg......\n",
      "[CV 2/2; 274/336] END C=10, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.963 total time=   0.5s\n",
      "[CV 2/2; 275/336] START C=10, max_iter=200, penalty=none, solver=newton-cg......\n",
      "[CV 2/2; 267/336] END C=10, max_iter=50, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.3s\n",
      "[CV 1/2; 276/336] START C=10, max_iter=200, penalty=none, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 276/336] END C=10, max_iter=200, penalty=none, solver=lbfgs;, score=-1.054 total time=   0.7s\n",
      "[CV 2/2; 276/336] START C=10, max_iter=200, penalty=none, solver=lbfgs..........\n",
      "[CV 1/2; 267/336] END C=10, max_iter=50, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.6s\n",
      "[CV 1/2; 277/336] START C=10, max_iter=500, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 264/336] END C=1, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.355 total time=   9.2s\n",
      "[CV 2/2; 277/336] START C=10, max_iter=500, penalty=l2, solver=newton-cg........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 276/336] END C=10, max_iter=200, penalty=none, solver=lbfgs;, score=-1.125 total time=   0.7s\n",
      "[CV 1/2; 278/336] START C=10, max_iter=500, penalty=l2, solver=lbfgs............\n",
      "[CV 2/2; 271/336] END C=10, max_iter=100, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.1s\n",
      "[CV 2/2; 278/336] START C=10, max_iter=500, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 277/336] END C=10, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.944 total time=   0.4s\n",
      "[CV 1/2; 279/336] START C=10, max_iter=500, penalty=none, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 277/336] END C=10, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.963 total time=   0.3s\n",
      "[CV 2/2; 279/336] START C=10, max_iter=500, penalty=none, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 264/336] END C=1, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.867 total time=   9.5s\n",
      "[CV 1/2; 280/336] START C=10, max_iter=500, penalty=none, solver=lbfgs..........\n",
      "[CV 1/2; 278/336] END C=10, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.944 total time=   0.6s\n",
      "[CV 2/2; 280/336] START C=10, max_iter=500, penalty=none, solver=lbfgs..........\n",
      "[CV 2/2; 278/336] END C=10, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.963 total time=   0.6s\n",
      "[CV 1/2; 281/336] START C=10, max_iter=1000, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 281/336] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.944 total time=   0.4s\n",
      "[CV 2/2; 281/336] START C=10, max_iter=1000, penalty=l2, solver=newton-cg.......\n",
      "[CV 2/2; 281/336] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.963 total time=   0.3s\n",
      "[CV 1/2; 282/336] START C=10, max_iter=1000, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 271/336] END C=10, max_iter=100, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.7s\n",
      "[CV 2/2; 282/336] START C=10, max_iter=1000, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 282/336] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.944 total time=   0.6s\n",
      "[CV 1/2; 283/336] START C=10, max_iter=1000, penalty=none, solver=newton-cg.....\n",
      "[CV 2/2; 282/336] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.963 total time=   0.5s\n",
      "[CV 2/2; 283/336] START C=10, max_iter=1000, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 280/336] END C=10, max_iter=500, penalty=none, solver=lbfgs;, score=-1.171 total time=   1.9s\n",
      "[CV 1/2; 284/336] START C=10, max_iter=1000, penalty=none, solver=lbfgs.........\n",
      "[CV 2/2; 280/336] END C=10, max_iter=500, penalty=none, solver=lbfgs;, score=-1.489 total time=   1.8s\n",
      "[CV 2/2; 284/336] START C=10, max_iter=1000, penalty=none, solver=lbfgs.........\n",
      "[CV 2/2; 275/336] END C=10, max_iter=200, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.3s\n",
      "[CV 1/2; 285/336] START C=10, max_iter=2500, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 285/336] END C=10, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.944 total time=   0.4s\n",
      "[CV 2/2; 285/336] START C=10, max_iter=2500, penalty=l2, solver=newton-cg.......\n",
      "[CV 2/2; 285/336] END C=10, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.963 total time=   0.3s\n",
      "[CV 1/2; 286/336] START C=10, max_iter=2500, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 286/336] END C=10, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.944 total time=   0.5s\n",
      "[CV 2/2; 286/336] START C=10, max_iter=2500, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 275/336] END C=10, max_iter=200, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.7s\n",
      "[CV 1/2; 287/336] START C=10, max_iter=2500, penalty=none, solver=newton-cg.....\n",
      "[CV 1/2; 284/336] END C=10, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.317 total time=   3.8s\n",
      "[CV 2/2; 287/336] START C=10, max_iter=2500, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 284/336] END C=10, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.601 total time=   4.0s\n",
      "[CV 1/2; 288/336] START C=10, max_iter=2500, penalty=none, solver=lbfgs.........\n",
      "[CV 2/2; 279/336] END C=10, max_iter=500, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.3s\n",
      "[CV 2/2; 288/336] START C=10, max_iter=2500, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 286/336] END C=10, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.963 total time=   0.5s\n",
      "[CV 1/2; 289/336] START C=100, max_iter=50, penalty=l2, solver=newton-cg........\n",
      "[CV 1/2; 289/336] END C=100, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.956 total time=   0.6s\n",
      "[CV 2/2; 289/336] START C=100, max_iter=50, penalty=l2, solver=newton-cg........\n",
      "[CV 2/2; 289/336] END C=100, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.975 total time=   0.5s\n",
      "[CV 1/2; 290/336] START C=100, max_iter=50, penalty=l2, solver=lbfgs............\n",
      "[CV 1/2; 279/336] END C=10, max_iter=500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.7s\n",
      "[CV 2/2; 290/336] START C=100, max_iter=50, penalty=l2, solver=lbfgs............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 290/336] END C=100, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.2s\n",
      "[CV 1/2; 291/336] START C=100, max_iter=50, penalty=none, solver=newton-cg......\n",
      "[CV 2/2; 290/336] END C=100, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.973 total time=   0.2s\n",
      "[CV 2/2; 291/336] START C=100, max_iter=50, penalty=none, solver=newton-cg......\n",
      "[CV 2/2; 283/336] END C=10, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.2s\n",
      "[CV 1/2; 292/336] START C=100, max_iter=50, penalty=none, solver=lbfgs..........\n",
      "[CV 1/2; 292/336] END C=100, max_iter=50, penalty=none, solver=lbfgs;, score=-0.956 total time=   0.2s\n",
      "[CV 2/2; 292/336] START C=100, max_iter=50, penalty=none, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 292/336] END C=100, max_iter=50, penalty=none, solver=lbfgs;, score=-0.972 total time=   0.2s\n",
      "[CV 1/2; 293/336] START C=100, max_iter=100, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 293/336] END C=100, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.956 total time=   0.6s\n",
      "[CV 2/2; 293/336] START C=100, max_iter=100, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 283/336] END C=10, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.6s\n",
      "[CV 1/2; 294/336] START C=100, max_iter=100, penalty=l2, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 294/336] END C=100, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.956 total time=   0.4s\n",
      "[CV 2/2; 293/336] END C=100, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.975 total time=   0.5s\n",
      "[CV 2/2; 294/336] START C=100, max_iter=100, penalty=l2, solver=lbfgs...........\n",
      "[CV 1/2; 295/336] START C=100, max_iter=100, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 294/336] END C=100, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.982 total time=   0.4s\n",
      "[CV 2/2; 295/336] START C=100, max_iter=100, penalty=none, solver=newton-cg.....\n",
      "[CV 2/2; 287/336] END C=10, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 1/2; 296/336] START C=100, max_iter=100, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 296/336] END C=100, max_iter=100, penalty=none, solver=lbfgs;, score=-1.007 total time=   0.4s\n",
      "[CV 2/2; 296/336] START C=100, max_iter=100, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 296/336] END C=100, max_iter=100, penalty=none, solver=lbfgs;, score=-1.034 total time=   0.4s\n",
      "[CV 1/2; 297/336] START C=100, max_iter=200, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 297/336] END C=100, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.956 total time=   0.6s\n",
      "[CV 2/2; 297/336] START C=100, max_iter=200, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 287/336] END C=10, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.5s\n",
      "[CV 1/2; 298/336] START C=100, max_iter=200, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 291/336] END C=100, max_iter=50, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 2/2; 298/336] START C=100, max_iter=200, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 297/336] END C=100, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.975 total time=   0.5s\n",
      "[CV 1/2; 299/336] START C=100, max_iter=200, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 298/336] END C=100, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.957 total time=   0.7s\n",
      "[CV 2/2; 299/336] START C=100, max_iter=200, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 298/336] END C=100, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.975 total time=   0.7s\n",
      "[CV 1/2; 300/336] START C=100, max_iter=200, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 291/336] END C=100, max_iter=50, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.5s\n",
      "[CV 2/2; 300/336] START C=100, max_iter=200, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 300/336] END C=100, max_iter=200, penalty=none, solver=lbfgs;, score=-1.054 total time=   0.8s\n",
      "[CV 1/2; 301/336] START C=100, max_iter=500, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 288/336] END C=10, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.355 total time=   9.3s\n",
      "[CV 2/2; 301/336] START C=100, max_iter=500, penalty=l2, solver=newton-cg.......\n",
      "[CV 2/2; 288/336] END C=10, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.867 total time=   9.2s\n",
      "[CV 1/2; 302/336] START C=100, max_iter=500, penalty=l2, solver=lbfgs...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 301/336] END C=100, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.975 total time=   0.5s\n",
      "[CV 2/2; 302/336] START C=100, max_iter=500, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 295/336] END C=100, max_iter=100, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 1/2; 303/336] START C=100, max_iter=500, penalty=none, solver=newton-cg.....\n",
      "[CV 2/2; 300/336] END C=100, max_iter=200, penalty=none, solver=lbfgs;, score=-1.125 total time=   0.8s\n",
      "[CV 2/2; 303/336] START C=100, max_iter=500, penalty=none, solver=newton-cg.....\n",
      "[CV 1/2; 301/336] END C=100, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.956 total time=   0.7s\n",
      "[CV 1/2; 304/336] START C=100, max_iter=500, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 302/336] END C=100, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.956 total time=   1.4s\n",
      "[CV 2/2; 304/336] START C=100, max_iter=500, penalty=none, solver=lbfgs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 295/336] END C=100, max_iter=100, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.6s\n",
      "[CV 1/2; 305/336] START C=100, max_iter=1000, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 302/336] END C=100, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.975 total time=   1.5s\n",
      "[CV 2/2; 305/336] START C=100, max_iter=1000, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 305/336] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.956 total time=   0.6s\n",
      "[CV 1/2; 306/336] START C=100, max_iter=1000, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 304/336] END C=100, max_iter=500, penalty=none, solver=lbfgs;, score=-1.171 total time=   1.8s\n",
      "[CV 2/2; 306/336] START C=100, max_iter=1000, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 305/336] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.975 total time=   0.5s\n",
      "[CV 1/2; 307/336] START C=100, max_iter=1000, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 304/336] END C=100, max_iter=500, penalty=none, solver=lbfgs;, score=-1.489 total time=   1.8s\n",
      "[CV 2/2; 307/336] START C=100, max_iter=1000, penalty=none, solver=newton-cg....\n",
      "[CV 1/2; 306/336] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.956 total time=   1.4s\n",
      "[CV 1/2; 308/336] START C=100, max_iter=1000, penalty=none, solver=lbfgs........\n",
      "[CV 2/2; 306/336] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.975 total time=   1.5s\n",
      "[CV 2/2; 308/336] START C=100, max_iter=1000, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 299/336] END C=100, max_iter=200, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.9s\n",
      "[CV 1/2; 309/336] START C=100, max_iter=2500, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 309/336] END C=100, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.956 total time=   0.6s\n",
      "[CV 2/2; 309/336] START C=100, max_iter=2500, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 309/336] END C=100, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.975 total time=   0.5s\n",
      "[CV 1/2; 310/336] START C=100, max_iter=2500, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 299/336] END C=100, max_iter=200, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.4s\n",
      "[CV 2/2; 310/336] START C=100, max_iter=2500, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 303/336] END C=100, max_iter=500, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 1/2; 311/336] START C=100, max_iter=2500, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 310/336] END C=100, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.956 total time=   1.4s\n",
      "[CV 2/2; 311/336] START C=100, max_iter=2500, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 310/336] END C=100, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.975 total time=   1.4s\n",
      "[CV 1/2; 312/336] START C=100, max_iter=2500, penalty=none, solver=lbfgs........\n",
      "[CV 1/2; 308/336] END C=100, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.317 total time=   3.5s\n",
      "[CV 2/2; 312/336] START C=100, max_iter=2500, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 308/336] END C=100, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.601 total time=   3.7s\n",
      "[CV 1/2; 313/336] START C=1000, max_iter=50, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 303/336] END C=100, max_iter=500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.2s\n",
      "[CV 2/2; 313/336] START C=1000, max_iter=50, penalty=l2, solver=newton-cg.......\n",
      "[CV 1/2; 313/336] END C=1000, max_iter=50, penalty=l2, solver=newton-cg;, score=-0.998 total time=   1.3s\n",
      "[CV 1/2; 314/336] START C=1000, max_iter=50, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 313/336] END C=1000, max_iter=50, penalty=l2, solver=newton-cg;, score=-1.029 total time=   1.2s\n",
      "[CV 2/2; 314/336] START C=1000, max_iter=50, penalty=l2, solver=lbfgs...........\n",
      "[CV 2/2; 307/336] END C=100, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.8s\n",
      "[CV 1/2; 315/336] START C=1000, max_iter=50, penalty=none, solver=newton-cg.....\n",
      "[CV 1/2; 314/336] END C=1000, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.959 total time=   0.2s\n",
      "[CV 2/2; 315/336] START C=1000, max_iter=50, penalty=none, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 314/336] END C=1000, max_iter=50, penalty=l2, solver=lbfgs;, score=-0.975 total time=   0.2s\n",
      "[CV 1/2; 316/336] START C=1000, max_iter=50, penalty=none, solver=lbfgs.........\n",
      "[CV 1/2; 316/336] END C=1000, max_iter=50, penalty=none, solver=lbfgs;, score=-0.956 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 316/336] START C=1000, max_iter=50, penalty=none, solver=lbfgs.........\n",
      "[CV 2/2; 316/336] END C=1000, max_iter=50, penalty=none, solver=lbfgs;, score=-0.972 total time=   0.2s\n",
      "[CV 1/2; 317/336] START C=1000, max_iter=100, penalty=l2, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 307/336] END C=100, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.3s\n",
      "[CV 2/2; 317/336] START C=1000, max_iter=100, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 317/336] END C=1000, max_iter=100, penalty=l2, solver=newton-cg;, score=-0.998 total time=   1.3s\n",
      "[CV 1/2; 318/336] START C=1000, max_iter=100, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 317/336] END C=1000, max_iter=100, penalty=l2, solver=newton-cg;, score=-1.029 total time=   1.2s\n",
      "[CV 2/2; 318/336] START C=1000, max_iter=100, penalty=l2, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 318/336] END C=1000, max_iter=100, penalty=l2, solver=lbfgs;, score=-0.992 total time=   0.5s\n",
      "[CV 1/2; 319/336] START C=1000, max_iter=100, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 318/336] END C=1000, max_iter=100, penalty=l2, solver=lbfgs;, score=-1.021 total time=   0.5s\n",
      "[CV 2/2; 319/336] START C=1000, max_iter=100, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 311/336] END C=100, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.1s\n",
      "[CV 1/2; 320/336] START C=1000, max_iter=100, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 320/336] END C=1000, max_iter=100, penalty=none, solver=lbfgs;, score=-1.007 total time=   0.3s\n",
      "[CV 2/2; 320/336] START C=1000, max_iter=100, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 320/336] END C=1000, max_iter=100, penalty=none, solver=lbfgs;, score=-1.034 total time=   0.4s\n",
      "[CV 1/2; 321/336] START C=1000, max_iter=200, penalty=l2, solver=newton-cg......\n",
      "[CV 1/2; 311/336] END C=100, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.4s\n",
      "[CV 2/2; 321/336] START C=1000, max_iter=200, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 315/336] END C=1000, max_iter=50, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.1s\n",
      "[CV 1/2; 322/336] START C=1000, max_iter=200, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 321/336] END C=1000, max_iter=200, penalty=l2, solver=newton-cg;, score=-1.029 total time=   1.2s\n",
      "[CV 2/2; 322/336] START C=1000, max_iter=200, penalty=l2, solver=lbfgs..........\n",
      "[CV 1/2; 321/336] END C=1000, max_iter=200, penalty=l2, solver=newton-cg;, score=-0.998 total time=   1.4s\n",
      "[CV 1/2; 323/336] START C=1000, max_iter=200, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 322/336] END C=1000, max_iter=200, penalty=l2, solver=lbfgs;, score=-0.999 total time=   0.7s\n",
      "[CV 2/2; 323/336] START C=1000, max_iter=200, penalty=none, solver=newton-cg....\n",
      "[CV 2/2; 322/336] END C=1000, max_iter=200, penalty=l2, solver=lbfgs;, score=-1.045 total time=   0.7s\n",
      "[CV 1/2; 324/336] START C=1000, max_iter=200, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 312/336] END C=100, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.355 total time=   9.2s\n",
      "[CV 2/2; 324/336] START C=1000, max_iter=200, penalty=none, solver=lbfgs........\n",
      "[CV 1/2; 315/336] END C=1000, max_iter=50, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.5s\n",
      "[CV 1/2; 325/336] START C=1000, max_iter=500, penalty=l2, solver=newton-cg......\n",
      "[CV 2/2; 312/336] END C=100, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.867 total time=   9.2s\n",
      "[CV 2/2; 325/336] START C=1000, max_iter=500, penalty=l2, solver=newton-cg......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 324/336] END C=1000, max_iter=200, penalty=none, solver=lbfgs;, score=-1.054 total time=   0.7s\n",
      "[CV 1/2; 326/336] START C=1000, max_iter=500, penalty=l2, solver=lbfgs..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 324/336] END C=1000, max_iter=200, penalty=none, solver=lbfgs;, score=-1.125 total time=   0.8s\n",
      "[CV 2/2; 326/336] START C=1000, max_iter=500, penalty=l2, solver=lbfgs..........\n",
      "[CV 2/2; 319/336] END C=1000, max_iter=100, penalty=none, solver=newton-cg;, score=-1.599 total time=   5.9s\n",
      "[CV 1/2; 327/336] START C=1000, max_iter=500, penalty=none, solver=newton-cg....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 325/336] END C=1000, max_iter=500, penalty=l2, solver=newton-cg;, score=-1.029 total time=   1.3s\n",
      "[CV 2/2; 327/336] START C=1000, max_iter=500, penalty=none, solver=newton-cg....\n",
      "[CV 1/2; 325/336] END C=1000, max_iter=500, penalty=l2, solver=newton-cg;, score=-0.998 total time=   1.4s\n",
      "[CV 1/2; 328/336] START C=1000, max_iter=500, penalty=none, solver=lbfgs........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 326/336] END C=1000, max_iter=500, penalty=l2, solver=lbfgs;, score=-0.997 total time=   1.8s\n",
      "[CV 2/2; 328/336] START C=1000, max_iter=500, penalty=none, solver=lbfgs........\n",
      "[CV 1/2; 319/336] END C=1000, max_iter=100, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.3s\n",
      "[CV 1/2; 329/336] START C=1000, max_iter=1000, penalty=l2, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 326/336] END C=1000, max_iter=500, penalty=l2, solver=lbfgs;, score=-1.033 total time=   1.8s\n",
      "[CV 2/2; 329/336] START C=1000, max_iter=1000, penalty=l2, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 328/336] END C=1000, max_iter=500, penalty=none, solver=lbfgs;, score=-1.171 total time=   1.8s\n",
      "[CV 1/2; 330/336] START C=1000, max_iter=1000, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 329/336] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=-0.998 total time=   1.3s\n",
      "[CV 2/2; 330/336] START C=1000, max_iter=1000, penalty=l2, solver=lbfgs.........\n",
      "[CV 2/2; 329/336] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=-1.029 total time=   1.2s\n",
      "[CV 1/2; 331/336] START C=1000, max_iter=1000, penalty=none, solver=newton-cg...\n",
      "[CV 2/2; 328/336] END C=1000, max_iter=500, penalty=none, solver=lbfgs;, score=-1.489 total time=   1.8s\n",
      "[CV 2/2; 331/336] START C=1000, max_iter=1000, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 323/336] END C=1000, max_iter=200, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 1/2; 332/336] START C=1000, max_iter=1000, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 323/336] END C=1000, max_iter=200, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.5s\n",
      "[CV 2/2; 332/336] START C=1000, max_iter=1000, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 330/336] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=-0.998 total time=   3.7s\n",
      "[CV 1/2; 333/336] START C=1000, max_iter=2500, penalty=l2, solver=newton-cg.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 330/336] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=-1.029 total time=   3.7s\n",
      "[CV 2/2; 333/336] START C=1000, max_iter=2500, penalty=l2, solver=newton-cg.....\n",
      "[CV 2/2; 327/336] END C=1000, max_iter=500, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.1s\n",
      "[CV 1/2; 334/336] START C=1000, max_iter=2500, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 327/336] END C=1000, max_iter=500, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.4s\n",
      "[CV 2/2; 334/336] START C=1000, max_iter=2500, penalty=l2, solver=lbfgs.........\n",
      "[CV 1/2; 333/336] END C=1000, max_iter=2500, penalty=l2, solver=newton-cg;, score=-0.998 total time=   1.3s\n",
      "[CV 1/2; 335/336] START C=1000, max_iter=2500, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 333/336] END C=1000, max_iter=2500, penalty=l2, solver=newton-cg;, score=-1.029 total time=   1.2s\n",
      "[CV 2/2; 335/336] START C=1000, max_iter=2500, penalty=none, solver=newton-cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 332/336] END C=1000, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.317 total time=   3.6s\n",
      "[CV 1/2; 336/336] START C=1000, max_iter=2500, penalty=none, solver=lbfgs.......\n",
      "[CV 2/2; 331/336] END C=1000, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.599 total time=   6.0s\n",
      "[CV 2/2; 336/336] START C=1000, max_iter=2500, penalty=none, solver=lbfgs.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 332/336] END C=1000, max_iter=1000, penalty=none, solver=lbfgs;, score=-1.601 total time=   3.7s\n",
      "[CV 1/2; 331/336] END C=1000, max_iter=1000, penalty=none, solver=newton-cg;, score=-1.593 total time=   7.4s\n",
      "[CV 1/2; 334/336] END C=1000, max_iter=2500, penalty=l2, solver=lbfgs;, score=-0.998 total time=   4.0s\n",
      "[CV 2/2; 334/336] END C=1000, max_iter=2500, penalty=l2, solver=lbfgs;, score=-1.028 total time=   3.8s\n",
      "[CV 2/2; 335/336] END C=1000, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.599 total time=   4.7s\n",
      "[CV 1/2; 335/336] END C=1000, max_iter=2500, penalty=none, solver=newton-cg;, score=-1.593 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 336/336] END C=1000, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.355 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "84 fits failed out of a total of 672.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "84 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan -1.00588797 -0.94927898 -0.95861138         nan -0.96778161\n",
      " -0.94927898 -0.96321341         nan -0.98772816 -0.94927898 -0.97102472\n",
      "         nan -0.97962715 -0.94927899 -0.98809242         nan -0.97593741\n",
      " -0.94927899 -1.00930969         nan -1.0204525  -0.94927898 -1.05359249\n",
      "         nan -0.97416316 -0.94921508 -0.95856214         nan -1.03221028\n",
      " -0.94921505 -0.96317464         nan -0.95754049 -0.94921502 -0.97108638\n",
      "         nan -0.96741543 -0.94921503 -0.98802726         nan -0.9583668\n",
      " -0.94921504 -1.00931495         nan -1.00220817 -0.94921505 -1.05361747\n",
      "         nan -0.9493553  -0.95013863 -0.95870063         nan -0.95056254\n",
      " -0.95013805 -0.96324708         nan -0.94951597 -0.95013861 -0.97111604\n",
      "         nan -0.9493435  -0.95013858 -0.98808714         nan -0.94939501\n",
      " -0.95013929 -1.00934056         nan -0.94933331 -0.95013864 -1.05359921\n",
      "         nan -0.946137   -0.95142393 -0.95870686         nan -0.94614607\n",
      " -0.95142426 -0.96317253         nan -0.94614603 -0.95142388 -0.97104686\n",
      "         nan -0.94614599 -0.95142376 -0.98807264         nan -0.94614609\n",
      " -0.95142379 -1.00929613         nan -0.94614603 -0.95142349 -1.05361919\n",
      "         nan -0.94912196 -0.95366427 -0.95868436         nan -0.95006289\n",
      " -0.95370734 -0.96316308         nan -0.95088083 -0.95370945 -0.97105495\n",
      "         nan -0.95127157 -0.95370793 -0.98804664         nan -0.9516148\n",
      " -0.95371004 -1.00927371         nan -0.95178692 -0.95370928 -1.05360115\n",
      "         nan -0.95653712 -0.95773704 -0.95882972         nan -0.95957524\n",
      " -0.96036012 -0.96323            nan -0.96397903 -0.96330814 -0.97101583\n",
      "         nan -0.97137673 -0.96530486 -0.98802529         nan -0.97801267\n",
      " -0.96544361 -1.00929886         nan -0.987805   -0.9654414  -1.05358682\n",
      "         nan -0.95838152 -0.95868784 -0.95874678         nan -0.96277297\n",
      " -0.96281314 -0.96311659         nan -0.96999824 -0.96988709 -0.97105523\n",
      "         nan -0.98543617 -0.98331755 -0.98805769         nan -1.00389292\n",
      " -0.99588634 -1.00929872         nan -1.04007511 -1.00836885 -1.05359529\n",
      " -0.94927898 -0.94927903 -1.59624212 -0.9636879  -0.94927898 -0.94927903\n",
      " -1.59624212 -1.0203361  -0.94927898 -0.94927903 -1.59624212 -1.08927025\n",
      " -0.94927898 -0.94927903 -1.59624212 -1.32982436 -0.94927898 -0.94927903\n",
      " -1.59624212 -1.45926694 -0.94927898 -0.94927903 -1.59624212 -1.61119901\n",
      " -0.94921505 -0.94921507 -1.59624212 -0.9636879  -0.94921505 -0.94921507\n",
      " -1.59624212 -1.0203361  -0.94921505 -0.94921507 -1.59624212 -1.08927025\n",
      " -0.94921505 -0.94921507 -1.59624212 -1.32982436 -0.94921505 -0.94921507\n",
      " -1.59624212 -1.45926694 -0.94921505 -0.94921507 -1.59624212 -1.61119901\n",
      " -0.95013867 -0.95013792 -1.59624212 -0.9636879  -0.95013867 -0.95013792\n",
      " -1.59624212 -1.0203361  -0.95013867 -0.95013792 -1.59624212 -1.08927025\n",
      " -0.95013867 -0.95013792 -1.59624212 -1.32982436 -0.95013867 -0.95013792\n",
      " -1.59624212 -1.45926694 -0.95013867 -0.95013792 -1.59624212 -1.61119901\n",
      " -0.95142316 -0.95142795 -1.59624212 -0.9636879  -0.95142316 -0.95142795\n",
      " -1.59624212 -1.0203361  -0.95142316 -0.95142795 -1.59624212 -1.08927025\n",
      " -0.95142316 -0.95142795 -1.59624212 -1.32982436 -0.95142316 -0.95142795\n",
      " -1.59624212 -1.45926694 -0.95142316 -0.95142795 -1.59624212 -1.61119901\n",
      " -0.95371206 -0.95442056 -1.59624212 -0.9636879  -0.95371206 -0.95365165\n",
      " -1.59624212 -1.0203361  -0.95371206 -0.95371405 -1.59624212 -1.08927025\n",
      " -0.95371206 -0.95371405 -1.59624212 -1.32982436 -0.95371206 -0.95371405\n",
      " -1.59624212 -1.45926694 -0.95371206 -0.95371405 -1.59624212 -1.61119901\n",
      " -0.96556212 -0.96479635 -1.59624212 -0.9636879  -0.96556212 -0.9690553\n",
      " -1.59624212 -1.0203361  -0.96556212 -0.96610609 -1.59624212 -1.08927025\n",
      " -0.96556212 -0.96548084 -1.59624212 -1.32982436 -0.96556212 -0.96548084\n",
      " -1.59624212 -1.45926694 -0.96556212 -0.96548084 -1.59624212 -1.61119901\n",
      " -1.0133696  -0.96715047 -1.59624212 -0.9636879  -1.0133696  -1.00651828\n",
      " -1.59624212 -1.0203361  -1.0133696  -1.02197213 -1.59624212 -1.08927025\n",
      " -1.0133696  -1.01473653 -1.59624212 -1.32982436 -1.0133696  -1.01396095\n",
      " -1.59624212 -1.45926694 -1.0133696  -1.01322234 -1.59624212 -1.61119901]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 336/336] END C=1000, max_iter=2500, penalty=none, solver=lbfgs;, score=-1.867 total time=   5.7s\n",
      "Best score: -0.946\n",
      "Best parameters set:\n",
      "\tC: 1\n",
      "\tmax_iter: 50\n",
      "\tpenalty: 'l1'\n",
      "\tsolver: 'saga'\n",
      "\tC: 1\n",
      "\tmax_iter: 50\n",
      "\tpenalty: 'l1'\n",
      "\tsolver: 'saga'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/NLP/nlp_env/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# We can now start grid search on these parameters\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=log_reg, \n",
    "                     param_grid=param_grid, \n",
    "                     scoring=mll_scorer,\n",
    "                     verbose=10, \n",
    "                     n_jobs=-1, # using all available cores\n",
    "                     refit=True, # el modelo final se ajustará con \n",
    "                                 # los mejores hiperparámetros encontrados después de la búsqueda.\n",
    "                     cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(X_train, y_train)  # we can use the full data here but im only using xtrain\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for params in param_grid:\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best score: -0.946\n",
    "- Best parameters set:\n",
    "\t- C: 1\n",
    "\t- max_iter: 50\n",
    "\t- penalty: 'l1'\n",
    "\t- solver: 'saga'\n",
    "\t- C: 1\n",
    "\t- max_iter: 50\n",
    "\t- penalty: 'l1'\n",
    "\t- solver: 'saga'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import decomposition\n",
    "\n",
    "# Apply SVD, I chose 120 components. 120-200 components are good enough for SVM model.\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(X_train)\n",
    "xtrain_svd = svd.transform(X_train)\n",
    "xvalid_svd = svd.transform(X_val)\n",
    "\n",
    "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(X_train)\n",
    "xtrain_svd_scl = scl.transform(X_train)\n",
    "xvalid_svd_scl = scl.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.001 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       187\n",
      "           1       0.45      1.00      0.62       205\n",
      "           2       1.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.45       454\n",
      "   macro avg       0.82      0.33      0.21       454\n",
      "weighted avg       0.75      0.45      0.28       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple SVM\n",
    "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
    "clf.fit(xtrain_svd_scl, y_train)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_val, predictions))\n",
    "\n",
    "# Convertir probabilidades a etiquetas\n",
    "predicted_labels = np.argmax(predictions, axis=1)  \n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(classification_report(y_val, predicted_labels, zero_division=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.049 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.01       187\n",
      "           1       0.45      1.00      0.62       205\n",
      "           2       1.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.45       454\n",
      "   macro avg       0.65      0.33      0.21       454\n",
      "weighted avg       0.55      0.45      0.28       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# Fitting a simple xgboost \n",
    "clf = xgb.XGBClassifier(max_depth=7,\n",
    "                        n_estimators=200, \n",
    "                        colsample_bytree=0.8, \n",
    "                        subsample=0.8, \n",
    "                        nthread=10, \n",
    "                        learning_rate=0.1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict_proba(X_val)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_val, predictions))\n",
    "\n",
    "# Convertir probabilidades a etiquetas\n",
    "predicted_labels = np.argmax(predictions, axis=1)  \n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(classification_report(y_val, predicted_labels, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
